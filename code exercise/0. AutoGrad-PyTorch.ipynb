{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 自动求导\n",
    "\n",
    "假设我们想对函数 $y = 2\\mathbf{x}^{\\top}\\mathbf{x}$关于列向量 $\\mathbf{x}$求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AVG',\n",
       " 'AggregationType',\n",
       " 'AnyType',\n",
       " 'Argument',\n",
       " 'ArgumentSpec',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BenchmarkConfig',\n",
       " 'BenchmarkExecutionStats',\n",
       " 'Block',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'BoolType',\n",
       " 'BufferDict',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CONV_BN_FUSION',\n",
       " 'CallStack',\n",
       " 'Capsule',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ClassType',\n",
       " 'Code',\n",
       " 'CompilationUnit',\n",
       " 'CompleteArgumentSpec',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'ComplexType',\n",
       " 'ConcreteModuleType',\n",
       " 'ConcreteModuleTypeBuilder',\n",
       " 'CudaBFloat16StorageBase',\n",
       " 'CudaBoolStorageBase',\n",
       " 'CudaByteStorageBase',\n",
       " 'CudaCharStorageBase',\n",
       " 'CudaComplexDoubleStorageBase',\n",
       " 'CudaComplexFloatStorageBase',\n",
       " 'CudaDoubleStorageBase',\n",
       " 'CudaFloatStorageBase',\n",
       " 'CudaHalfStorageBase',\n",
       " 'CudaIntStorageBase',\n",
       " 'CudaLongStorageBase',\n",
       " 'CudaShortStorageBase',\n",
       " 'DeepCopyMemoTable',\n",
       " 'DeviceObjType',\n",
       " 'DictType',\n",
       " 'DisableTorchFunction',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'EnumType',\n",
       " 'ErrorReport',\n",
       " 'ExecutionPlan',\n",
       " 'FUSE_ADD_RELU',\n",
       " 'FatalError',\n",
       " 'FileCheck',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'FloatType',\n",
       " 'FunctionSchema',\n",
       " 'Future',\n",
       " 'FutureType',\n",
       " 'Generator',\n",
       " 'Gradient',\n",
       " 'Graph',\n",
       " 'GraphExecutorState',\n",
       " 'HOIST_CONV_PACKED_PARAMS',\n",
       " 'HalfStorage',\n",
       " 'HalfStorageBase',\n",
       " 'HalfTensor',\n",
       " 'INSERT_FOLD_PREPACK_OPS',\n",
       " 'IODescriptor',\n",
       " 'InferredType',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'IntType',\n",
       " 'InterfaceType',\n",
       " 'JITException',\n",
       " 'ListType',\n",
       " 'LiteScriptModule',\n",
       " 'LockingLogger',\n",
       " 'LoggerBase',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'MobileOptimizerType',\n",
       " 'ModuleDict',\n",
       " 'Node',\n",
       " 'NoneType',\n",
       " 'NoopLogger',\n",
       " 'NumberType',\n",
       " 'OptionalType',\n",
       " 'ParameterDict',\n",
       " 'PyObjectType',\n",
       " 'PyTorchFileReader',\n",
       " 'PyTorchFileWriter',\n",
       " 'QInt32Storage',\n",
       " 'QInt32StorageBase',\n",
       " 'QInt8Storage',\n",
       " 'QInt8StorageBase',\n",
       " 'QUInt4x2Storage',\n",
       " 'QUInt8Storage',\n",
       " 'REMOVE_DROPOUT',\n",
       " 'RRefType',\n",
       " 'SUM',\n",
       " 'ScriptClass',\n",
       " 'ScriptFunction',\n",
       " 'ScriptMethod',\n",
       " 'ScriptModule',\n",
       " 'ScriptObject',\n",
       " 'Set',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Size',\n",
       " 'StaticRuntime',\n",
       " 'Storage',\n",
       " 'Stream',\n",
       " 'StreamObjType',\n",
       " 'StringType',\n",
       " 'TYPE_CHECKING',\n",
       " 'Tensor',\n",
       " 'TensorType',\n",
       " 'ThroughputBenchmark',\n",
       " 'TracingState',\n",
       " 'TupleType',\n",
       " 'Type',\n",
       " 'USE_GLOBAL_DEPS',\n",
       " 'USE_RTLD_GLOBAL_WITH_LIBTORCH',\n",
       " 'Use',\n",
       " 'Value',\n",
       " '_C',\n",
       " '_StorageBase',\n",
       " '_VF',\n",
       " '__all__',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__config__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__future__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_adaptive_avg_pool2d',\n",
       " '_add_batch_dim',\n",
       " '_add_relu',\n",
       " '_add_relu_',\n",
       " '_addmv_impl_',\n",
       " '_aminmax',\n",
       " '_amp_foreach_non_finite_check_and_unscale_',\n",
       " '_amp_update_scale',\n",
       " '_assert',\n",
       " '_autograd_functions',\n",
       " '_baddbmm_mkl_',\n",
       " '_batch_norm_impl_index',\n",
       " '_bmm',\n",
       " '_cast_Byte',\n",
       " '_cast_Char',\n",
       " '_cast_Double',\n",
       " '_cast_Float',\n",
       " '_cast_Half',\n",
       " '_cast_Int',\n",
       " '_cast_Long',\n",
       " '_cast_Short',\n",
       " '_cat',\n",
       " '_choose_qparams_per_tensor',\n",
       " '_classes',\n",
       " '_compute_linear_combination',\n",
       " '_conj',\n",
       " '_convolution',\n",
       " '_convolution_nogroup',\n",
       " '_copy_from',\n",
       " '_ctc_loss',\n",
       " '_cudnn_ctc_loss',\n",
       " '_cudnn_init_dropout_state',\n",
       " '_cudnn_rnn',\n",
       " '_cudnn_rnn_flatten_weight',\n",
       " '_cufft_clear_plan_cache',\n",
       " '_cufft_get_plan_cache_max_size',\n",
       " '_cufft_get_plan_cache_size',\n",
       " '_cufft_set_plan_cache_max_size',\n",
       " '_cummax_helper',\n",
       " '_cummin_helper',\n",
       " '_debug_has_internal_overlap',\n",
       " '_dim_arange',\n",
       " '_dirichlet_grad',\n",
       " '_embedding_bag',\n",
       " '_embedding_bag_forward_only',\n",
       " '_empty_affine_quantized',\n",
       " '_empty_per_channel_affine_quantized',\n",
       " '_euclidean_dist',\n",
       " '_fake_quantize_learnable_per_channel_affine',\n",
       " '_fake_quantize_learnable_per_tensor_affine',\n",
       " '_fft_c2c',\n",
       " '_fft_c2r',\n",
       " '_fft_r2c',\n",
       " '_foreach_abs',\n",
       " '_foreach_abs_',\n",
       " '_foreach_acos',\n",
       " '_foreach_acos_',\n",
       " '_foreach_add',\n",
       " '_foreach_add_',\n",
       " '_foreach_addcdiv',\n",
       " '_foreach_addcdiv_',\n",
       " '_foreach_addcmul',\n",
       " '_foreach_addcmul_',\n",
       " '_foreach_asin',\n",
       " '_foreach_asin_',\n",
       " '_foreach_atan',\n",
       " '_foreach_atan_',\n",
       " '_foreach_ceil',\n",
       " '_foreach_ceil_',\n",
       " '_foreach_cos',\n",
       " '_foreach_cos_',\n",
       " '_foreach_cosh',\n",
       " '_foreach_cosh_',\n",
       " '_foreach_div',\n",
       " '_foreach_div_',\n",
       " '_foreach_erf',\n",
       " '_foreach_erf_',\n",
       " '_foreach_erfc',\n",
       " '_foreach_erfc_',\n",
       " '_foreach_exp',\n",
       " '_foreach_exp_',\n",
       " '_foreach_expm1',\n",
       " '_foreach_expm1_',\n",
       " '_foreach_floor',\n",
       " '_foreach_floor_',\n",
       " '_foreach_frac',\n",
       " '_foreach_frac_',\n",
       " '_foreach_lgamma',\n",
       " '_foreach_lgamma_',\n",
       " '_foreach_log',\n",
       " '_foreach_log10',\n",
       " '_foreach_log10_',\n",
       " '_foreach_log1p',\n",
       " '_foreach_log1p_',\n",
       " '_foreach_log2',\n",
       " '_foreach_log2_',\n",
       " '_foreach_log_',\n",
       " '_foreach_maximum',\n",
       " '_foreach_minimum',\n",
       " '_foreach_mul',\n",
       " '_foreach_mul_',\n",
       " '_foreach_neg',\n",
       " '_foreach_neg_',\n",
       " '_foreach_reciprocal',\n",
       " '_foreach_reciprocal_',\n",
       " '_foreach_round',\n",
       " '_foreach_round_',\n",
       " '_foreach_sigmoid',\n",
       " '_foreach_sigmoid_',\n",
       " '_foreach_sin',\n",
       " '_foreach_sin_',\n",
       " '_foreach_sinh',\n",
       " '_foreach_sinh_',\n",
       " '_foreach_sqrt',\n",
       " '_foreach_sqrt_',\n",
       " '_foreach_sub',\n",
       " '_foreach_sub_',\n",
       " '_foreach_tan',\n",
       " '_foreach_tan_',\n",
       " '_foreach_tanh',\n",
       " '_foreach_tanh_',\n",
       " '_foreach_trunc',\n",
       " '_foreach_trunc_',\n",
       " '_foreach_zero_',\n",
       " '_fused_dropout',\n",
       " '_grid_sampler_2d_cpu_fallback',\n",
       " '_has_compatible_shallow_copy_type',\n",
       " '_import_dotted_name',\n",
       " '_index_copy_',\n",
       " '_index_put_impl_',\n",
       " '_initExtension',\n",
       " '_jit_internal',\n",
       " '_linalg_inv_out_helper_',\n",
       " '_linalg_qr_helper',\n",
       " '_linalg_solve_out_helper_',\n",
       " '_linalg_utils',\n",
       " '_load_global_deps',\n",
       " '_lobpcg',\n",
       " '_log_softmax',\n",
       " '_log_softmax_backward_data',\n",
       " '_logcumsumexp',\n",
       " '_lowrank',\n",
       " '_lu_solve_helper',\n",
       " '_lu_with_info',\n",
       " '_make_dual',\n",
       " '_make_per_channel_quantized_tensor',\n",
       " '_make_per_tensor_quantized_tensor',\n",
       " '_masked_scale',\n",
       " '_mkldnn',\n",
       " '_mkldnn_reshape',\n",
       " '_mkldnn_transpose',\n",
       " '_mkldnn_transpose_',\n",
       " '_mode',\n",
       " '_namedtensor_internals',\n",
       " '_nnpack_available',\n",
       " '_nnpack_spatial_convolution',\n",
       " '_ops',\n",
       " '_pack_padded_sequence',\n",
       " '_pad_packed_sequence',\n",
       " '_remove_batch_dim',\n",
       " '_reshape_from_tensor',\n",
       " '_rowwise_prune',\n",
       " '_s_where',\n",
       " '_sample_dirichlet',\n",
       " '_saturate_weight_to_fp16',\n",
       " '_shape_as_tensor',\n",
       " '_six',\n",
       " '_sobol_engine_draw',\n",
       " '_sobol_engine_ff_',\n",
       " '_sobol_engine_initialize_state_',\n",
       " '_sobol_engine_scramble_',\n",
       " '_softmax',\n",
       " '_softmax_backward_data',\n",
       " '_sparse_addmm',\n",
       " '_sparse_coo_tensor_unsafe',\n",
       " '_sparse_log_softmax',\n",
       " '_sparse_log_softmax_backward_data',\n",
       " '_sparse_matrix_mask_helper',\n",
       " '_sparse_mm',\n",
       " '_sparse_softmax',\n",
       " '_sparse_softmax_backward_data',\n",
       " '_sparse_sparse_matmul',\n",
       " '_sparse_sum',\n",
       " '_stack',\n",
       " '_standard_gamma',\n",
       " '_standard_gamma_grad',\n",
       " '_std',\n",
       " '_storage_classes',\n",
       " '_string_classes',\n",
       " '_syevd_helper',\n",
       " '_tensor_classes',\n",
       " '_tensor_str',\n",
       " '_test_serialization_subcmul',\n",
       " '_trilinear',\n",
       " '_unique',\n",
       " '_unique2',\n",
       " '_unpack_dual',\n",
       " '_use_cudnn_ctc_loss',\n",
       " '_use_cudnn_rnn_flatten_weight',\n",
       " '_utils',\n",
       " '_utils_internal',\n",
       " '_validate_sparse_coo_tensor_args',\n",
       " '_var',\n",
       " '_vmap_internals',\n",
       " '_weight_norm',\n",
       " '_weight_norm_cuda_interface',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'absolute',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'acosh',\n",
       " 'acosh_',\n",
       " 'adaptive_avg_pool1d',\n",
       " 'adaptive_max_pool1d',\n",
       " 'add',\n",
       " 'addbmm',\n",
       " 'addcdiv',\n",
       " 'addcmul',\n",
       " 'addmm',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'affine_grid_generator',\n",
       " 'align_tensors',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'alpha_dropout',\n",
       " 'alpha_dropout_',\n",
       " 'amax',\n",
       " 'amin',\n",
       " 'angle',\n",
       " 'any',\n",
       " 'arange',\n",
       " 'arccos',\n",
       " 'arccos_',\n",
       " 'arccosh',\n",
       " 'arccosh_',\n",
       " 'arcsin',\n",
       " 'arcsin_',\n",
       " 'arcsinh',\n",
       " 'arcsinh_',\n",
       " 'arctan',\n",
       " 'arctan_',\n",
       " 'arctanh',\n",
       " 'arctanh_',\n",
       " 'are_deterministic_algorithms_enabled',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_strided',\n",
       " 'as_strided_',\n",
       " 'as_tensor',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'asinh',\n",
       " 'asinh_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan_',\n",
       " 'atanh',\n",
       " 'atanh_',\n",
       " 'atleast_1d',\n",
       " 'atleast_2d',\n",
       " 'atleast_3d',\n",
       " 'autocast_decrement_nesting',\n",
       " 'autocast_increment_nesting',\n",
       " 'autograd',\n",
       " 'avg_pool1d',\n",
       " 'backends',\n",
       " 'baddbmm',\n",
       " 'bartlett_window',\n",
       " 'base_py_dll_path',\n",
       " 'batch_norm',\n",
       " 'batch_norm_backward_elemt',\n",
       " 'batch_norm_backward_reduce',\n",
       " 'batch_norm_elemt',\n",
       " 'batch_norm_gather_stats',\n",
       " 'batch_norm_gather_stats_with_counts',\n",
       " 'batch_norm_stats',\n",
       " 'batch_norm_update_stats',\n",
       " 'bernoulli',\n",
       " 'bfloat16',\n",
       " 'bilinear',\n",
       " 'binary_cross_entropy_with_logits',\n",
       " 'bincount',\n",
       " 'binomial',\n",
       " 'bitwise_and',\n",
       " 'bitwise_not',\n",
       " 'bitwise_or',\n",
       " 'bitwise_xor',\n",
       " 'blackman_window',\n",
       " 'block_diag',\n",
       " 'bmm',\n",
       " 'bool',\n",
       " 'broadcast_shapes',\n",
       " 'broadcast_tensors',\n",
       " 'broadcast_to',\n",
       " 'bucketize',\n",
       " 'can_cast',\n",
       " 'cartesian_prod',\n",
       " 'cat',\n",
       " 'cdist',\n",
       " 'cdouble',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'celu',\n",
       " 'celu_',\n",
       " 'cfloat',\n",
       " 'chain_matmul',\n",
       " 'channel_shuffle',\n",
       " 'channels_last',\n",
       " 'channels_last_3d',\n",
       " 'cholesky',\n",
       " 'cholesky_inverse',\n",
       " 'cholesky_solve',\n",
       " 'choose_qparams_optimized',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clamp_',\n",
       " 'clamp_max',\n",
       " 'clamp_max_',\n",
       " 'clamp_min',\n",
       " 'clamp_min_',\n",
       " 'classes',\n",
       " 'clear_autocast_cache',\n",
       " 'clip',\n",
       " 'clip_',\n",
       " 'clone',\n",
       " 'column_stack',\n",
       " 'combinations',\n",
       " 'compiled_with_cxx11_abi',\n",
       " 'complex',\n",
       " 'complex128',\n",
       " 'complex32',\n",
       " 'complex64',\n",
       " 'conj',\n",
       " 'constant_pad_nd',\n",
       " 'contiguous_format',\n",
       " 'conv1d',\n",
       " 'conv2d',\n",
       " 'conv3d',\n",
       " 'conv_tbc',\n",
       " 'conv_transpose1d',\n",
       " 'conv_transpose2d',\n",
       " 'conv_transpose3d',\n",
       " 'convolution',\n",
       " 'copysign',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'cosine_embedding_loss',\n",
       " 'cosine_similarity',\n",
       " 'count_nonzero',\n",
       " 'cpp',\n",
       " 'cross',\n",
       " 'ctc_loss',\n",
       " 'ctypes',\n",
       " 'cuda',\n",
       " 'cuda_path',\n",
       " 'cuda_version',\n",
       " 'cudnn_affine_grid_generator',\n",
       " 'cudnn_batch_norm',\n",
       " 'cudnn_convolution',\n",
       " 'cudnn_convolution_transpose',\n",
       " 'cudnn_grid_sampler',\n",
       " 'cudnn_is_acceptable',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'default_generator',\n",
       " 'deg2rad',\n",
       " 'deg2rad_',\n",
       " 'dequantize',\n",
       " 'det',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_embed',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'diff',\n",
       " 'digamma',\n",
       " 'dist',\n",
       " 'distributed',\n",
       " 'distributions',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dll',\n",
       " 'dll_path',\n",
       " 'dll_paths',\n",
       " 'dlls',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dropout',\n",
       " 'dropout_',\n",
       " 'dsmm',\n",
       " 'dstack',\n",
       " 'dtype',\n",
       " 'eig',\n",
       " 'einsum',\n",
       " 'embedding',\n",
       " 'embedding_bag',\n",
       " 'embedding_renorm_',\n",
       " 'empty',\n",
       " 'empty_like',\n",
       " 'empty_meta',\n",
       " 'empty_quantized',\n",
       " 'empty_strided',\n",
       " 'enable_grad',\n",
       " 'eq',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erf_',\n",
       " 'erfc',\n",
       " 'erfc_',\n",
       " 'erfinv',\n",
       " 'exp',\n",
       " 'exp2',\n",
       " 'exp2_',\n",
       " 'exp_',\n",
       " 'expm1',\n",
       " 'expm1_',\n",
       " 'eye',\n",
       " 'fake_quantize_per_channel_affine',\n",
       " 'fake_quantize_per_tensor_affine',\n",
       " 'fbgemm_linear_fp16_weight',\n",
       " 'fbgemm_linear_fp16_weight_fp32_activation',\n",
       " 'fbgemm_linear_int8_weight',\n",
       " 'fbgemm_linear_int8_weight_fp32_activation',\n",
       " 'fbgemm_linear_quantize_weight',\n",
       " 'fbgemm_pack_gemm_matrix_fp16',\n",
       " 'fbgemm_pack_quantized_matrix',\n",
       " 'feature_alpha_dropout',\n",
       " 'feature_alpha_dropout_',\n",
       " 'feature_dropout',\n",
       " 'feature_dropout_',\n",
       " 'fft',\n",
       " 'fill_',\n",
       " 'finfo',\n",
       " 'fix',\n",
       " 'fix_',\n",
       " 'flatten',\n",
       " 'flip',\n",
       " 'fliplr',\n",
       " 'flipud',\n",
       " 'float',\n",
       " 'float16',\n",
       " 'float32',\n",
       " 'float64',\n",
       " 'float_power',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'floor_divide',\n",
       " 'fmax',\n",
       " 'fmin',\n",
       " 'fmod',\n",
       " 'fork',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'frobenius_norm',\n",
       " 'from_file',\n",
       " 'from_numpy',\n",
       " 'full',\n",
       " 'full_like',\n",
       " 'functional',\n",
       " 'futures',\n",
       " 'gather',\n",
       " 'gcd',\n",
       " 'gcd_',\n",
       " 'ge',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'get_default_dtype',\n",
       " 'get_device',\n",
       " 'get_file_path',\n",
       " 'get_num_interop_threads',\n",
       " 'get_num_threads',\n",
       " 'get_rng_state',\n",
       " 'glob',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'grid_sampler',\n",
       " 'grid_sampler_2d',\n",
       " 'grid_sampler_3d',\n",
       " 'group_norm',\n",
       " 'gru',\n",
       " 'gru_cell',\n",
       " 'gt',\n",
       " 'half',\n",
       " 'hamming_window',\n",
       " 'hann_window',\n",
       " 'hardshrink',\n",
       " 'has_cuda',\n",
       " 'has_cudnn',\n",
       " 'has_lapack',\n",
       " 'has_mkl',\n",
       " 'has_mkldnn',\n",
       " 'has_openmp',\n",
       " 'heaviside',\n",
       " 'hinge_embedding_loss',\n",
       " 'histc',\n",
       " 'hsmm',\n",
       " 'hspmm',\n",
       " 'hstack',\n",
       " 'hub',\n",
       " 'hypot',\n",
       " 'i0',\n",
       " 'i0_',\n",
       " 'igamma',\n",
       " 'igammac',\n",
       " 'iinfo',\n",
       " 'imag',\n",
       " 'import_ir_module',\n",
       " 'import_ir_module_from_buffer',\n",
       " 'index_add',\n",
       " 'index_copy',\n",
       " 'index_fill',\n",
       " 'index_put',\n",
       " 'index_put_',\n",
       " 'index_select',\n",
       " 'init_num_threads',\n",
       " 'initial_seed',\n",
       " 'inner',\n",
       " 'instance_norm',\n",
       " 'int',\n",
       " 'int16',\n",
       " 'int32',\n",
       " 'int64',\n",
       " 'int8',\n",
       " 'int_repr',\n",
       " 'inverse',\n",
       " 'is_anomaly_enabled',\n",
       " 'is_autocast_enabled',\n",
       " 'is_complex',\n",
       " 'is_deterministic',\n",
       " 'is_distributed',\n",
       " 'is_floating_point',\n",
       " 'is_grad_enabled',\n",
       " 'is_loaded',\n",
       " 'is_nonzero',\n",
       " 'is_same_size',\n",
       " 'is_signed',\n",
       " 'is_storage',\n",
       " 'is_tensor',\n",
       " 'is_vulkan_available',\n",
       " 'isclose',\n",
       " 'isfinite',\n",
       " 'isinf',\n",
       " 'isnan',\n",
       " 'isneginf',\n",
       " 'isposinf',\n",
       " 'isreal',\n",
       " 'istft',\n",
       " 'jit',\n",
       " 'kaiser_window',\n",
       " 'kernel32',\n",
       " 'kl_div',\n",
       " 'kron',\n",
       " 'kthvalue',\n",
       " 'last_error',\n",
       " 'layer_norm',\n",
       " 'layout',\n",
       " 'lcm',\n",
       " 'lcm_',\n",
       " 'ldexp',\n",
       " 'ldexp_',\n",
       " 'le',\n",
       " 'legacy_contiguous_format',\n",
       " 'lerp',\n",
       " 'less',\n",
       " 'less_equal',\n",
       " 'lgamma',\n",
       " 'linalg',\n",
       " 'linspace',\n",
       " 'load',\n",
       " 'lobpcg',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log10_',\n",
       " 'log1p',\n",
       " 'log1p_',\n",
       " 'log2',\n",
       " 'log2_',\n",
       " 'log_',\n",
       " 'log_softmax',\n",
       " 'logaddexp',\n",
       " 'logaddexp2',\n",
       " 'logcumsumexp',\n",
       " 'logdet',\n",
       " 'logical_and',\n",
       " 'logical_not',\n",
       " 'logical_or',\n",
       " 'logical_xor',\n",
       " 'logit',\n",
       " 'logit_',\n",
       " 'logspace',\n",
       " 'logsumexp',\n",
       " 'long',\n",
       " 'lstm',\n",
       " 'lstm_cell',\n",
       " 'lstsq',\n",
       " 'lt',\n",
       " 'lu',\n",
       " 'lu_solve',\n",
       " 'lu_unpack',\n",
       " 'manual_seed',\n",
       " 'margin_ranking_loss',\n",
       " 'masked_fill',\n",
       " 'masked_scatter',\n",
       " 'masked_select',\n",
       " 'matmul',\n",
       " 'matrix_exp',\n",
       " 'matrix_power',\n",
       " 'matrix_rank',\n",
       " 'max',\n",
       " 'max_pool1d',\n",
       " 'max_pool1d_with_indices',\n",
       " 'max_pool2d',\n",
       " 'max_pool3d',\n",
       " 'maximum',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'memory_format',\n",
       " 'merge_type_from_type_comment',\n",
       " 'meshgrid',\n",
       " 'min',\n",
       " 'minimum',\n",
       " 'miopen_batch_norm',\n",
       " 'miopen_convolution',\n",
       " 'miopen_convolution_transpose',\n",
       " 'miopen_depthwise_convolution',\n",
       " 'miopen_rnn',\n",
       " 'mkldnn_adaptive_avg_pool2d',\n",
       " 'mkldnn_convolution',\n",
       " 'mkldnn_convolution_backward_weights',\n",
       " 'mkldnn_linear_backward_weights',\n",
       " 'mkldnn_max_pool2d',\n",
       " 'mkldnn_max_pool3d',\n",
       " 'mm',\n",
       " 'mode',\n",
       " 'moveaxis',\n",
       " 'movedim',\n",
       " 'msort',\n",
       " 'mul',\n",
       " 'multinomial',\n",
       " 'multiply',\n",
       " 'multiprocessing',\n",
       " 'mv',\n",
       " 'mvlgamma',\n",
       " 'name',\n",
       " 'nan_to_num',\n",
       " 'nan_to_num_',\n",
       " 'nanmedian',\n",
       " 'nanquantile',\n",
       " 'nansum',\n",
       " 'narrow',\n",
       " 'narrow_copy',\n",
       " 'native_batch_norm',\n",
       " 'native_group_norm',\n",
       " 'native_layer_norm',\n",
       " 'native_norm',\n",
       " 'ne',\n",
       " 'neg',\n",
       " 'neg_',\n",
       " 'negative',\n",
       " 'negative_',\n",
       " 'nextafter',\n",
       " 'nn',\n",
       " 'no_grad',\n",
       " 'nonzero',\n",
       " 'norm',\n",
       " 'norm_except_dim',\n",
       " 'normal',\n",
       " 'not_equal',\n",
       " 'nuclear_norm',\n",
       " 'numel',\n",
       " 'nvtoolsext_dll_path',\n",
       " 'ones',\n",
       " 'ones_like',\n",
       " 'onnx',\n",
       " 'ops',\n",
       " 'optim',\n",
       " 'orgqr',\n",
       " 'ormqr',\n",
       " 'os',\n",
       " 'outer',\n",
       " 'overrides',\n",
       " 'pairwise_distance',\n",
       " 'parse_ir',\n",
       " 'parse_schema',\n",
       " 'parse_type_comment',\n",
       " 'path_patched',\n",
       " 'pca_lowrank',\n",
       " 'pdist',\n",
       " 'per_channel_affine',\n",
       " 'per_channel_affine_float_qparams',\n",
       " 'per_channel_symmetric',\n",
       " 'per_tensor_affine',\n",
       " 'per_tensor_symmetric',\n",
       " 'pfiles_path',\n",
       " 'pinverse',\n",
       " 'pixel_shuffle',\n",
       " 'pixel_unshuffle',\n",
       " 'platform',\n",
       " 'poisson',\n",
       " 'poisson_nll_loss',\n",
       " 'polar',\n",
       " 'polygamma',\n",
       " 'pow',\n",
       " 'prelu',\n",
       " 'prepare_multiprocessing_environment',\n",
       " 'preserve_format',\n",
       " 'prev_error_mode',\n",
       " 'prod',\n",
       " 'profiler',\n",
       " 'promote_types',\n",
       " 'py_dll_path',\n",
       " 'q_per_channel_axis',\n",
       " 'q_per_channel_scales',\n",
       " 'q_per_channel_zero_points',\n",
       " 'q_scale',\n",
       " 'q_zero_point',\n",
       " 'qint32',\n",
       " 'qint8',\n",
       " 'qr',\n",
       " 'qscheme',\n",
       " 'quantile',\n",
       " 'quantization',\n",
       " 'quantize_per_channel',\n",
       " 'quantize_per_tensor',\n",
       " 'quantized_batch_norm',\n",
       " 'quantized_gru',\n",
       " 'quantized_gru_cell',\n",
       " 'quantized_lstm',\n",
       " 'quantized_lstm_cell',\n",
       " 'quantized_max_pool1d',\n",
       " 'quantized_max_pool2d',\n",
       " 'quantized_rnn_relu_cell',\n",
       " 'quantized_rnn_tanh_cell',\n",
       " 'quasirandom',\n",
       " 'quint4x2',\n",
       " 'quint8',\n",
       " 'rad2deg',\n",
       " 'rad2deg_',\n",
       " 'rand',\n",
       " 'rand_like',\n",
       " 'randint',\n",
       " 'randint_like',\n",
       " 'randn',\n",
       " 'randn_like',\n",
       " 'random',\n",
       " 'randperm',\n",
       " 'range',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'reciprocal',\n",
       " 'reciprocal_',\n",
       " 'relu',\n",
       " 'relu_',\n",
       " 'remainder',\n",
       " 'renorm',\n",
       " 'repeat_interleave',\n",
       " 'res',\n",
       " 'reshape',\n",
       " 'resize_as_',\n",
       " 'result_type',\n",
       " 'rnn_relu',\n",
       " 'rnn_relu_cell',\n",
       " 'rnn_tanh',\n",
       " 'rnn_tanh_cell',\n",
       " 'roll',\n",
       " 'rot90',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'row_stack',\n",
       " 'rrelu',\n",
       " 'rrelu_',\n",
       " 'rsqrt',\n",
       " 'rsqrt_',\n",
       " 'rsub',\n",
       " 'saddmm',\n",
       " 'save',\n",
       " 'scalar_tensor',\n",
       " 'scatter',\n",
       " 'scatter_add',\n",
       " 'searchsorted',\n",
       " 'seed',\n",
       " 'select',\n",
       " 'selu',\n",
       " 'selu_',\n",
       " 'serialization',\n",
       " 'set_anomaly_enabled',\n",
       " 'set_autocast_enabled',\n",
       " 'set_default_dtype',\n",
       " 'set_default_tensor_type',\n",
       " 'set_deterministic',\n",
       " 'set_flush_denormal',\n",
       " 'set_grad_enabled',\n",
       " 'set_num_interop_threads',\n",
       " 'set_num_threads',\n",
       " 'set_printoptions',\n",
       " 'set_rng_state',\n",
       " 'sgn',\n",
       " 'short',\n",
       " 'sigmoid',\n",
       " 'sigmoid_',\n",
       " 'sign',\n",
       " 'signbit',\n",
       " 'sin',\n",
       " 'sin_',\n",
       " 'sinc',\n",
       " 'sinc_',\n",
       " 'sinh',\n",
       " 'sinh_',\n",
       " 'slogdet',\n",
       " 'smm',\n",
       " 'softmax',\n",
       " 'solve',\n",
       " 'sort',\n",
       " 'sparse',\n",
       " 'sparse_coo',\n",
       " 'sparse_coo_tensor',\n",
       " 'split',\n",
       " 'split_with_sizes',\n",
       " 'spmm',\n",
       " 'sqrt',\n",
       " 'sqrt_',\n",
       " 'square',\n",
       " 'square_',\n",
       " 'squeeze',\n",
       " 'sspaddmm',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'std_mean',\n",
       " 'stft',\n",
       " 'storage',\n",
       " 'strided',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'svd',\n",
       " 'svd_lowrank',\n",
       " 'swapaxes',\n",
       " 'swapdims',\n",
       " 'symeig',\n",
       " 'sys',\n",
       " 't',\n",
       " 'take',\n",
       " 'tan',\n",
       " 'tan_',\n",
       " 'tanh',\n",
       " 'tanh_',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torch:\n",
      "\n",
      "NAME\n",
      "    torch\n",
      "\n",
      "DESCRIPTION\n",
      "    The torch package contains data structures for multi-dimensional\n",
      "    tensors and defines mathematical operations over these tensors.\n",
      "    Additionally, it provides many utilities for efficient serializing of\n",
      "    Tensors and arbitrary types, and other useful utilities.\n",
      "    \n",
      "    It has a CUDA counterpart, that enables you to run your tensor computations\n",
      "    on an NVIDIA GPU with compute capability >= 3.0.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _C\n",
      "    _VF\n",
      "    __config__\n",
      "    __future__\n",
      "    _appdirs\n",
      "    _autograd_functions\n",
      "    _classes\n",
      "    _jit_internal\n",
      "    _linalg_utils\n",
      "    _lobpcg\n",
      "    _lowrank\n",
      "    _namedtensor_internals\n",
      "    _ops\n",
      "    _python_dispatcher\n",
      "    _six\n",
      "    _storage_docs\n",
      "    _tensor_docs\n",
      "    _tensor_str\n",
      "    _torch_docs\n",
      "    _utils\n",
      "    _utils_internal\n",
      "    _vmap_internals\n",
      "    autograd (package)\n",
      "    backends (package)\n",
      "    contrib (package)\n",
      "    cuda (package)\n",
      "    distributed (package)\n",
      "    distributions (package)\n",
      "    fft (package)\n",
      "    for_onnx (package)\n",
      "    functional\n",
      "    futures (package)\n",
      "    fx (package)\n",
      "    hub\n",
      "    jit (package)\n",
      "    linalg (package)\n",
      "    multiprocessing (package)\n",
      "    nn (package)\n",
      "    onnx (package)\n",
      "    optim (package)\n",
      "    overrides\n",
      "    package (package)\n",
      "    profiler (package)\n",
      "    quantization (package)\n",
      "    quasirandom\n",
      "    random\n",
      "    serialization\n",
      "    sparse (package)\n",
      "    storage\n",
      "    tensor\n",
      "    testing (package)\n",
      "    types\n",
      "    utils (package)\n",
      "    version\n",
      "\n",
      "SUBMODULES\n",
      "    classes\n",
      "    cpp\n",
      "    ops\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        FatalError\n",
      "        torch.jit.Error\n",
      "    builtins.object\n",
      "        BoolTensor\n",
      "        ByteTensor\n",
      "        CharTensor\n",
      "        DoubleTensor\n",
      "        FloatTensor\n",
      "        IntTensor\n",
      "        LongTensor\n",
      "        ShortTensor\n",
      "        Stream\n",
      "        device\n",
      "        dtype\n",
      "        finfo\n",
      "        iinfo\n",
      "        layout\n",
      "        memory_format\n",
      "        qscheme\n",
      "        torch._C.DisableTorchFunction\n",
      "        torch._C.Generator\n",
      "    builtins.tuple(builtins.object)\n",
      "        Size\n",
      "    pybind11_builtins.pybind11_object(builtins.object)\n",
      "        torch._C.AggregationType\n",
      "        torch._C.Argument\n",
      "        torch._C.ArgumentSpec\n",
      "        torch._C.BenchmarkConfig\n",
      "        torch._C.BenchmarkExecutionStats\n",
      "        torch._C.Block\n",
      "        torch._C.BufferDict\n",
      "        torch._C.CallStack\n",
      "        torch._C.Capsule\n",
      "        torch._C.Code\n",
      "        torch._C.CompleteArgumentSpec\n",
      "        torch._C.ConcreteModuleType\n",
      "        torch._C.ConcreteModuleTypeBuilder\n",
      "        torch._C.DeepCopyMemoTable\n",
      "        torch._C.ErrorReport\n",
      "        torch._C.ExecutionPlan\n",
      "        torch._C.FileCheck\n",
      "        torch._C.FunctionSchema\n",
      "        torch._C.Future\n",
      "        torch._C.Gradient\n",
      "        torch._C.Graph\n",
      "        torch._C.GraphExecutorState\n",
      "        torch._C.IODescriptor\n",
      "        torch._C.InferredType\n",
      "        torch._C.LiteScriptModule\n",
      "        torch._C.MobileOptimizerType\n",
      "        torch._C.ModuleDict\n",
      "        torch._C.Node\n",
      "        torch._C.ParameterDict\n",
      "        torch._C.PyTorchFileReader\n",
      "        torch._C.PyTorchFileWriter\n",
      "        torch._C.ScriptClass\n",
      "        torch._C.ScriptMethod\n",
      "        torch._C.ScriptObject\n",
      "            torch._C.ScriptModule\n",
      "        torch._C.StaticRuntime\n",
      "        torch._C.ThroughputBenchmark\n",
      "        torch._C.TracingState\n",
      "        torch._C.Type\n",
      "            torch._C.AnyType\n",
      "            torch._C.BoolType\n",
      "            torch._C.ClassType\n",
      "            torch._C.ComplexType\n",
      "            torch._C.DeviceObjType\n",
      "            torch._C.DictType\n",
      "            torch._C.EnumType\n",
      "            torch._C.FloatType\n",
      "            torch._C.FutureType\n",
      "            torch._C.IntType\n",
      "            torch._C.InterfaceType\n",
      "            torch._C.ListType\n",
      "            torch._C.NoneType\n",
      "            torch._C.NumberType\n",
      "            torch._C.OptionalType\n",
      "            torch._C.PyObjectType\n",
      "            torch._C.RRefType\n",
      "            torch._C.StreamObjType\n",
      "            torch._C.StringType\n",
      "            torch._C.TensorType\n",
      "            torch._C.TupleType\n",
      "        torch._C.Use\n",
      "        torch._C.Value\n",
      "        torch.jit.CompilationUnit\n",
      "        torch.jit.ScriptFunction\n",
      "    torch._C.BoolStorageBase(builtins.object)\n",
      "        BoolStorage(torch._C.BoolStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.ByteStorageBase(builtins.object)\n",
      "        ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CharStorageBase(builtins.object)\n",
      "        CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.DoubleStorageBase(builtins.object)\n",
      "        DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.FloatStorageBase(builtins.object)\n",
      "        FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.IntStorageBase(builtins.object)\n",
      "        IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.LoggerBase(pybind11_builtins.pybind11_object)\n",
      "        torch._C.LockingLogger\n",
      "        torch._C.NoopLogger\n",
      "    torch._C.LongStorageBase(builtins.object)\n",
      "        LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.ShortStorageBase(builtins.object)\n",
      "        ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "    torch._C._TensorBase(builtins.object)\n",
      "        Tensor\n",
      "    torch.autograd.grad_mode._DecoratorContextManager(builtins.object)\n",
      "        torch.autograd.grad_mode.enable_grad\n",
      "        torch.autograd.grad_mode.no_grad\n",
      "    torch.storage._StorageBase(builtins.object)\n",
      "        BoolStorage(torch._C.BoolStorageBase, torch.storage._StorageBase)\n",
      "        ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "        CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "        DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "        FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "        IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "        LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "        ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "    \n",
      "    class AggregationType(pybind11_builtins.pybind11_object)\n",
      "     |  Members:\n",
      "     |  \n",
      "     |  SUM\n",
      "     |  \n",
      "     |  AVG\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AggregationType\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: object, other: object) -> bool\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |      __getstate__(self: object) -> int\n",
      "     |  \n",
      "     |  __hash__(...)\n",
      "     |      __hash__(self: object) -> int\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |      __index__(self: torch._C.AggregationType) -> int\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.AggregationType, value: int) -> None\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |      __int__(self: torch._C.AggregationType) -> int\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      __ne__(self: object, other: object) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: object) -> str\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |      __setstate__(self: torch._C.AggregationType, state: int) -> None\n",
      "     |  \n",
      "     |  __str__ = name(...)\n",
      "     |      name(self: handle) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |  \n",
      "     |  name\n",
      "     |      name(self: handle) -> str\n",
      "     |  \n",
      "     |  value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AVG = <AggregationType.AVG: 1>\n",
      "     |  \n",
      "     |  SUM = <AggregationType.SUM: 0>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class AnyType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      AnyType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.AnyType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Argument(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Argument\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  has_default_value(...)\n",
      "     |      has_default_value(self: torch._C.Argument) -> bool_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  N\n",
      "     |  \n",
      "     |  default_value\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ArgumentSpec(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ArgumentSpec\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BenchmarkConfig(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      BenchmarkConfig\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.BenchmarkConfig) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  num_calling_threads\n",
      "     |  \n",
      "     |  num_iters\n",
      "     |  \n",
      "     |  num_warmup_iters\n",
      "     |  \n",
      "     |  num_worker_threads\n",
      "     |  \n",
      "     |  profiler_output_path\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BenchmarkExecutionStats(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      BenchmarkExecutionStats\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  latency_avg_ms\n",
      "     |  \n",
      "     |  num_iters\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Block(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Block\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  addInputToBlock(...)\n",
      "     |      addInputToBlock(self: torch._C.Block) -> torch._C.Value\n",
      "     |  \n",
      "     |  addNode(...)\n",
      "     |      addNode(self: torch._C.Block, arg0: str, arg1: List[torch._C.Value]) -> torch::jit::Node\n",
      "     |  \n",
      "     |  findAllNodes(...)\n",
      "     |      findAllNodes(self: torch._C.Block, kind: str, recurse: bool = True) -> List[torch::jit::Node]\n",
      "     |      \n",
      "     |      Find all nodes\n",
      "     |  \n",
      "     |  findNode(...)\n",
      "     |      findNode(self: torch._C.Block, kind: str, recurse: bool = True) -> torch::jit::Node\n",
      "     |      \n",
      "     |      Find Node\n",
      "     |  \n",
      "     |  inputs(...)\n",
      "     |      inputs(self: torch._C.Block) -> Iterator\n",
      "     |  \n",
      "     |  nodes(...)\n",
      "     |      nodes(self: torch._C.Block) -> Iterator\n",
      "     |  \n",
      "     |  outputs(...)\n",
      "     |      outputs(self: torch._C.Block) -> Iterator\n",
      "     |  \n",
      "     |  paramNode(...)\n",
      "     |      paramNode(self: torch._C.Block) -> torch::jit::Node\n",
      "     |  \n",
      "     |  registerOutput(...)\n",
      "     |      registerOutput(self: torch._C.Block, arg0: torch._C.Value) -> int\n",
      "     |  \n",
      "     |  returnNode(...)\n",
      "     |      returnNode(self: torch._C.Block) -> torch::jit::Node\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BoolStorage(torch._C.BoolStorageBase, torch.storage._StorageBase)\n",
      "     |  BoolStorage(*args, **kwargs)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BoolStorage\n",
      "     |      torch._C.BoolStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.BoolStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.BoolStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.BoolStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  get_device(self) -> int\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class BoolTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, normalized: bool = False, onesided: Union[bool, NoneType] = None, length: Union[int, NoneType] = None, return_complex: bool = False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Union[bool, NoneType] = None, return_complex: Union[bool, NoneType] = None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.bool\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class BoolType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      BoolType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.BoolType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BufferDict(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      BufferDict\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.BufferDict, arg0: torch._C.ScriptModule) -> None\n",
      "     |  \n",
      "     |  contains(...)\n",
      "     |      contains(self: torch._C.BufferDict, arg0: str) -> bool\n",
      "     |  \n",
      "     |  getattr(...)\n",
      "     |      getattr(self: torch._C.BufferDict, arg0: str) -> object\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      items(self: torch._C.BufferDict) -> List[Tuple[str, object]]\n",
      "     |  \n",
      "     |  setattr(...)\n",
      "     |      setattr(self: torch._C.BufferDict, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "     |  ByteStorage(*args, **kwargs)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ByteStorage\n",
      "     |      torch._C.ByteStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.ByteStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.ByteStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.ByteStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  get_device(self) -> int\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class ByteTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, normalized: bool = False, onesided: Union[bool, NoneType] = None, length: Union[int, NoneType] = None, return_complex: bool = False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Union[bool, NoneType] = None, return_complex: Union[bool, NoneType] = None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.uint8\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class CallStack(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      CallStack\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.CallStack, arg0: str, arg1: torch._C._jit_tree_views.SourceRange) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Capsule(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Capsule\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "     |  CharStorage(*args, **kwargs)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CharStorage\n",
      "     |      torch._C.CharStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CharStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CharStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CharStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  get_device(self) -> int\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class CharTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, normalized: bool = False, onesided: Union[bool, NoneType] = None, length: Union[int, NoneType] = None, return_complex: bool = False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Union[bool, NoneType] = None, return_complex: Union[bool, NoneType] = None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int8\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class ClassType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      ClassType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ClassType, arg0: str) -> None\n",
      "     |  \n",
      "     |  name(...)\n",
      "     |      name(self: torch._C.ClassType) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Code(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Code\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  grad_executor_states(...)\n",
      "     |      grad_executor_states(self: torch._C.Code) -> List[torch::jit::GraphExecutorState]\n",
      "     |  \n",
      "     |  num_bailouts(...)\n",
      "     |      num_bailouts(self: torch._C.Code) -> int\n",
      "     |  \n",
      "     |  request_bailout(...)\n",
      "     |      request_bailout(self: torch._C.Code, arg0: int) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class CompilationUnit(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      CompilationUnit\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getattr__(...)\n",
      "     |      __getattr__(self: torch._C.CompilationUnit, arg0: str) -> torch::jit::StrongFunctionPtr\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.CompilationUnit, lang: str = '', _frames_up: int = 0) -> None\n",
      "     |  \n",
      "     |  create_function(...)\n",
      "     |      create_function(self: torch._C.CompilationUnit, qualified_name: str, graph: torch._C.Graph, should_mangle: bool = False) -> torch::jit::StrongFunctionPtr\n",
      "     |  \n",
      "     |  define(...)\n",
      "     |      define(self: torch._C.CompilationUnit, src: str, rcb: Callable[[str], object] = None, _frames_up: int = 0) -> None\n",
      "     |  \n",
      "     |  find_function(...)\n",
      "     |      find_function(self: torch._C.CompilationUnit, arg0: str) -> Optional[torch::jit::StrongFunctionPtr]\n",
      "     |  \n",
      "     |  get_functions(...)\n",
      "     |      get_functions(self: torch._C.CompilationUnit) -> List[torch::jit::StrongFunctionPtr]\n",
      "     |  \n",
      "     |  get_interface(...)\n",
      "     |      get_interface(self: torch._C.CompilationUnit, arg0: str) -> torch._C.InterfaceType\n",
      "     |  \n",
      "     |  set_optimized(...)\n",
      "     |      set_optimized(self: torch._C.CompilationUnit, arg0: bool) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class CompleteArgumentSpec(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      CompleteArgumentSpec\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.CompleteArgumentSpec) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ComplexType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      ComplexType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.ComplexType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ConcreteModuleType(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ConcreteModuleType\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      dump(self: torch._C.ConcreteModuleType) -> None\n",
      "     |  \n",
      "     |  equals(...)\n",
      "     |      equals(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. equals(self: torch._C.ConcreteModuleType, arg0: torch._C.ConcreteModuleType) -> bool\n",
      "     |      \n",
      "     |      2. equals(self: torch._C.ConcreteModuleType, arg0: torch._C.ConcreteModuleTypeBuilder) -> bool\n",
      "     |  \n",
      "     |  get_attributes(...)\n",
      "     |      get_attributes(self: torch._C.ConcreteModuleType) -> Dict[str, Tuple[torch._C.Type, bool]]\n",
      "     |  \n",
      "     |  get_constants(...)\n",
      "     |      get_constants(self: torch._C.ConcreteModuleType) -> Dict[str, object]\n",
      "     |  \n",
      "     |  get_modules(...)\n",
      "     |      get_modules(self: torch._C.ConcreteModuleType) -> List[Tuple[str, torch._C.ConcreteModuleType]]\n",
      "     |  \n",
      "     |  is_ignored_attribute(...)\n",
      "     |      is_ignored_attribute(self: torch._C.ConcreteModuleType, arg0: str) -> bool\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_jit_type(...) from builtins.PyCapsule\n",
      "     |      from_jit_type(arg0: torch._C.Type) -> torch._C.ConcreteModuleType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  jit_type\n",
      "     |  \n",
      "     |  py_class\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ConcreteModuleTypeBuilder(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ConcreteModuleTypeBuilder\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ConcreteModuleTypeBuilder, arg0: object) -> None\n",
      "     |  \n",
      "     |  add_attribute(...)\n",
      "     |      add_attribute(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: torch._C.Type, arg2: bool, arg3: bool) -> None\n",
      "     |  \n",
      "     |  add_builtin_function(...)\n",
      "     |      add_builtin_function(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: str) -> None\n",
      "     |  \n",
      "     |  add_constant(...)\n",
      "     |      add_constant(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  add_failed_attribute(...)\n",
      "     |      add_failed_attribute(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: str) -> None\n",
      "     |  \n",
      "     |  add_forward_hook(...)\n",
      "     |      add_forward_hook(self: torch._C.ConcreteModuleTypeBuilder, arg0: object) -> None\n",
      "     |  \n",
      "     |  add_forward_pre_hook(...)\n",
      "     |      add_forward_pre_hook(self: torch._C.ConcreteModuleTypeBuilder, arg0: object) -> None\n",
      "     |  \n",
      "     |  add_function_attribute(...)\n",
      "     |      add_function_attribute(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: torch._C.Type, arg2: object) -> None\n",
      "     |  \n",
      "     |  add_ignored_attribute(...)\n",
      "     |      add_ignored_attribute(self: torch._C.ConcreteModuleTypeBuilder, arg0: str) -> None\n",
      "     |  \n",
      "     |  add_ignored_attributes(...)\n",
      "     |      add_ignored_attributes(self: torch._C.ConcreteModuleTypeBuilder, arg0: List[str]) -> None\n",
      "     |  \n",
      "     |  add_module(...)\n",
      "     |      add_module(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: torch::jit::ConcreteModuleType) -> None\n",
      "     |  \n",
      "     |  add_overload(...)\n",
      "     |      add_overload(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: List[str]) -> None\n",
      "     |  \n",
      "     |  build(...)\n",
      "     |      build(self: torch._C.ConcreteModuleTypeBuilder) -> torch::jit::ConcreteModuleType\n",
      "     |  \n",
      "     |  equals(...)\n",
      "     |      equals(self: torch._C.ConcreteModuleTypeBuilder, arg0: torch._C.ConcreteModuleTypeBuilder) -> bool\n",
      "     |  \n",
      "     |  set_module_dict(...)\n",
      "     |      set_module_dict(self: torch._C.ConcreteModuleTypeBuilder) -> None\n",
      "     |  \n",
      "     |  set_module_list(...)\n",
      "     |      set_module_list(self: torch._C.ConcreteModuleTypeBuilder) -> None\n",
      "     |  \n",
      "     |  set_poisoned(...)\n",
      "     |      set_poisoned(self: torch._C.ConcreteModuleTypeBuilder) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class DeepCopyMemoTable(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      DeepCopyMemoTable\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class DeviceObjType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      DeviceObjType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.DeviceObjType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class DictType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      DictType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.DictType, arg0: torch._C.Type, arg1: torch._C.Type) -> None\n",
      "     |  \n",
      "     |  getKeyType(...)\n",
      "     |      getKeyType(self: torch._C.DictType) -> torch._C.Type\n",
      "     |  \n",
      "     |  getValueType(...)\n",
      "     |      getValueType(self: torch._C.DictType) -> torch._C.Type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class DisableTorchFunction(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(...)\n",
      "     |  \n",
      "     |  __exit__(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "     |  DoubleStorage(*args, **kwargs)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DoubleStorage\n",
      "     |      torch._C.DoubleStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.DoubleStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.DoubleStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.DoubleStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  get_device(self) -> int\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class DoubleTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, normalized: bool = False, onesided: Union[bool, NoneType] = None, length: Union[int, NoneType] = None, return_complex: bool = False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Union[bool, NoneType] = None, return_complex: Union[bool, NoneType] = None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.float64\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class EnumType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      EnumType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.EnumType, arg0: str, arg1: torch._C.Type, arg2: List[object]) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ErrorReport(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ErrorReport\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ErrorReport, arg0: torch._C._jit_tree_views.SourceRange) -> None\n",
      "     |  \n",
      "     |  what(...)\n",
      "     |      what(self: torch._C.ErrorReport) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  call_stack(...) from builtins.PyCapsule\n",
      "     |      call_stack() -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ExecutionPlan(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ExecutionPlan\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FatalError(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FatalError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class FileCheck(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      FileCheck\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.FileCheck) -> None\n",
      "     |  \n",
      "     |  check(...)\n",
      "     |      check(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_count(...)\n",
      "     |      check_count(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. check_count(self: torch._C.FileCheck, arg0: str, arg1: int, arg2: bool) -> torch._C.FileCheck\n",
      "     |      \n",
      "     |      2. check_count(self: torch._C.FileCheck, str: str, count: int, exactly: bool = False) -> torch._C.FileCheck\n",
      "     |      \n",
      "     |      Check Count\n",
      "     |  \n",
      "     |  check_dag(...)\n",
      "     |      check_dag(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_next(...)\n",
      "     |      check_next(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_not(...)\n",
      "     |      check_not(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_same(...)\n",
      "     |      check_same(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_source_highlighted(...)\n",
      "     |      check_source_highlighted(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  run(...)\n",
      "     |      run(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. run(self: torch._C.FileCheck, arg0: str) -> None\n",
      "     |      \n",
      "     |      2. run(self: torch._C.FileCheck, arg0: torch._C.Graph) -> None\n",
      "     |      \n",
      "     |      3. run(self: torch._C.FileCheck, checks_file: str, test_file: str) -> None\n",
      "     |      \n",
      "     |      Run\n",
      "     |      \n",
      "     |      4. run(self: torch._C.FileCheck, checks_file: str, graph: torch._C.Graph) -> None\n",
      "     |      \n",
      "     |      Run\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "     |  FloatStorage(*args, **kwargs)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FloatStorage\n",
      "     |      torch._C.FloatStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.FloatStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.FloatStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.FloatStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  get_device(self) -> int\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class FloatTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, normalized: bool = False, onesided: Union[bool, NoneType] = None, length: Union[int, NoneType] = None, return_complex: bool = False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Union[bool, NoneType] = None, return_complex: Union[bool, NoneType] = None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.float32\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class FloatType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      FloatType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.FloatType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FunctionSchema(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      FunctionSchema\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.FunctionSchema, arg0: torch._C.FunctionSchema) -> bool\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: torch._C.FunctionSchema) -> str\n",
      "     |  \n",
      "     |  is_backward_compatible_with(...)\n",
      "     |      is_backward_compatible_with(self: torch._C.FunctionSchema, arg0: torch._C.FunctionSchema) -> bool\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  arguments\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  overload_name\n",
      "     |  \n",
      "     |  returns\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Future(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Future\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |      __getstate__(self: torch._C.Future) -> tuple\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.Future) -> None\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |      __setstate__(self: torch._C.Future, arg0: tuple) -> None\n",
      "     |  \n",
      "     |  add_done_callback(...)\n",
      "     |      add_done_callback(self: torch._C.Future, arg0: function) -> None\n",
      "     |  \n",
      "     |  done(...)\n",
      "     |      done(self: torch._C.Future) -> bool\n",
      "     |  \n",
      "     |  set_result(...)\n",
      "     |      set_result(self: torch._C.Future, arg0: object) -> None\n",
      "     |  \n",
      "     |  then(...)\n",
      "     |      then(self: torch._C.Future, arg0: function) -> torch._C.Future\n",
      "     |  \n",
      "     |  value(...)\n",
      "     |      value(self: torch._C.Future) -> object\n",
      "     |  \n",
      "     |  wait(...)\n",
      "     |      wait(self: torch._C.Future) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FutureType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      FutureType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.FutureType, arg0: torch._C.Type) -> None\n",
      "     |  \n",
      "     |  getElementType(...)\n",
      "     |      getElementType(self: torch._C.FutureType) -> torch._C.Type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Generator(builtins.object)\n",
      "     |  Generator(device='cpu') -> Generator\n",
      "     |  \n",
      "     |  Creates and returns a generator object that manages the state of the algorithm which\n",
      "     |  produces pseudo random numbers. Used as a keyword argument in many :ref:`inplace-random-sampling`\n",
      "     |  functions.\n",
      "     |  \n",
      "     |  Arguments:\n",
      "     |      device (:class:`torch.device`, optional): the desired device for the generator.\n",
      "     |  \n",
      "     |  Returns:\n",
      "     |      Generator: An torch.Generator object.\n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> g_cpu = torch.Generator()\n",
      "     |      >>> g_cuda = torch.Generator(device='cuda')\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  get_state(...)\n",
      "     |      Generator.get_state() -> Tensor\n",
      "     |      \n",
      "     |      Returns the Generator state as a ``torch.ByteTensor``.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Tensor: A ``torch.ByteTensor`` which contains all the necessary bits\n",
      "     |          to restore a Generator to a specific point in time.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu.get_state()\n",
      "     |  \n",
      "     |  initial_seed(...)\n",
      "     |      Generator.initial_seed() -> int\n",
      "     |      \n",
      "     |      Returns the initial seed for generating random numbers.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu.initial_seed()\n",
      "     |          2147483647\n",
      "     |  \n",
      "     |  manual_seed(...)\n",
      "     |      Generator.manual_seed(seed) -> Generator\n",
      "     |      \n",
      "     |      Sets the seed for generating random numbers. Returns a `torch.Generator` object.\n",
      "     |      It is recommended to set a large seed, i.e. a number that has a good balance of 0\n",
      "     |      and 1 bits. Avoid having many 0 bits in the seed.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          seed (int): The desired seed. Value must be within the inclusive range\n",
      "     |              `[-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]`. Otherwise, a RuntimeError\n",
      "     |              is raised. Negative inputs are remapped to positive values with the formula\n",
      "     |              `0xffff_ffff_ffff_ffff + seed`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Generator: An torch.Generator object.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu.manual_seed(2147483647)\n",
      "     |  \n",
      "     |  seed(...)\n",
      "     |      Generator.seed() -> int\n",
      "     |      \n",
      "     |      Gets a non-deterministic random number from std::random_device or the current\n",
      "     |      time and uses it to seed a Generator.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu.seed()\n",
      "     |          1516516984916\n",
      "     |  \n",
      "     |  set_state(...)\n",
      "     |      Generator.set_state(new_state) -> void\n",
      "     |      \n",
      "     |      Sets the Generator state.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          new_state (torch.ByteTensor): The desired state.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu_other = torch.Generator()\n",
      "     |          >>> g_cpu.set_state(g_cpu_other.get_state())\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  device\n",
      "     |      Generator.device -> device\n",
      "     |      \n",
      "     |      Gets the current device of the generator.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu.device\n",
      "     |          device(type='cpu')\n",
      "    \n",
      "    class Gradient(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Gradient\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  df\n",
      "     |  \n",
      "     |  df_input_captured_inputs\n",
      "     |  \n",
      "     |  df_input_captured_outputs\n",
      "     |  \n",
      "     |  df_input_vjps\n",
      "     |  \n",
      "     |  df_output_vjps\n",
      "     |  \n",
      "     |  f\n",
      "     |  \n",
      "     |  f_real_outputs\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Graph(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Graph\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Graph) -> str\n",
      "     |  \n",
      "     |  addInput(...)\n",
      "     |      addInput(self: torch._C.Graph) -> torch::jit::Value\n",
      "     |  \n",
      "     |  appendNode(...)\n",
      "     |      appendNode(self: torch._C.Graph, arg0: torch::jit::Node) -> torch::jit::Node\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      copy(self: torch._C.Graph) -> torch._C.Graph\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. create(self: torch._C.Graph, arg0: str) -> torch::jit::Node\n",
      "     |      \n",
      "     |      2. create(self: torch._C.Graph, arg0: str, arg1: int) -> torch::jit::Node\n",
      "     |      \n",
      "     |      3. create(self: torch._C.Graph, arg0: str, arg1: List[torch::jit::Value]) -> torch::jit::Node\n",
      "     |      \n",
      "     |      4. create(self: torch._C.Graph, arg0: str, arg1: List[torch::jit::Value], arg2: int) -> torch::jit::Node\n",
      "     |  \n",
      "     |  createClone(...)\n",
      "     |      createClone(self: torch._C.Graph, arg0: torch::jit::Node, arg1: object) -> torch::jit::Node\n",
      "     |  \n",
      "     |  createCudaFusionGroup(...)\n",
      "     |      createCudaFusionGroup(self: torch._C.Graph) -> torch::jit::Node\n",
      "     |  \n",
      "     |  createFusionGroup(...)\n",
      "     |      createFusionGroup(self: torch._C.Graph) -> torch::jit::Node\n",
      "     |  \n",
      "     |  dump_alias_db(...)\n",
      "     |      dump_alias_db(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  eraseInput(...)\n",
      "     |      eraseInput(self: torch._C.Graph, arg0: int) -> None\n",
      "     |  \n",
      "     |  findAllNodes(...)\n",
      "     |      findAllNodes(self: torch._C.Graph, kind: str, recurse: bool = True) -> List[torch::jit::Node]\n",
      "     |      \n",
      "     |      Find all nodes\n",
      "     |  \n",
      "     |  findNode(...)\n",
      "     |      findNode(self: torch._C.Graph, kind: str, recurse: bool = True) -> torch::jit::Node\n",
      "     |      \n",
      "     |      Find Node\n",
      "     |  \n",
      "     |  inputs(...)\n",
      "     |      inputs(self: torch._C.Graph) -> Iterator\n",
      "     |  \n",
      "     |  insertConstant(...)\n",
      "     |      insertConstant(self: torch._C.Graph, arg0: IValue) -> torch::jit::Value\n",
      "     |  \n",
      "     |  insertNode(...)\n",
      "     |      insertNode(self: torch._C.Graph, arg0: torch::jit::Node) -> torch::jit::Node\n",
      "     |  \n",
      "     |  lint(...)\n",
      "     |      lint(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  nodes(...)\n",
      "     |      nodes(self: torch._C.Graph) -> Iterator\n",
      "     |  \n",
      "     |  outputs(...)\n",
      "     |      outputs(self: torch._C.Graph) -> Iterator\n",
      "     |  \n",
      "     |  param_node(...)\n",
      "     |      param_node(self: torch._C.Graph) -> torch::jit::Node\n",
      "     |  \n",
      "     |  prependNode(...)\n",
      "     |      prependNode(self: torch._C.Graph, arg0: torch::jit::Node) -> torch::jit::Node\n",
      "     |  \n",
      "     |  registerOutput(...)\n",
      "     |      registerOutput(self: torch._C.Graph, arg0: torch::jit::Value) -> int\n",
      "     |  \n",
      "     |  return_node(...)\n",
      "     |      return_node(self: torch._C.Graph) -> torch::jit::Node\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Graph, print_source_ranges: bool = True) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class GraphExecutorState(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      GraphExecutorState\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  execution_plans\n",
      "     |  \n",
      "     |  fallback\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class IODescriptor(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      IODescriptor\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class InferredType(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      InferredType\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. __init__(self: torch._C.InferredType, arg0: torch._C.Type) -> None\n",
      "     |      \n",
      "     |      2. __init__(self: torch._C.InferredType, arg0: str) -> None\n",
      "     |  \n",
      "     |  reason(...)\n",
      "     |      reason(self: torch._C.InferredType) -> str\n",
      "     |  \n",
      "     |  success(...)\n",
      "     |      success(self: torch._C.InferredType) -> bool\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(self: torch._C.InferredType) -> torch._C.Type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "     |  IntStorage(*args, **kwargs)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IntStorage\n",
      "     |      torch._C.IntStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.IntStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.IntStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.IntStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  get_device(self) -> int\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class IntTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, normalized: bool = False, onesided: Union[bool, NoneType] = None, length: Union[int, NoneType] = None, return_complex: bool = False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Union[bool, NoneType] = None, return_complex: Union[bool, NoneType] = None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int32\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class IntType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      IntType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.IntType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class InterfaceType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      InterfaceType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.InterfaceType, arg0: str) -> None\n",
      "     |  \n",
      "     |  getMethod(...)\n",
      "     |      getMethod(self: torch._C.InterfaceType, arg0: str) -> torch._C.FunctionSchema\n",
      "     |  \n",
      "     |  getMethodNames(...)\n",
      "     |      getMethodNames(self: torch._C.InterfaceType) -> List[str]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    JITException = class Error(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Error\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class ListType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      ListType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ListType, arg0: torch._C.Type) -> None\n",
      "     |  \n",
      "     |  getElementType(...)\n",
      "     |      getElementType(self: torch._C.ListType) -> torch._C.Type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  ofBools(...) from builtins.PyCapsule\n",
      "     |      ofBools() -> torch._C.ListType\n",
      "     |  \n",
      "     |  ofComplexDoubles(...) from builtins.PyCapsule\n",
      "     |      ofComplexDoubles() -> torch._C.ListType\n",
      "     |  \n",
      "     |  ofFloats(...) from builtins.PyCapsule\n",
      "     |      ofFloats() -> torch._C.ListType\n",
      "     |  \n",
      "     |  ofInts(...) from builtins.PyCapsule\n",
      "     |      ofInts() -> torch._C.ListType\n",
      "     |  \n",
      "     |  ofTensors(...) from builtins.PyCapsule\n",
      "     |      ofTensors() -> torch._C.ListType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class LiteScriptModule(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      LiteScriptModule\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.LiteScriptModule, arg0: c10::ivalue::Object, arg1: torch::jit::mobile::CompilationUnit) -> None\n",
      "     |  \n",
      "     |  find_method(...)\n",
      "     |      find_method(self: torch._C.LiteScriptModule, method_name: str) -> bool\n",
      "     |  \n",
      "     |  forward(...)\n",
      "     |      forward(self: torch._C.LiteScriptModule, input_tuple: tuple) -> IValue\n",
      "     |  \n",
      "     |  run_method(...)\n",
      "     |      run_method(self: torch._C.LiteScriptModule, method_name: str, input_tuple: tuple) -> IValue\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class LockingLogger(LoggerBase)\n",
      "     |  Method resolution order:\n",
      "     |      LockingLogger\n",
      "     |      LoggerBase\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.LockingLogger) -> None\n",
      "     |  \n",
      "     |  get_counter_val(...)\n",
      "     |      get_counter_val(self: torch._C.LockingLogger, arg0: str) -> int\n",
      "     |  \n",
      "     |  set_aggregation_type(...)\n",
      "     |      set_aggregation_type(self: torch._C.LockingLogger, arg0: str, arg1: torch._C.AggregationType) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "     |  LongStorage(*args, **kwargs)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LongStorage\n",
      "     |      torch._C.LongStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.LongStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.LongStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.LongStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  get_device(self) -> int\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class LongTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, normalized: bool = False, onesided: Union[bool, NoneType] = None, length: Union[int, NoneType] = None, return_complex: bool = False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Union[bool, NoneType] = None, return_complex: Union[bool, NoneType] = None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int64\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class MobileOptimizerType(pybind11_builtins.pybind11_object)\n",
      "     |  Members:\n",
      "     |  \n",
      "     |  CONV_BN_FUSION\n",
      "     |  \n",
      "     |  INSERT_FOLD_PREPACK_OPS\n",
      "     |  \n",
      "     |  REMOVE_DROPOUT\n",
      "     |  \n",
      "     |  FUSE_ADD_RELU\n",
      "     |  \n",
      "     |  HOIST_CONV_PACKED_PARAMS\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MobileOptimizerType\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: object, other: object) -> bool\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |      __getstate__(self: object) -> int\n",
      "     |  \n",
      "     |  __hash__(...)\n",
      "     |      __hash__(self: object) -> int\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |      __index__(self: torch._C.MobileOptimizerType) -> int\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.MobileOptimizerType, value: int) -> None\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |      __int__(self: torch._C.MobileOptimizerType) -> int\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      __ne__(self: object, other: object) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: object) -> str\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |      __setstate__(self: torch._C.MobileOptimizerType, state: int) -> None\n",
      "     |  \n",
      "     |  __str__ = name(...)\n",
      "     |      name(self: handle) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |  \n",
      "     |  name\n",
      "     |      name(self: handle) -> str\n",
      "     |  \n",
      "     |  value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CONV_BN_FUSION = <MobileOptimizerType.CONV_BN_FUSION: 0>\n",
      "     |  \n",
      "     |  FUSE_ADD_RELU = <MobileOptimizerType.FUSE_ADD_RELU: 3>\n",
      "     |  \n",
      "     |  HOIST_CONV_PACKED_PARAMS = <MobileOptimizerType.HOIST_CONV_PACKED_PARA...\n",
      "     |  \n",
      "     |  INSERT_FOLD_PREPACK_OPS = <MobileOptimizerType.INSERT_FOLD_PREPACK_OPS...\n",
      "     |  \n",
      "     |  REMOVE_DROPOUT = <MobileOptimizerType.REMOVE_DROPOUT: 2>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ModuleDict(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ModuleDict\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ModuleDict, arg0: torch._C.ScriptModule) -> None\n",
      "     |  \n",
      "     |  contains(...)\n",
      "     |      contains(self: torch._C.ModuleDict, arg0: str) -> bool\n",
      "     |  \n",
      "     |  getattr(...)\n",
      "     |      getattr(self: torch._C.ModuleDict, arg0: str) -> object\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      items(self: torch._C.ModuleDict) -> List[Tuple[str, object]]\n",
      "     |  \n",
      "     |  setattr(...)\n",
      "     |      setattr(self: torch._C.ModuleDict, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Node(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Node\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  addBlock(...)\n",
      "     |      addBlock(self: torch._C.Node) -> torch._C.Block\n",
      "     |  \n",
      "     |  addInput(...)\n",
      "     |      addInput(self: torch._C.Node, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  addOutput(...)\n",
      "     |      addOutput(self: torch._C.Node) -> torch._C.Value\n",
      "     |  \n",
      "     |  attributeNames(...)\n",
      "     |      attributeNames(self: torch._C.Node) -> List[str]\n",
      "     |  \n",
      "     |  blocks(...)\n",
      "     |      blocks(self: torch._C.Node) -> Iterator\n",
      "     |  \n",
      "     |  cconv(...)\n",
      "     |      cconv(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  copyAttributes(...)\n",
      "     |      copyAttributes(self: torch._C.Node, arg0: torch._C.Node) -> torch._C.Node\n",
      "     |  \n",
      "     |  destroy(...)\n",
      "     |      destroy(self: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  eraseOutput(...)\n",
      "     |      eraseOutput(self: torch._C.Node, arg0: int) -> None\n",
      "     |  \n",
      "     |  f(...)\n",
      "     |      f(self: torch._C.Node, arg0: str) -> float\n",
      "     |  \n",
      "     |  f_(...)\n",
      "     |      f_(self: torch._C.Node, arg0: str, arg1: float) -> torch._C.Node\n",
      "     |  \n",
      "     |  findAllNodes(...)\n",
      "     |      findAllNodes(self: torch._C.Node, kind: str, recurse: bool = True) -> List[torch._C.Node]\n",
      "     |      \n",
      "     |      Find all nodes\n",
      "     |  \n",
      "     |  findNode(...)\n",
      "     |      findNode(self: torch._C.Node, kind: str, recurse: bool = True) -> torch._C.Node\n",
      "     |      \n",
      "     |      Find Node\n",
      "     |  \n",
      "     |  fs(...)\n",
      "     |      fs(self: torch._C.Node, arg0: str) -> List[float]\n",
      "     |  \n",
      "     |  fs_(...)\n",
      "     |      fs_(self: torch._C.Node, arg0: str, arg1: List[float]) -> torch._C.Node\n",
      "     |  \n",
      "     |  g(...)\n",
      "     |      g(self: torch._C.Node, arg0: str) -> torch._C.Graph\n",
      "     |  \n",
      "     |  g_(...)\n",
      "     |      g_(self: torch._C.Node, arg0: str, arg1: torch._C.Graph) -> torch._C.Node\n",
      "     |  \n",
      "     |  gs(...)\n",
      "     |      gs(self: torch._C.Node, arg0: str) -> List[torch._C.Graph]\n",
      "     |  \n",
      "     |  gs_(...)\n",
      "     |      gs_(self: torch._C.Node, arg0: str, arg1: List[torch._C.Graph]) -> torch._C.Node\n",
      "     |  \n",
      "     |  hasAttribute(...)\n",
      "     |      hasAttribute(self: torch._C.Node, arg0: str) -> bool\n",
      "     |  \n",
      "     |  hasAttributes(...)\n",
      "     |      hasAttributes(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  hasMultipleOutputs(...)\n",
      "     |      hasMultipleOutputs(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  hasUses(...)\n",
      "     |      hasUses(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  i(...)\n",
      "     |      i(self: torch._C.Node, arg0: str) -> int\n",
      "     |  \n",
      "     |  i_(...)\n",
      "     |      i_(self: torch._C.Node, arg0: str, arg1: int) -> torch._C.Node\n",
      "     |  \n",
      "     |  input(...)\n",
      "     |      input(self: torch._C.Node) -> torch._C.Value\n",
      "     |  \n",
      "     |  inputs(...)\n",
      "     |      inputs(self: torch._C.Node) -> Iterator\n",
      "     |  \n",
      "     |  inputsAt(...)\n",
      "     |      inputsAt(self: torch._C.Node, arg0: int) -> torch._C.Value\n",
      "     |  \n",
      "     |  inputsSize(...)\n",
      "     |      inputsSize(self: torch._C.Node) -> int\n",
      "     |  \n",
      "     |  insertAfter(...)\n",
      "     |      insertAfter(self: torch._C.Node, arg0: torch._C.Node) -> torch._C.Node\n",
      "     |  \n",
      "     |  insertBefore(...)\n",
      "     |      insertBefore(self: torch._C.Node, arg0: torch._C.Node) -> torch._C.Node\n",
      "     |  \n",
      "     |  is(...)\n",
      "     |      is(self: torch._C.Node, arg0: str) -> List[int]\n",
      "     |  \n",
      "     |  isAfter(...)\n",
      "     |      isAfter(self: torch._C.Node, arg0: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  isBefore(...)\n",
      "     |      isBefore(self: torch._C.Node, arg0: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  isNondeterministic(...)\n",
      "     |      isNondeterministic(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  is_(...)\n",
      "     |      is_(self: torch._C.Node, arg0: str, arg1: List[int]) -> torch._C.Node\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Node) -> Symbol\n",
      "     |  \n",
      "     |  kindOf(...)\n",
      "     |      kindOf(self: torch._C.Node, arg0: str) -> AttributeKind\n",
      "     |  \n",
      "     |  moveAfter(...)\n",
      "     |      moveAfter(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  moveBefore(...)\n",
      "     |      moveBefore(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  mustBeNone(...)\n",
      "     |      mustBeNone(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  output(...)\n",
      "     |      output(self: torch._C.Node) -> torch._C.Value\n",
      "     |  \n",
      "     |  outputs(...)\n",
      "     |      outputs(self: torch._C.Node) -> Iterator\n",
      "     |  \n",
      "     |  outputsAt(...)\n",
      "     |      outputsAt(self: torch._C.Node, arg0: int) -> torch._C.Value\n",
      "     |  \n",
      "     |  outputsSize(...)\n",
      "     |      outputsSize(self: torch._C.Node) -> int\n",
      "     |  \n",
      "     |  pyname(...)\n",
      "     |      pyname(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  pyobj(...)\n",
      "     |      pyobj(self: torch._C.Node) -> object\n",
      "     |  \n",
      "     |  removeAllInputs(...)\n",
      "     |      removeAllInputs(self: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  removeAttribute(...)\n",
      "     |      removeAttribute(self: torch._C.Node, arg0: str) -> torch._C.Node\n",
      "     |  \n",
      "     |  removeInput(...)\n",
      "     |      removeInput(self: torch._C.Node, arg0: int) -> None\n",
      "     |  \n",
      "     |  replaceAllUsesWith(...)\n",
      "     |      replaceAllUsesWith(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  replaceInput(...)\n",
      "     |      replaceInput(self: torch._C.Node, arg0: int, arg1: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  replaceInputWith(...)\n",
      "     |      replaceInputWith(self: torch._C.Node, arg0: torch._C.Value, arg1: torch._C.Value) -> None\n",
      "     |  \n",
      "     |  s(...)\n",
      "     |      s(self: torch._C.Node, arg0: str) -> str\n",
      "     |  \n",
      "     |  s_(...)\n",
      "     |      s_(self: torch._C.Node, arg0: str, arg1: str) -> torch._C.Node\n",
      "     |  \n",
      "     |  scalar_args(...)\n",
      "     |      scalar_args(self: torch._C.Node) -> list\n",
      "     |  \n",
      "     |  schema(...)\n",
      "     |      schema(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  scopeName(...)\n",
      "     |      scopeName(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  sourceRange(...)\n",
      "     |      sourceRange(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  ss(...)\n",
      "     |      ss(self: torch._C.Node, arg0: str) -> List[str]\n",
      "     |  \n",
      "     |  ss_(...)\n",
      "     |      ss_(self: torch._C.Node, arg0: str, arg1: List[str]) -> torch._C.Node\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t(self: torch._C.Node, arg0: str) -> at::Tensor\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_(self: torch._C.Node, arg0: str, arg1: at::Tensor) -> torch._C.Node\n",
      "     |  \n",
      "     |  ts(...)\n",
      "     |      ts(self: torch._C.Node, arg0: str) -> List[at::Tensor]\n",
      "     |  \n",
      "     |  ts_(...)\n",
      "     |      ts_(self: torch._C.Node, arg0: str, arg1: List[at::Tensor]) -> torch._C.Node\n",
      "     |  \n",
      "     |  z(...)\n",
      "     |      z(self: torch._C.Node, arg0: str) -> at::Tensor\n",
      "     |  \n",
      "     |  z_(...)\n",
      "     |      z_(self: torch._C.Node, arg0: str, arg1: at::Tensor) -> torch._C.Node\n",
      "     |  \n",
      "     |  zs(...)\n",
      "     |      zs(self: torch._C.Node, arg0: str) -> List[at::Tensor]\n",
      "     |  \n",
      "     |  zs_(...)\n",
      "     |      zs_(self: torch._C.Node, arg0: str, arg1: List[at::Tensor]) -> torch._C.Node\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class NoneType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      NoneType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.NoneType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class NoopLogger(LoggerBase)\n",
      "     |  Method resolution order:\n",
      "     |      NoopLogger\n",
      "     |      LoggerBase\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.NoopLogger) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class NumberType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      NumberType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.NumberType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class OptionalType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      OptionalType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.OptionalType, arg0: torch._C.Type) -> None\n",
      "     |  \n",
      "     |  getElementType(...)\n",
      "     |      getElementType(self: torch._C.OptionalType) -> torch._C.Type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  ofTensor(...) from builtins.PyCapsule\n",
      "     |      ofTensor() -> torch._C.OptionalType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ParameterDict(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ParameterDict\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ParameterDict, arg0: torch._C.ScriptModule) -> None\n",
      "     |  \n",
      "     |  contains(...)\n",
      "     |      contains(self: torch._C.ParameterDict, arg0: str) -> bool\n",
      "     |  \n",
      "     |  getattr(...)\n",
      "     |      getattr(self: torch._C.ParameterDict, arg0: str) -> object\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      items(self: torch._C.ParameterDict) -> List[Tuple[str, object]]\n",
      "     |  \n",
      "     |  setattr(...)\n",
      "     |      setattr(self: torch._C.ParameterDict, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class PyObjectType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      PyObjectType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.PyObjectType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class PyTorchFileReader(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      PyTorchFileReader\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. __init__(self: torch._C.PyTorchFileReader, arg0: str) -> None\n",
      "     |      \n",
      "     |      2. __init__(self: torch._C.PyTorchFileReader, arg0: object) -> None\n",
      "     |  \n",
      "     |  get_all_records(...)\n",
      "     |      get_all_records(self: torch._C.PyTorchFileReader) -> List[str]\n",
      "     |  \n",
      "     |  get_record(...)\n",
      "     |      get_record(self: torch._C.PyTorchFileReader, arg0: str) -> bytes\n",
      "     |  \n",
      "     |  get_storage_from_record(...)\n",
      "     |      get_storage_from_record(self: torch._C.PyTorchFileReader, arg0: str, arg1: int, arg2: object) -> at::Tensor\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class PyTorchFileWriter(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      PyTorchFileWriter\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. __init__(self: torch._C.PyTorchFileWriter, arg0: str) -> None\n",
      "     |      \n",
      "     |      2. __init__(self: torch._C.PyTorchFileWriter, arg0: object) -> None\n",
      "     |      \n",
      "     |      3. __init__(self: torch._C.PyTorchFileWriter, arg0: Callable[[capsule, int], int]) -> None\n",
      "     |  \n",
      "     |  write_end_of_file(...)\n",
      "     |      write_end_of_file(self: torch._C.PyTorchFileWriter) -> None\n",
      "     |  \n",
      "     |  write_record(...)\n",
      "     |      write_record(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. write_record(self: torch._C.PyTorchFileWriter, arg0: str, arg1: str, arg2: int) -> None\n",
      "     |      \n",
      "     |      2. write_record(self: torch._C.PyTorchFileWriter, arg0: str, arg1: int, arg2: int) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class RRefType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      RRefType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.RRefType, arg0: torch._C.Type) -> None\n",
      "     |  \n",
      "     |  getElementType(...)\n",
      "     |      getElementType(self: torch._C.RRefType) -> torch._C.Type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptClass(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ScriptClass\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(...)\n",
      "     |      __call__(self: torch._C.ScriptClass, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptFunction(pybind11_builtins.pybind11_object)\n",
      "     |  Functionally equivalent to a :class:`ScriptModule`, but represents a single\n",
      "     |  function and does not have any attributes or Parameters.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ScriptFunction\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(...)\n",
      "     |      __call__(*args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_debug_state(...)\n",
      "     |      get_debug_state(self: torch._C.ScriptFunction) -> torch._C.GraphExecutorState\n",
      "     |  \n",
      "     |  graph_for = _graph_for(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(self: torch._C.ScriptFunction, filename: str, _extra_files: Dict[str, str] = {}) -> None\n",
      "     |  \n",
      "     |  save_to_buffer(...)\n",
      "     |      save_to_buffer(self: torch._C.ScriptFunction, _extra_files: Dict[str, str] = {}) -> bytes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  inlined_graph\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  qualified_name\n",
      "     |  \n",
      "     |  schema\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptMethod(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ScriptMethod\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(...)\n",
      "     |      __call__(*args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  graph_for = _graph_for(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  code_with_constants\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  inlined_graph\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  schema\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptModule(ScriptObject)\n",
      "     |  Method resolution order:\n",
      "     |      ScriptModule\n",
      "     |      ScriptObject\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __copy__(...)\n",
      "     |      __copy__(self: torch._C.ScriptModule) -> torch._C.ScriptModule\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      __deepcopy__(self: torch._C.ScriptModule, arg0: dict) -> torch._C.ScriptModule\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ScriptModule, arg0: str, arg1: torch::jit::CompilationUnit, arg2: bool) -> None\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(self: torch._C.ScriptModule, arg0: Callable[[torch._C.ScriptModule], None]) -> None\n",
      "     |  \n",
      "     |  children(...)\n",
      "     |      children(self: torch._C.ScriptModule) -> torch::jit::slot_list_impl<torch::jit::detail::ModulePolicy>\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      dump(self: torch._C.ScriptModule, code: bool = True, attrs: bool = True, params: bool = True) -> None\n",
      "     |  \n",
      "     |  dump_to_str(...)\n",
      "     |      dump_to_str(self: torch._C.ScriptModule, code: bool = True, attrs: bool = True, params: bool = True, indent: int = 0) -> str\n",
      "     |  \n",
      "     |  get_debug_state(...)\n",
      "     |      get_debug_state(self: torch._C.ScriptModule) -> torch._C.GraphExecutorState\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(self: torch._C.ScriptModule, filename: str, _extra_files: Dict[str, str] = {}) -> None\n",
      "     |  \n",
      "     |  save_to_buffer(...)\n",
      "     |      save_to_buffer(self: torch._C.ScriptModule, _extra_files: Dict[str, str] = {}) -> bytes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  code_with_constants\n",
      "     |  \n",
      "     |  qualified_name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ScriptObject:\n",
      "     |  \n",
      "     |  __abs__(...)\n",
      "     |      __abs__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |      __add__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |      __and__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __concat__(...)\n",
      "     |      __concat__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __contains__(...)\n",
      "     |      __contains__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __delitem__(...)\n",
      "     |      __delitem__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __floordiv__(...)\n",
      "     |      __floordiv__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      __ge__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __getattr__(...)\n",
      "     |      __getattr__(self: torch._C.ScriptObject, arg0: str) -> object\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      __getitem__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |      __getstate__(self: torch._C.ScriptObject) -> Tuple[object, str]\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      __gt__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __hash__(...)\n",
      "     |      __hash__(self: torch._C.ScriptObject) -> int\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |      __iadd__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |      __iand__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __iconcat__(...)\n",
      "     |      __iconcat__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |      __ifloordiv__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |      __ilshift__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __imatmul__(...)\n",
      "     |      __imatmul__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |      __imod__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |      __imul__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |      __index__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __inv__(...)\n",
      "     |      __inv__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |      __invert__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |      __ior__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ipow__(...)\n",
      "     |      __ipow__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |      __irshift__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |      __isub__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __itruediv__(...)\n",
      "     |      __itruediv__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |      __ixor__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      __le__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __len__(...)\n",
      "     |      __len__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |      __lshift__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      __lt__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |      __matmul__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |      __mod__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |      __mul__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      __ne__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __neg__(...)\n",
      "     |      __neg__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __not__(...)\n",
      "     |      __not__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |      __or__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __pos__(...)\n",
      "     |      __pos__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __pow__(...)\n",
      "     |      __pow__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |      __rshift__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __setitem__(...)\n",
      "     |      __setitem__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |      __setstate__(self: torch._C.ScriptObject, arg0: Tuple[object, str]) -> None\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |      __sub__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |      __truediv__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |      __xor__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  getattr(...)\n",
      "     |      getattr(self: torch._C.ScriptObject, arg0: str) -> object\n",
      "     |  \n",
      "     |  hasattr(...)\n",
      "     |      hasattr(self: torch._C.ScriptObject, arg0: str) -> bool\n",
      "     |  \n",
      "     |  setattr(...)\n",
      "     |      setattr(self: torch._C.ScriptObject, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptObject(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ScriptObject\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__(...)\n",
      "     |      __abs__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |      __add__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |      __and__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __concat__(...)\n",
      "     |      __concat__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __contains__(...)\n",
      "     |      __contains__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __copy__(...)\n",
      "     |      __copy__(self: torch._C.ScriptObject) -> torch._C.ScriptObject\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      __deepcopy__(self: torch._C.ScriptObject, arg0: dict) -> torch._C.ScriptObject\n",
      "     |  \n",
      "     |  __delitem__(...)\n",
      "     |      __delitem__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __floordiv__(...)\n",
      "     |      __floordiv__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      __ge__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __getattr__(...)\n",
      "     |      __getattr__(self: torch._C.ScriptObject, arg0: str) -> object\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      __getitem__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |      __getstate__(self: torch._C.ScriptObject) -> Tuple[object, str]\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      __gt__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __hash__(...)\n",
      "     |      __hash__(self: torch._C.ScriptObject) -> int\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |      __iadd__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |      __iand__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __iconcat__(...)\n",
      "     |      __iconcat__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |      __ifloordiv__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |      __ilshift__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __imatmul__(...)\n",
      "     |      __imatmul__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |      __imod__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |      __imul__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |      __index__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __inv__(...)\n",
      "     |      __inv__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |      __invert__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |      __ior__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ipow__(...)\n",
      "     |      __ipow__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |      __irshift__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |      __isub__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __itruediv__(...)\n",
      "     |      __itruediv__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |      __ixor__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      __le__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __len__(...)\n",
      "     |      __len__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |      __lshift__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      __lt__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |      __matmul__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |      __mod__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |      __mul__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      __ne__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __neg__(...)\n",
      "     |      __neg__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __not__(...)\n",
      "     |      __not__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |      __or__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __pos__(...)\n",
      "     |      __pos__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __pow__(...)\n",
      "     |      __pow__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |      __rshift__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __setitem__(...)\n",
      "     |      __setitem__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |      __setstate__(self: torch._C.ScriptObject, arg0: Tuple[object, str]) -> None\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |      __sub__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |      __truediv__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |      __xor__(self: torch._C.ScriptObject, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  getattr(...)\n",
      "     |      getattr(self: torch._C.ScriptObject, arg0: str) -> object\n",
      "     |  \n",
      "     |  hasattr(...)\n",
      "     |      hasattr(self: torch._C.ScriptObject, arg0: str) -> bool\n",
      "     |  \n",
      "     |  setattr(...)\n",
      "     |      setattr(self: torch._C.ScriptObject, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "     |  ShortStorage(*args, **kwargs)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ShortStorage\n",
      "     |      torch._C.ShortStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.ShortStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.ShortStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.ShortStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  get_device(self) -> int\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class ShortTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, normalized: bool = False, onesided: Union[bool, NoneType] = None, length: Union[int, NoneType] = None, return_complex: bool = False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Union[bool, NoneType] = None, return_complex: Union[bool, NoneType] = None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int16\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class Size(builtins.tuple)\n",
      "     |  Size(iterable=(), /)\n",
      "     |  \n",
      "     |  Built-in immutable sequence.\n",
      "     |  \n",
      "     |  If no argument is given, the constructor returns an empty tuple.\n",
      "     |  If iterable is specified the tuple is initialized from iterable's items.\n",
      "     |  \n",
      "     |  If the argument is a tuple, the return value is the same object.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Size\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getnewargs__(self, /)\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class StaticRuntime(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      StaticRuntime\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  benchmark(...)\n",
      "     |      benchmark(self: torch._C.StaticRuntime, arg0: List[at::Tensor], arg1: Dict[str, at::Tensor], arg2: int, arg3: int) -> None\n",
      "     |  \n",
      "     |  benchmark_individual_ops(...)\n",
      "     |      benchmark_individual_ops(self: torch._C.StaticRuntime, arg0: List[at::Tensor], arg1: Dict[str, at::Tensor], arg2: int, arg3: int) -> torch._C.StaticRuntime.IndividualMetrics\n",
      "     |  \n",
      "     |  run(...)\n",
      "     |      run(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. run(self: torch._C.StaticRuntime, arg0: List[at::Tensor]) -> List[at::Tensor]\n",
      "     |      \n",
      "     |      2. run(self: torch._C.StaticRuntime, arg0: List[at::Tensor], arg1: Dict[str, at::Tensor]) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  IndividualMetrics = <class 'torch._C.StaticRuntime.IndividualMetrics'>\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Stream(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class StreamObjType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      StreamObjType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.StreamObjType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class StringType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      StringType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.StringType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Tensor(torch._C._TensorBase)\n",
      "     |  Method resolution order:\n",
      "     |      Tensor\n",
      "     |      torch._C._TensorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  istft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, normalized: bool = False, onesided: Union[bool, NoneType] = None, length: Union[int, NoneType] = None, return_complex: bool = False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  stft(self, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: 'Optional[Tensor]' = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Union[bool, NoneType] = None, return_complex: Union[bool, NoneType] = None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from builtins.type\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C._TensorBase:\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C._TensorBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C._TensorBase:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_cuda\n",
      "     |      Is ``True`` if the Tensor is stored on the GPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_sparse\n",
      "     |      Is ``True`` if the Tensor uses sparse storage layout, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  layout\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "    \n",
      "    class TensorType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      TensorType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.TensorType\n",
      "     |  \n",
      "     |  getInferred(...) from builtins.PyCapsule\n",
      "     |      getInferred() -> torch._C.TensorType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ThroughputBenchmark(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ThroughputBenchmark\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. __init__(self: torch._C.ThroughputBenchmark, arg0: torch._C.ScriptModule) -> None\n",
      "     |      \n",
      "     |      2. __init__(self: torch._C.ThroughputBenchmark, arg0: object) -> None\n",
      "     |  \n",
      "     |  add_input(...)\n",
      "     |      add_input(self: torch._C.ThroughputBenchmark, *args, **kwargs) -> None\n",
      "     |  \n",
      "     |  benchmark(...)\n",
      "     |      benchmark(self: torch._C.ThroughputBenchmark, arg0: torch._C.BenchmarkConfig) -> torch._C.BenchmarkExecutionStats\n",
      "     |  \n",
      "     |  run_once(...)\n",
      "     |      run_once(self: torch._C.ThroughputBenchmark, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class TracingState(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      TracingState\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.TracingState) -> str\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: torch._C.TracingState) -> str\n",
      "     |  \n",
      "     |  current_scope(...)\n",
      "     |      current_scope(self: torch._C.TracingState) -> str\n",
      "     |  \n",
      "     |  graph(...)\n",
      "     |      graph(self: torch._C.TracingState) -> torch._C.Graph\n",
      "     |  \n",
      "     |  pop_scope(...)\n",
      "     |      pop_scope(self: torch._C.TracingState) -> None\n",
      "     |  \n",
      "     |  push_scope(...)\n",
      "     |      push_scope(self: torch._C.TracingState, arg0: str) -> None\n",
      "     |  \n",
      "     |  set_graph(...)\n",
      "     |      set_graph(self: torch._C.TracingState, arg0: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class TupleType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      TupleType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.TupleType, arg0: List[torch._C.Type]) -> None\n",
      "     |  \n",
      "     |  elements(...)\n",
      "     |      elements(self: torch._C.TupleType) -> List[torch._C.Type]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Type:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Type(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  is_interface_type(...)\n",
      "     |      is_interface_type(self: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  undefined(...)\n",
      "     |      undefined(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  varyingSizes(...)\n",
      "     |      varyingSizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Use(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Use\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  isAfter(...)\n",
      "     |      isAfter(self: torch._C.Use, arg0: torch._C.Use) -> bool\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  offset\n",
      "     |  \n",
      "     |  user\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Value(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Value\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Value) -> str\n",
      "     |  \n",
      "     |  copyMetadata(...)\n",
      "     |      copyMetadata(self: torch._C.Value, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  debugName(...)\n",
      "     |      debugName(self: torch._C.Value) -> str\n",
      "     |  \n",
      "     |  inferTypeFrom(...)\n",
      "     |      inferTypeFrom(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. inferTypeFrom(self: torch._C.Value, arg0: at::Tensor) -> None\n",
      "     |      \n",
      "     |      2. inferTypeFrom(self: torch._C.Value, arg0: c10::ivalue::Object) -> None\n",
      "     |  \n",
      "     |  isCompleteTensor(...)\n",
      "     |      isCompleteTensor(self: torch._C.Value) -> bool\n",
      "     |  \n",
      "     |  node(...)\n",
      "     |      node(self: torch._C.Value) -> torch::jit::Node\n",
      "     |  \n",
      "     |  offset(...)\n",
      "     |      offset(self: torch._C.Value) -> int\n",
      "     |  \n",
      "     |  replaceAllUsesAfterNodeWith(...)\n",
      "     |      replaceAllUsesAfterNodeWith(self: torch._C.Value, arg0: torch::jit::Node, arg1: torch._C.Value) -> None\n",
      "     |  \n",
      "     |  replaceAllUsesWith(...)\n",
      "     |      replaceAllUsesWith(self: torch._C.Value, arg0: torch._C.Value) -> None\n",
      "     |  \n",
      "     |  requiresGrad(...)\n",
      "     |      requiresGrad(self: torch._C.Value) -> None\n",
      "     |  \n",
      "     |  requires_grad(...)\n",
      "     |      requires_grad(self: torch._C.Value) -> bool\n",
      "     |  \n",
      "     |  setDebugName(...)\n",
      "     |      setDebugName(self: torch._C.Value, arg0: str) -> torch._C.Value\n",
      "     |  \n",
      "     |  setType(...)\n",
      "     |      setType(self: torch._C.Value, arg0: c10::Type) -> torch._C.Value\n",
      "     |  \n",
      "     |  setTypeAs(...)\n",
      "     |      setTypeAs(self: torch._C.Value, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  toIValue(...)\n",
      "     |      toIValue(self: torch._C.Value) -> Optional[IValue]\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. type(self: torch._C.Value) -> c10::Type\n",
      "     |      \n",
      "     |      2. type(self: torch._C.Value) -> c10::Type\n",
      "     |  \n",
      "     |  unique(...)\n",
      "     |      unique(self: torch._C.Value) -> int\n",
      "     |  \n",
      "     |  uses(...)\n",
      "     |      uses(self: torch._C.Value) -> List[torch::jit::Use]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class device(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  index\n",
      "     |  \n",
      "     |  type\n",
      "    \n",
      "    class dtype(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  is_complex\n",
      "     |  \n",
      "     |  is_floating_point\n",
      "     |  \n",
      "     |  is_signed\n",
      "    \n",
      "    class enable_grad(_DecoratorContextManager)\n",
      "     |  Context-manager that enables gradient calculation.\n",
      "     |  \n",
      "     |  Enables gradient calculation, if it has been disabled via :class:`~no_grad`\n",
      "     |  or :class:`~set_grad_enabled`.\n",
      "     |  \n",
      "     |  This context manager is thread local; it will not affect computation\n",
      "     |  in other threads.\n",
      "     |  \n",
      "     |  Also functions as a decorator. (Make sure to instantiate with parenthesis.)\n",
      "     |  \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> x = torch.tensor([1], requires_grad=True)\n",
      "     |      >>> with torch.no_grad():\n",
      "     |      ...   with torch.enable_grad():\n",
      "     |      ...     y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      True\n",
      "     |      >>> y.backward()\n",
      "     |      >>> x.grad\n",
      "     |      >>> @torch.enable_grad()\n",
      "     |      ... def doubler(x):\n",
      "     |      ...     return x * 2\n",
      "     |      >>> with torch.no_grad():\n",
      "     |      ...     z = doubler(x)\n",
      "     |      >>> z.requires_grad\n",
      "     |      True\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      enable_grad\n",
      "     |      _DecoratorContextManager\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self) -> None\n",
      "     |  \n",
      "     |  __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _DecoratorContextManager:\n",
      "     |  \n",
      "     |  __call__(self, func: ~F) -> ~F\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _DecoratorContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class finfo(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  bits\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  eps\n",
      "     |  \n",
      "     |  max\n",
      "     |  \n",
      "     |  min\n",
      "     |  \n",
      "     |  resolution\n",
      "     |  \n",
      "     |  tiny\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class iinfo(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  bits\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  max\n",
      "     |  \n",
      "     |  min\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class layout(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "    \n",
      "    class memory_format(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "    \n",
      "    class no_grad(_DecoratorContextManager)\n",
      "     |  Context-manager that disabled gradient calculation.\n",
      "     |  \n",
      "     |  Disabling gradient calculation is useful for inference, when you are sure\n",
      "     |  that you will not call :meth:`Tensor.backward()`. It will reduce memory\n",
      "     |  consumption for computations that would otherwise have `requires_grad=True`.\n",
      "     |  \n",
      "     |  In this mode, the result of every computation will have\n",
      "     |  `requires_grad=False`, even when the inputs have `requires_grad=True`.\n",
      "     |  \n",
      "     |  This context manager is thread local; it will not affect computation\n",
      "     |  in other threads.\n",
      "     |  \n",
      "     |  Also functions as a decorator. (Make sure to instantiate with parenthesis.)\n",
      "     |  \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> x = torch.tensor([1], requires_grad=True)\n",
      "     |      >>> with torch.no_grad():\n",
      "     |      ...   y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      False\n",
      "     |      >>> @torch.no_grad()\n",
      "     |      ... def doubler(x):\n",
      "     |      ...     return x * 2\n",
      "     |      >>> z = doubler(x)\n",
      "     |      >>> z.requires_grad\n",
      "     |      False\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      no_grad\n",
      "     |      _DecoratorContextManager\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _DecoratorContextManager:\n",
      "     |  \n",
      "     |  __call__(self, func: ~F) -> ~F\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _DecoratorContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class qscheme(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "\n",
      "FUNCTIONS\n",
      "    _adaptive_avg_pool2d(...)\n",
      "    \n",
      "    _add_batch_dim(...)\n",
      "    \n",
      "    _add_relu(...)\n",
      "    \n",
      "    _add_relu_(...)\n",
      "    \n",
      "    _addmv_impl_(...)\n",
      "    \n",
      "    _aminmax(...)\n",
      "    \n",
      "    _amp_foreach_non_finite_check_and_unscale_(...)\n",
      "    \n",
      "    _amp_update_scale(...)\n",
      "    \n",
      "    _baddbmm_mkl_(...)\n",
      "    \n",
      "    _batch_norm_impl_index(...)\n",
      "    \n",
      "    _bmm(...)\n",
      "    \n",
      "    _cast_Byte(...)\n",
      "    \n",
      "    _cast_Char(...)\n",
      "    \n",
      "    _cast_Double(...)\n",
      "    \n",
      "    _cast_Float(...)\n",
      "    \n",
      "    _cast_Half(...)\n",
      "    \n",
      "    _cast_Int(...)\n",
      "    \n",
      "    _cast_Long(...)\n",
      "    \n",
      "    _cast_Short(...)\n",
      "    \n",
      "    _cat(...)\n",
      "    \n",
      "    _choose_qparams_per_tensor(...)\n",
      "    \n",
      "    _compute_linear_combination(...)\n",
      "    \n",
      "    _conj(...)\n",
      "    \n",
      "    _convolution(...)\n",
      "    \n",
      "    _convolution_nogroup(...)\n",
      "    \n",
      "    _copy_from(...)\n",
      "    \n",
      "    _ctc_loss(...)\n",
      "    \n",
      "    _cudnn_ctc_loss(...)\n",
      "    \n",
      "    _cudnn_init_dropout_state(...)\n",
      "    \n",
      "    _cudnn_rnn(...)\n",
      "    \n",
      "    _cudnn_rnn_flatten_weight(...)\n",
      "    \n",
      "    _cufft_clear_plan_cache(...)\n",
      "    \n",
      "    _cufft_get_plan_cache_max_size(...)\n",
      "    \n",
      "    _cufft_get_plan_cache_size(...)\n",
      "    \n",
      "    _cufft_set_plan_cache_max_size(...)\n",
      "    \n",
      "    _cummax_helper(...)\n",
      "    \n",
      "    _cummin_helper(...)\n",
      "    \n",
      "    _debug_has_internal_overlap(...)\n",
      "    \n",
      "    _dim_arange(...)\n",
      "    \n",
      "    _dirichlet_grad(...)\n",
      "    \n",
      "    _embedding_bag(...)\n",
      "    \n",
      "    _embedding_bag_forward_only(...)\n",
      "    \n",
      "    _empty_affine_quantized(...)\n",
      "    \n",
      "    _empty_per_channel_affine_quantized(...)\n",
      "    \n",
      "    _euclidean_dist(...)\n",
      "    \n",
      "    _fake_quantize_learnable_per_channel_affine(...)\n",
      "    \n",
      "    _fake_quantize_learnable_per_tensor_affine(...)\n",
      "    \n",
      "    _fft_c2c(...)\n",
      "    \n",
      "    _fft_c2r(...)\n",
      "    \n",
      "    _fft_r2c(...)\n",
      "    \n",
      "    _foreach_abs(...)\n",
      "    \n",
      "    _foreach_abs_(...)\n",
      "    \n",
      "    _foreach_acos(...)\n",
      "    \n",
      "    _foreach_acos_(...)\n",
      "    \n",
      "    _foreach_add(...)\n",
      "    \n",
      "    _foreach_add_(...)\n",
      "    \n",
      "    _foreach_addcdiv(...)\n",
      "    \n",
      "    _foreach_addcdiv_(...)\n",
      "    \n",
      "    _foreach_addcmul(...)\n",
      "    \n",
      "    _foreach_addcmul_(...)\n",
      "    \n",
      "    _foreach_asin(...)\n",
      "    \n",
      "    _foreach_asin_(...)\n",
      "    \n",
      "    _foreach_atan(...)\n",
      "    \n",
      "    _foreach_atan_(...)\n",
      "    \n",
      "    _foreach_ceil(...)\n",
      "    \n",
      "    _foreach_ceil_(...)\n",
      "    \n",
      "    _foreach_cos(...)\n",
      "    \n",
      "    _foreach_cos_(...)\n",
      "    \n",
      "    _foreach_cosh(...)\n",
      "    \n",
      "    _foreach_cosh_(...)\n",
      "    \n",
      "    _foreach_div(...)\n",
      "    \n",
      "    _foreach_div_(...)\n",
      "    \n",
      "    _foreach_erf(...)\n",
      "    \n",
      "    _foreach_erf_(...)\n",
      "    \n",
      "    _foreach_erfc(...)\n",
      "    \n",
      "    _foreach_erfc_(...)\n",
      "    \n",
      "    _foreach_exp(...)\n",
      "    \n",
      "    _foreach_exp_(...)\n",
      "    \n",
      "    _foreach_expm1(...)\n",
      "    \n",
      "    _foreach_expm1_(...)\n",
      "    \n",
      "    _foreach_floor(...)\n",
      "    \n",
      "    _foreach_floor_(...)\n",
      "    \n",
      "    _foreach_frac(...)\n",
      "    \n",
      "    _foreach_frac_(...)\n",
      "    \n",
      "    _foreach_lgamma(...)\n",
      "    \n",
      "    _foreach_lgamma_(...)\n",
      "    \n",
      "    _foreach_log(...)\n",
      "    \n",
      "    _foreach_log10(...)\n",
      "    \n",
      "    _foreach_log10_(...)\n",
      "    \n",
      "    _foreach_log1p(...)\n",
      "    \n",
      "    _foreach_log1p_(...)\n",
      "    \n",
      "    _foreach_log2(...)\n",
      "    \n",
      "    _foreach_log2_(...)\n",
      "    \n",
      "    _foreach_log_(...)\n",
      "    \n",
      "    _foreach_maximum(...)\n",
      "    \n",
      "    _foreach_minimum(...)\n",
      "    \n",
      "    _foreach_mul(...)\n",
      "    \n",
      "    _foreach_mul_(...)\n",
      "    \n",
      "    _foreach_neg(...)\n",
      "    \n",
      "    _foreach_neg_(...)\n",
      "    \n",
      "    _foreach_reciprocal(...)\n",
      "    \n",
      "    _foreach_reciprocal_(...)\n",
      "    \n",
      "    _foreach_round(...)\n",
      "    \n",
      "    _foreach_round_(...)\n",
      "    \n",
      "    _foreach_sigmoid(...)\n",
      "    \n",
      "    _foreach_sigmoid_(...)\n",
      "    \n",
      "    _foreach_sin(...)\n",
      "    \n",
      "    _foreach_sin_(...)\n",
      "    \n",
      "    _foreach_sinh(...)\n",
      "    \n",
      "    _foreach_sinh_(...)\n",
      "    \n",
      "    _foreach_sqrt(...)\n",
      "    \n",
      "    _foreach_sqrt_(...)\n",
      "    \n",
      "    _foreach_sub(...)\n",
      "    \n",
      "    _foreach_sub_(...)\n",
      "    \n",
      "    _foreach_tan(...)\n",
      "    \n",
      "    _foreach_tan_(...)\n",
      "    \n",
      "    _foreach_tanh(...)\n",
      "    \n",
      "    _foreach_tanh_(...)\n",
      "    \n",
      "    _foreach_trunc(...)\n",
      "    \n",
      "    _foreach_trunc_(...)\n",
      "    \n",
      "    _foreach_zero_(...)\n",
      "    \n",
      "    _fused_dropout(...)\n",
      "    \n",
      "    _grid_sampler_2d_cpu_fallback(...)\n",
      "    \n",
      "    _has_compatible_shallow_copy_type(...)\n",
      "    \n",
      "    _index_copy_(...)\n",
      "    \n",
      "    _index_put_impl_(...)\n",
      "    \n",
      "    _linalg_inv_out_helper_(...)\n",
      "    \n",
      "    _linalg_qr_helper(...)\n",
      "    \n",
      "    _linalg_solve_out_helper_(...)\n",
      "    \n",
      "    _log_softmax(...)\n",
      "    \n",
      "    _log_softmax_backward_data(...)\n",
      "    \n",
      "    _logcumsumexp(...)\n",
      "    \n",
      "    _lu_solve_helper(...)\n",
      "    \n",
      "    _lu_with_info(...)\n",
      "    \n",
      "    _make_dual(...)\n",
      "    \n",
      "    _make_per_channel_quantized_tensor(...)\n",
      "    \n",
      "    _make_per_tensor_quantized_tensor(...)\n",
      "    \n",
      "    _masked_scale(...)\n",
      "    \n",
      "    _mkldnn_reshape(...)\n",
      "    \n",
      "    _mkldnn_transpose(...)\n",
      "    \n",
      "    _mkldnn_transpose_(...)\n",
      "    \n",
      "    _mode(...)\n",
      "    \n",
      "    _nnpack_available(...)\n",
      "    \n",
      "    _nnpack_spatial_convolution(...)\n",
      "    \n",
      "    _pack_padded_sequence(...)\n",
      "    \n",
      "    _pad_packed_sequence(...)\n",
      "    \n",
      "    _remove_batch_dim(...)\n",
      "    \n",
      "    _reshape_from_tensor(...)\n",
      "    \n",
      "    _rowwise_prune(...)\n",
      "    \n",
      "    _s_where(...)\n",
      "    \n",
      "    _sample_dirichlet(...)\n",
      "    \n",
      "    _saturate_weight_to_fp16(...)\n",
      "    \n",
      "    _shape_as_tensor(...)\n",
      "    \n",
      "    _sobol_engine_draw(...)\n",
      "    \n",
      "    _sobol_engine_ff_(...)\n",
      "    \n",
      "    _sobol_engine_initialize_state_(...)\n",
      "    \n",
      "    _sobol_engine_scramble_(...)\n",
      "    \n",
      "    _softmax(...)\n",
      "    \n",
      "    _softmax_backward_data(...)\n",
      "    \n",
      "    _sparse_addmm(...)\n",
      "    \n",
      "    _sparse_coo_tensor_unsafe(...)\n",
      "    \n",
      "    _sparse_log_softmax(...)\n",
      "    \n",
      "    _sparse_log_softmax_backward_data(...)\n",
      "    \n",
      "    _sparse_matrix_mask_helper(...)\n",
      "    \n",
      "    _sparse_mm(...)\n",
      "    \n",
      "    _sparse_softmax(...)\n",
      "    \n",
      "    _sparse_softmax_backward_data(...)\n",
      "    \n",
      "    _sparse_sparse_matmul(...)\n",
      "    \n",
      "    _sparse_sum(...)\n",
      "    \n",
      "    _stack(...)\n",
      "    \n",
      "    _standard_gamma(...)\n",
      "    \n",
      "    _standard_gamma_grad(...)\n",
      "    \n",
      "    _std(...)\n",
      "    \n",
      "    _syevd_helper(...)\n",
      "    \n",
      "    _test_serialization_subcmul(...)\n",
      "    \n",
      "    _trilinear(...)\n",
      "    \n",
      "    _unique(...)\n",
      "    \n",
      "    _unique2(...)\n",
      "    \n",
      "    _unpack_dual(...)\n",
      "    \n",
      "    _use_cudnn_ctc_loss(...)\n",
      "    \n",
      "    _use_cudnn_rnn_flatten_weight(...)\n",
      "    \n",
      "    _validate_sparse_coo_tensor_args(...)\n",
      "    \n",
      "    _var(...)\n",
      "    \n",
      "    _weight_norm(...)\n",
      "    \n",
      "    _weight_norm_cuda_interface(...)\n",
      "    \n",
      "    abs(...)\n",
      "        abs(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the absolute value of each element in :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = |\\text{input}_{i}|\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.abs(torch.tensor([-1, -2, 3]))\n",
      "            tensor([ 1,  2,  3])\n",
      "    \n",
      "    abs_(...)\n",
      "    \n",
      "    absolute(...)\n",
      "        absolute(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.abs`\n",
      "    \n",
      "    acos(...)\n",
      "        acos(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the inverse cosine of each element in :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\cos^{-1}(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.3348, -0.5889,  0.2005, -0.1584])\n",
      "            >>> torch.acos(a)\n",
      "            tensor([ 1.2294,  2.2004,  1.3690,  1.7298])\n",
      "    \n",
      "    acos_(...)\n",
      "    \n",
      "    acosh(...)\n",
      "        acosh(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the inverse hyperbolic cosine of the elements of :attr:`input`.\n",
      "        \n",
      "        Note:\n",
      "            The domain of the inverse hyperbolic cosine is `[1, inf)` and values outside this range\n",
      "            will be mapped to ``NaN``, except for `+ INF` for which the output is mapped to `+ INF`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\cosh^{-1}(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4).uniform_(1, 2)\n",
      "            >>> a\n",
      "            tensor([ 1.3192, 1.9915, 1.9674, 1.7151 ])\n",
      "            >>> torch.acosh(a)\n",
      "            tensor([ 0.7791, 1.3120, 1.2979, 1.1341 ])\n",
      "    \n",
      "    acosh_(...)\n",
      "    \n",
      "    adaptive_avg_pool1d(...)\n",
      "        adaptive_avg_pool1d(input, output_size) -> Tensor\n",
      "        \n",
      "        Applies a 1D adaptive average pooling over an input signal composed of\n",
      "        several input planes.\n",
      "        \n",
      "        See :class:`~torch.nn.AdaptiveAvgPool1d` for details and output shape.\n",
      "        \n",
      "        Args:\n",
      "            output_size: the target output size (single integer)\n",
      "    \n",
      "    adaptive_max_pool1d(...)\n",
      "    \n",
      "    add(...)\n",
      "        add(input, other, *, out=None)\n",
      "        \n",
      "        Adds the scalar :attr:`other` to each element of the input :attr:`input`\n",
      "        and returns a new resulting tensor.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out} = \\text{input} + \\text{other}\n",
      "        \n",
      "        If :attr:`input` is of type FloatTensor or DoubleTensor, :attr:`other` must be\n",
      "        a real number, otherwise it should be an integer.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            value (Number): the number to be added to each element of :attr:`input`\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.0202,  1.0985,  1.3506, -0.6056])\n",
      "            >>> torch.add(a, 20)\n",
      "            tensor([ 20.0202,  21.0985,  21.3506,  19.3944])\n",
      "        \n",
      "        .. function:: add(input, other, *, alpha=1, out=None)\n",
      "        \n",
      "        Each element of the tensor :attr:`other` is multiplied by the scalar\n",
      "        :attr:`alpha` and added to each element of the tensor :attr:`input`.\n",
      "        The resulting tensor is returned.\n",
      "        \n",
      "        The shapes of :attr:`input` and :attr:`other` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out} = \\text{input} + \\text{alpha} \\times \\text{other}\n",
      "        \n",
      "        If :attr:`other` is of type FloatTensor or DoubleTensor, :attr:`alpha` must be\n",
      "        a real number, otherwise it should be an integer.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the first input tensor\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            alpha (Number): the scalar multiplier for :attr:`other`\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-0.9732, -0.3497,  0.6245,  0.4022])\n",
      "            >>> b = torch.randn(4, 1)\n",
      "            >>> b\n",
      "            tensor([[ 0.3743],\n",
      "                    [-1.7724],\n",
      "                    [-0.5811],\n",
      "                    [-0.8017]])\n",
      "            >>> torch.add(a, b, alpha=10)\n",
      "            tensor([[  2.7695,   3.3930,   4.3672,   4.1450],\n",
      "                    [-18.6971, -18.0736, -17.0994, -17.3216],\n",
      "                    [ -6.7845,  -6.1610,  -5.1868,  -5.4090],\n",
      "                    [ -8.9902,  -8.3667,  -7.3925,  -7.6147]])\n",
      "    \n",
      "    addbmm(...)\n",
      "        addbmm(input, batch1, batch2, *, beta=1, alpha=1, out=None) -> Tensor\n",
      "        \n",
      "        Performs a batch matrix-matrix product of matrices stored\n",
      "        in :attr:`batch1` and :attr:`batch2`,\n",
      "        with a reduced add step (all matrix multiplications get accumulated\n",
      "        along the first dimension).\n",
      "        :attr:`input` is added to the final result.\n",
      "        \n",
      "        :attr:`batch1` and :attr:`batch2` must be 3-D tensors each containing the\n",
      "        same number of matrices.\n",
      "        \n",
      "        If :attr:`batch1` is a :math:`(b \\times n \\times m)` tensor, :attr:`batch2` is a\n",
      "        :math:`(b \\times m \\times p)` tensor, :attr:`input` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>` with a :math:`(n \\times p)` tensor\n",
      "        and :attr:`out` will be a :math:`(n \\times p)` tensor.\n",
      "        \n",
      "        .. math::\n",
      "            out = \\beta\\ \\text{input} + \\alpha\\ (\\sum_{i=0}^{b-1} \\text{batch1}_i \\mathbin{@} \\text{batch2}_i)\n",
      "        \n",
      "        If :attr:`beta` is 0, then :attr:`input` will be ignored, and `nan` and `inf` in\n",
      "        it will not be propagated.\n",
      "        \n",
      "        For inputs of type `FloatTensor` or `DoubleTensor`, arguments :attr:`beta` and :attr:`alpha`\n",
      "        must be real numbers, otherwise they should be integers.\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        Args:\n",
      "            batch1 (Tensor): the first batch of matrices to be multiplied\n",
      "            batch2 (Tensor): the second batch of matrices to be multiplied\n",
      "        \n",
      "        Keyword args:\n",
      "            beta (Number, optional): multiplier for :attr:`input` (:math:`\\beta`)\n",
      "            input (Tensor): matrix to be added\n",
      "            alpha (Number, optional): multiplier for `batch1 @ batch2` (:math:`\\alpha`)\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> M = torch.randn(3, 5)\n",
      "            >>> batch1 = torch.randn(10, 3, 4)\n",
      "            >>> batch2 = torch.randn(10, 4, 5)\n",
      "            >>> torch.addbmm(M, batch1, batch2)\n",
      "            tensor([[  6.6311,   0.0503,   6.9768, -12.0362,  -2.1653],\n",
      "                    [ -4.8185,  -1.4255,  -6.6760,   8.9453,   2.5743],\n",
      "                    [ -3.8202,   4.3691,   1.0943,  -1.1109,   5.4730]])\n",
      "    \n",
      "    addcdiv(...)\n",
      "        addcdiv(input, tensor1, tensor2, *, value=1, out=None) -> Tensor\n",
      "        \n",
      "        Performs the element-wise division of :attr:`tensor1` by :attr:`tensor2`,\n",
      "        multiply the result by the scalar :attr:`value` and add it to :attr:`input`.\n",
      "        \n",
      "        .. warning::\n",
      "            Integer division with addcdiv is no longer supported, and in a future\n",
      "            release addcdiv will perform a true division of tensor1 and tensor2.\n",
      "            The historic addcdiv behavior can be implemented as\n",
      "            (input + value * torch.trunc(tensor1 / tensor2)).to(input.dtype)\n",
      "            for integer inputs and as (input + value * tensor1 / tensor2) for float inputs.\n",
      "            The future addcdiv behavior is just the latter implementation:\n",
      "            (input + value * tensor1 / tensor2), for all dtypes.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = \\text{input}_i + \\text{value} \\times \\frac{\\text{tensor1}_i}{\\text{tensor2}_i}\n",
      "        \n",
      "        \n",
      "        The shapes of :attr:`input`, :attr:`tensor1`, and :attr:`tensor2` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        For inputs of type `FloatTensor` or `DoubleTensor`, :attr:`value` must be\n",
      "        a real number, otherwise an integer.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to be added\n",
      "            tensor1 (Tensor): the numerator tensor\n",
      "            tensor2 (Tensor): the denominator tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            value (Number, optional): multiplier for :math:`\\text{tensor1} / \\text{tensor2}`\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> t = torch.randn(1, 3)\n",
      "            >>> t1 = torch.randn(3, 1)\n",
      "            >>> t2 = torch.randn(1, 3)\n",
      "            >>> torch.addcdiv(t, t1, t2, value=0.1)\n",
      "            tensor([[-0.2312, -3.6496,  0.1312],\n",
      "                    [-1.0428,  3.4292, -0.1030],\n",
      "                    [-0.5369, -0.9829,  0.0430]])\n",
      "    \n",
      "    addcmul(...)\n",
      "        addcmul(input, tensor1, tensor2, *, value=1, out=None) -> Tensor\n",
      "        \n",
      "        Performs the element-wise multiplication of :attr:`tensor1`\n",
      "        by :attr:`tensor2`, multiply the result by the scalar :attr:`value`\n",
      "        and add it to :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = \\text{input}_i + \\text{value} \\times \\text{tensor1}_i \\times \\text{tensor2}_i\n",
      "        \n",
      "        The shapes of :attr:`tensor`, :attr:`tensor1`, and :attr:`tensor2` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        For inputs of type `FloatTensor` or `DoubleTensor`, :attr:`value` must be\n",
      "        a real number, otherwise an integer.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to be added\n",
      "            tensor1 (Tensor): the tensor to be multiplied\n",
      "            tensor2 (Tensor): the tensor to be multiplied\n",
      "        \n",
      "        Keyword args:\n",
      "            value (Number, optional): multiplier for :math:`tensor1 .* tensor2`\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> t = torch.randn(1, 3)\n",
      "            >>> t1 = torch.randn(3, 1)\n",
      "            >>> t2 = torch.randn(1, 3)\n",
      "            >>> torch.addcmul(t, t1, t2, value=0.1)\n",
      "            tensor([[-0.8635, -0.6391,  1.6174],\n",
      "                    [-0.7617, -0.5879,  1.7388],\n",
      "                    [-0.8353, -0.6249,  1.6511]])\n",
      "    \n",
      "    addmm(...)\n",
      "        addmm(input, mat1, mat2, *, beta=1, alpha=1, out=None) -> Tensor\n",
      "        \n",
      "        Performs a matrix multiplication of the matrices :attr:`mat1` and :attr:`mat2`.\n",
      "        The matrix :attr:`input` is added to the final result.\n",
      "        \n",
      "        If :attr:`mat1` is a :math:`(n \\times m)` tensor, :attr:`mat2` is a\n",
      "        :math:`(m \\times p)` tensor, then :attr:`input` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>` with a :math:`(n \\times p)` tensor\n",
      "        and :attr:`out` will be a :math:`(n \\times p)` tensor.\n",
      "        \n",
      "        :attr:`alpha` and :attr:`beta` are scaling factors on matrix-vector product between\n",
      "        :attr:`mat1` and :attr:`mat2` and the added matrix :attr:`input` respectively.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out} = \\beta\\ \\text{input} + \\alpha\\ (\\text{mat1}_i \\mathbin{@} \\text{mat2}_i)\n",
      "        \n",
      "        If :attr:`beta` is 0, then :attr:`input` will be ignored, and `nan` and `inf` in\n",
      "        it will not be propagated.\n",
      "        \n",
      "        For inputs of type `FloatTensor` or `DoubleTensor`, arguments :attr:`beta` and\n",
      "        :attr:`alpha` must be real numbers, otherwise they should be integers.\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): matrix to be added\n",
      "            mat1 (Tensor): the first matrix to be matrix multiplied\n",
      "            mat2 (Tensor): the second matrix to be matrix multiplied\n",
      "        \n",
      "        Keyword args:\n",
      "            beta (Number, optional): multiplier for :attr:`input` (:math:`\\beta`)\n",
      "            alpha (Number, optional): multiplier for :math:`mat1 @ mat2` (:math:`\\alpha`)\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> M = torch.randn(2, 3)\n",
      "            >>> mat1 = torch.randn(2, 3)\n",
      "            >>> mat2 = torch.randn(3, 3)\n",
      "            >>> torch.addmm(M, mat1, mat2)\n",
      "            tensor([[-4.8716,  1.4671, -1.3746],\n",
      "                    [ 0.7573, -3.9555, -2.8681]])\n",
      "    \n",
      "    addmv(...)\n",
      "        addmv(input, mat, vec, *, beta=1, alpha=1, out=None) -> Tensor\n",
      "        \n",
      "        Performs a matrix-vector product of the matrix :attr:`mat` and\n",
      "        the vector :attr:`vec`.\n",
      "        The vector :attr:`input` is added to the final result.\n",
      "        \n",
      "        If :attr:`mat` is a :math:`(n \\times m)` tensor, :attr:`vec` is a 1-D tensor of\n",
      "        size `m`, then :attr:`input` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>` with a 1-D tensor of size `n` and\n",
      "        :attr:`out` will be 1-D tensor of size `n`.\n",
      "        \n",
      "        :attr:`alpha` and :attr:`beta` are scaling factors on matrix-vector product between\n",
      "        :attr:`mat` and :attr:`vec` and the added tensor :attr:`input` respectively.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out} = \\beta\\ \\text{input} + \\alpha\\ (\\text{mat} \\mathbin{@} \\text{vec})\n",
      "        \n",
      "        If :attr:`beta` is 0, then :attr:`input` will be ignored, and `nan` and `inf` in\n",
      "        it will not be propagated.\n",
      "        \n",
      "        For inputs of type `FloatTensor` or `DoubleTensor`, arguments :attr:`beta` and\n",
      "        :attr:`alpha` must be real numbers, otherwise they should be integers\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): vector to be added\n",
      "            mat (Tensor): matrix to be matrix multiplied\n",
      "            vec (Tensor): vector to be matrix multiplied\n",
      "        \n",
      "        Keyword args:\n",
      "            beta (Number, optional): multiplier for :attr:`input` (:math:`\\beta`)\n",
      "            alpha (Number, optional): multiplier for :math:`mat @ vec` (:math:`\\alpha`)\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> M = torch.randn(2)\n",
      "            >>> mat = torch.randn(2, 3)\n",
      "            >>> vec = torch.randn(3)\n",
      "            >>> torch.addmv(M, mat, vec)\n",
      "            tensor([-0.3768, -5.5565])\n",
      "    \n",
      "    addmv_(...)\n",
      "    \n",
      "    addr(...)\n",
      "        addr(input, vec1, vec2, *, beta=1, alpha=1, out=None) -> Tensor\n",
      "        \n",
      "        Performs the outer-product of vectors :attr:`vec1` and :attr:`vec2`\n",
      "        and adds it to the matrix :attr:`input`.\n",
      "        \n",
      "        Optional values :attr:`beta` and :attr:`alpha` are scaling factors on the\n",
      "        outer product between :attr:`vec1` and :attr:`vec2` and the added matrix\n",
      "        :attr:`input` respectively.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out} = \\beta\\ \\text{input} + \\alpha\\ (\\text{vec1} \\otimes \\text{vec2})\n",
      "        \n",
      "        If :attr:`beta` is 0, then :attr:`input` will be ignored, and `nan` and `inf` in\n",
      "        it will not be propagated.\n",
      "        \n",
      "        If :attr:`vec1` is a vector of size `n` and :attr:`vec2` is a vector\n",
      "        of size `m`, then :attr:`input` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>` with a matrix of size\n",
      "        :math:`(n \\times m)` and :attr:`out` will be a matrix of size\n",
      "        :math:`(n \\times m)`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): matrix to be added\n",
      "            vec1 (Tensor): the first vector of the outer product\n",
      "            vec2 (Tensor): the second vector of the outer product\n",
      "        \n",
      "        Keyword args:\n",
      "            beta (Number, optional): multiplier for :attr:`input` (:math:`\\beta`)\n",
      "            alpha (Number, optional): multiplier for :math:`\\text{vec1} \\otimes \\text{vec2}` (:math:`\\alpha`)\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> vec1 = torch.arange(1., 4.)\n",
      "            >>> vec2 = torch.arange(1., 3.)\n",
      "            >>> M = torch.zeros(3, 2)\n",
      "            >>> torch.addr(M, vec1, vec2)\n",
      "            tensor([[ 1.,  2.],\n",
      "                    [ 2.,  4.],\n",
      "                    [ 3.,  6.]])\n",
      "    \n",
      "    affine_grid_generator(...)\n",
      "    \n",
      "    align_tensors(*tensors)\n",
      "    \n",
      "    all(...)\n",
      "        all(input) -> Tensor\n",
      "        \n",
      "        Tests if all elements in :attr:`input` evaluate to `True`.\n",
      "        \n",
      "        .. note:: This function matches the behaviour of NumPy in returning\n",
      "                  output of dtype `bool` for all supported dtypes except `uint8`.\n",
      "                  For `uint8` the dtype of output is `uint8` itself.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.rand(1, 2).bool()\n",
      "            >>> a\n",
      "            tensor([[False, True]], dtype=torch.bool)\n",
      "            >>> torch.all(a)\n",
      "            tensor(False, dtype=torch.bool)\n",
      "            >>> a = torch.arange(0, 3)\n",
      "            >>> a\n",
      "            tensor([0, 1, 2])\n",
      "            >>> torch.all(a)\n",
      "            tensor(False)\n",
      "        \n",
      "        .. function:: all(input, dim, keepdim=False, *, out=None) -> Tensor\n",
      "        \n",
      "        For each row of :attr:`input` in the given dimension :attr:`dim`,\n",
      "        returns `True` if all elements in the row evaluate to `True` and `False` otherwise.\n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "        as :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
      "        the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the dimension to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.rand(4, 2).bool()\n",
      "            >>> a\n",
      "            tensor([[True, True],\n",
      "                    [True, False],\n",
      "                    [True, True],\n",
      "                    [True, True]], dtype=torch.bool)\n",
      "            >>> torch.all(a, dim=1)\n",
      "            tensor([ True, False,  True,  True], dtype=torch.bool)\n",
      "            >>> torch.all(a, dim=0)\n",
      "            tensor([ True, False], dtype=torch.bool)\n",
      "    \n",
      "    allclose(...)\n",
      "        allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False) -> bool\n",
      "        \n",
      "        This function checks if all :attr:`input` and :attr:`other` satisfy the condition:\n",
      "        \n",
      "        .. math::\n",
      "            \\lvert \\text{input} - \\text{other} \\rvert \\leq \\texttt{atol} + \\texttt{rtol} \\times \\lvert \\text{other} \\rvert\n",
      "        \n",
      "        elementwise, for all elements of :attr:`input` and :attr:`other`. The behaviour of this function is analogous to\n",
      "        `numpy.allclose <https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html>`_\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): first tensor to compare\n",
      "            other (Tensor): second tensor to compare\n",
      "            atol (float, optional): absolute tolerance. Default: 1e-08\n",
      "            rtol (float, optional): relative tolerance. Default: 1e-05\n",
      "            equal_nan (bool, optional): if ``True``, then two ``NaN`` s will be considered equal. Default: ``False``\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08]))\n",
      "            False\n",
      "            >>> torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09]))\n",
      "            True\n",
      "            >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]))\n",
      "            False\n",
      "            >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True)\n",
      "            True\n",
      "    \n",
      "    alpha_dropout(...)\n",
      "    \n",
      "    alpha_dropout_(...)\n",
      "    \n",
      "    amax(...)\n",
      "        amax(input, dim, keepdim=False, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns the maximum value of each slice of the :attr:`input` tensor in the given\n",
      "        dimension(s) :attr:`dim`.\n",
      "        \n",
      "        .. note::\n",
      "            The difference between ``max``/``min`` and ``amax``/``amin`` is:\n",
      "                - ``amax``/``amin`` supports reducing on multiple dimensions,\n",
      "                - ``amax``/``amin`` does not return indices,\n",
      "                - ``amax``/``amin`` evenly distributes gradient between equal values,\n",
      "                  while ``max(dim)``/``min(dim)`` propagates gradient only to a single\n",
      "                  index in the source tensor.\n",
      "        \n",
      "        If :attr:`keepdim is ``True``, the output tensors are of the same size\n",
      "        as :attr:`input` except in the dimension(s) :attr:`dim` where they are of size 1.\n",
      "        Otherwise, :attr:`dim`s are squeezed (see :func:`torch.squeeze`), resulting\n",
      "        in the output tensors having fewer dimension than :attr:`input`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "          out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[ 0.8177,  1.4878, -0.2491,  0.9130],\n",
      "                    [-0.7158,  1.1775,  2.0992,  0.4817],\n",
      "                    [-0.0053,  0.0164, -1.3738, -0.0507],\n",
      "                    [ 1.9700,  1.1106, -1.0318, -1.0816]])\n",
      "            >>> torch.amax(a, 1)\n",
      "            tensor([1.4878, 2.0992, 0.0164, 1.9700])\n",
      "    \n",
      "    amin(...)\n",
      "        amin(input, dim, keepdim=False, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns the minimum value of each slice of the :attr:`input` tensor in the given\n",
      "        dimension(s) :attr:`dim`.\n",
      "        \n",
      "        .. note::\n",
      "            The difference between ``max``/``min`` and ``amax``/``amin`` is:\n",
      "                - ``amax``/``amin`` supports reducing on multiple dimensions,\n",
      "                - ``amax``/``amin`` does not return indices,\n",
      "                - ``amax``/``amin`` evenly distributes gradient between equal values,\n",
      "                  while ``max(dim)``/``min(dim)`` propagates gradient only to a single\n",
      "                  index in the source tensor.\n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensors are of the same size as\n",
      "        :attr:`input` except in the dimension(s) :attr:`dim` where they are of size 1.\n",
      "        Otherwise, :attr:`dim`s are squeezed (see :func:`torch.squeeze`), resulting in\n",
      "        the output tensors having fewer dimensions than :attr:`input`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "          out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[ 0.6451, -0.4866,  0.2987, -1.3312],\n",
      "                    [-0.5744,  1.2980,  1.8397, -0.2713],\n",
      "                    [ 0.9128,  0.9214, -1.7268, -0.2995],\n",
      "                    [ 0.9023,  0.4853,  0.9075, -1.6165]])\n",
      "            >>> torch.amin(a, 1)\n",
      "            tensor([-1.3312, -0.5744, -1.7268, -1.6165])\n",
      "    \n",
      "    angle(...)\n",
      "        angle(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise angle (in radians) of the given :attr:`input` tensor.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = angle(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        .. note:: Starting in PyTorch 1.8, angle returns pi for negative real numbers,\n",
      "                  zero for non-negative real numbers, and propagates NaNs. Previously\n",
      "                  the function would return zero for all real numbers and not propagate\n",
      "                  floating-point NaNs.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.angle(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))*180/3.14159\n",
      "            tensor([ 135.,  135,  -45])\n",
      "    \n",
      "    any(...)\n",
      "        any(input) -> Tensor\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Tests if any element in :attr:`input` evaluates to `True`.\n",
      "        \n",
      "        .. note:: This function matches the behaviour of NumPy in returning\n",
      "                  output of dtype `bool` for all supported dtypes except `uint8`.\n",
      "                  For `uint8` the dtype of output is `uint8` itself.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.rand(1, 2).bool()\n",
      "            >>> a\n",
      "            tensor([[False, True]], dtype=torch.bool)\n",
      "            >>> torch.any(a)\n",
      "            tensor(True, dtype=torch.bool)\n",
      "            >>> a = torch.arange(0, 3)\n",
      "            >>> a\n",
      "            tensor([0, 1, 2])\n",
      "            >>> torch.any(a)\n",
      "            tensor(True)\n",
      "        \n",
      "        .. function:: any(input, dim, keepdim=False, *, out=None) -> Tensor\n",
      "        \n",
      "        For each row of :attr:`input` in the given dimension :attr:`dim`,\n",
      "        returns `True` if any element in the row evaluate to `True` and `False` otherwise.\n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "        as :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
      "        the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the dimension to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 2) < 0\n",
      "            >>> a\n",
      "            tensor([[ True,  True],\n",
      "                    [False,  True],\n",
      "                    [ True,  True],\n",
      "                    [False, False]])\n",
      "            >>> torch.any(a, 1)\n",
      "            tensor([ True,  True,  True, False])\n",
      "            >>> torch.any(a, 0)\n",
      "            tensor([True, True])\n",
      "    \n",
      "    arange(...)\n",
      "        arange(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a 1-D tensor of size :math:`\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil`\n",
      "        with values from the interval ``[start, end)`` taken with common difference\n",
      "        :attr:`step` beginning from `start`.\n",
      "        \n",
      "        Note that non-integer :attr:`step` is subject to floating point rounding errors when\n",
      "        comparing against :attr:`end`; to avoid inconsistency, we advise adding a small epsilon to :attr:`end`\n",
      "        in such cases.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{{i+1}} = \\text{out}_{i} + \\text{step}\n",
      "        \n",
      "        Args:\n",
      "            start (Number): the starting value for the set of points. Default: ``0``.\n",
      "            end (Number): the ending value for the set of points\n",
      "            step (Number): the gap between each pair of adjacent points. Default: ``1``.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`). If `dtype` is not given, infer the data type from the other input\n",
      "                arguments. If any of `start`, `end`, or `stop` are floating-point, the\n",
      "                `dtype` is inferred to be the default dtype, see\n",
      "                :meth:`~torch.get_default_dtype`. Otherwise, the `dtype` is inferred to\n",
      "                be `torch.int64`.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.arange(5)\n",
      "            tensor([ 0,  1,  2,  3,  4])\n",
      "            >>> torch.arange(1, 4)\n",
      "            tensor([ 1,  2,  3])\n",
      "            >>> torch.arange(1, 2.5, 0.5)\n",
      "            tensor([ 1.0000,  1.5000,  2.0000])\n",
      "    \n",
      "    arccos(...)\n",
      "        arccos(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.acos`.\n",
      "    \n",
      "    arccos_(...)\n",
      "    \n",
      "    arccosh(...)\n",
      "        arccosh(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.acosh`.\n",
      "    \n",
      "    arccosh_(...)\n",
      "    \n",
      "    arcsin(...)\n",
      "        arcsin(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.asin`.\n",
      "    \n",
      "    arcsin_(...)\n",
      "    \n",
      "    arcsinh(...)\n",
      "        arcsinh(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.asinh`.\n",
      "    \n",
      "    arcsinh_(...)\n",
      "    \n",
      "    arctan(...)\n",
      "        arctan(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.atan`.\n",
      "    \n",
      "    arctan_(...)\n",
      "    \n",
      "    arctanh(...)\n",
      "        arctanh(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.atanh`.\n",
      "    \n",
      "    arctanh_(...)\n",
      "    \n",
      "    are_deterministic_algorithms_enabled()\n",
      "        Returns True if the global deterministic flag is turned on. Refer to\n",
      "        :func:`torch.use_deterministic_algorithms` documentation for more details.\n",
      "    \n",
      "    argmax(...)\n",
      "        argmax(input) -> LongTensor\n",
      "        \n",
      "        Returns the indices of the maximum value of all elements in the :attr:`input` tensor.\n",
      "        \n",
      "        This is the second value returned by :meth:`torch.max`. See its\n",
      "        documentation for the exact semantics of this method.\n",
      "        \n",
      "        .. note:: If there are multiple minimal values then the indices of the first minimal value are returned.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n",
      "                    [-0.7401, -0.8805, -0.3402, -1.1936],\n",
      "                    [ 0.4907, -1.3948, -1.0691, -0.3132],\n",
      "                    [-1.6092,  0.5419, -0.2993,  0.3195]])\n",
      "            >>> torch.argmax(a)\n",
      "            tensor(0)\n",
      "        \n",
      "        .. function:: argmax(input, dim, keepdim=False) -> LongTensor\n",
      "        \n",
      "        Returns the indices of the maximum values of a tensor across a dimension.\n",
      "        \n",
      "        This is the second value returned by :meth:`torch.max`. See its\n",
      "        documentation for the exact semantics of this method.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the dimension to reduce. If ``None``, the argmax of the flattened input is returned.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not. Ignored if ``dim=None``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n",
      "                    [-0.7401, -0.8805, -0.3402, -1.1936],\n",
      "                    [ 0.4907, -1.3948, -1.0691, -0.3132],\n",
      "                    [-1.6092,  0.5419, -0.2993,  0.3195]])\n",
      "            >>> torch.argmax(a, dim=1)\n",
      "            tensor([ 0,  2,  0,  1])\n",
      "    \n",
      "    argmin(...)\n",
      "        argmin(input, dim=None, keepdim=False) -> LongTensor\n",
      "        \n",
      "        Returns the indices of the minimum value(s) of the flattened tensor or along a dimension\n",
      "        \n",
      "        This is the second value returned by :meth:`torch.min`. See its\n",
      "        documentation for the exact semantics of this method.\n",
      "        \n",
      "        .. note:: If there are multiple minimal values then the indices of the first minimal value are returned.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the dimension to reduce. If ``None``, the argmin of the flattened input is returned.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not. Ignored if ``dim=None``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[ 0.1139,  0.2254, -0.1381,  0.3687],\n",
      "                    [ 1.0100, -1.1975, -0.0102, -0.4732],\n",
      "                    [-0.9240,  0.1207, -0.7506, -1.0213],\n",
      "                    [ 1.7809, -1.2960,  0.9384,  0.1438]])\n",
      "            >>> torch.argmin(a)\n",
      "            tensor(13)\n",
      "            >>> torch.argmin(a, dim=1)\n",
      "            tensor([ 2,  1,  3,  1])\n",
      "            >>> torch.argmin(a, dim=1, keepdim=True)\n",
      "            tensor([[2],\n",
      "                    [1],\n",
      "                    [3],\n",
      "                    [1]])\n",
      "    \n",
      "    argsort(...)\n",
      "        argsort(input, dim=-1, descending=False) -> LongTensor\n",
      "        \n",
      "        Returns the indices that sort a tensor along a given dimension in ascending\n",
      "        order by value.\n",
      "        \n",
      "        This is the second value returned by :meth:`torch.sort`.  See its documentation\n",
      "        for the exact semantics of this method.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int, optional): the dimension to sort along\n",
      "            descending (bool, optional): controls the sorting order (ascending or descending)\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[ 0.0785,  1.5267, -0.8521,  0.4065],\n",
      "                    [ 0.1598,  0.0788, -0.0745, -1.2700],\n",
      "                    [ 1.2208,  1.0722, -0.7064,  1.2564],\n",
      "                    [ 0.0669, -0.2318, -0.8229, -0.9280]])\n",
      "        \n",
      "        \n",
      "            >>> torch.argsort(a, dim=1)\n",
      "            tensor([[2, 0, 3, 1],\n",
      "                    [3, 2, 1, 0],\n",
      "                    [2, 1, 0, 3],\n",
      "                    [3, 2, 1, 0]])\n",
      "    \n",
      "    as_strided(...)\n",
      "        as_strided(input, size, stride, storage_offset=0) -> Tensor\n",
      "        \n",
      "        Create a view of an existing `torch.Tensor` :attr:`input` with specified\n",
      "        :attr:`size`, :attr:`stride` and :attr:`storage_offset`.\n",
      "        \n",
      "        .. warning::\n",
      "            More than one element of a created tensor may refer to a single memory\n",
      "            location. As a result, in-place operations (especially ones that are\n",
      "            vectorized) may result in incorrect behavior. If you need to write to\n",
      "            the tensors, please clone them first.\n",
      "        \n",
      "            Many PyTorch functions, which return a view of a tensor, are internally\n",
      "            implemented with this function. Those functions, like\n",
      "            :meth:`torch.Tensor.expand`, are easier to read and are therefore more\n",
      "            advisable to use.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            size (tuple or ints): the shape of the output tensor\n",
      "            stride (tuple or ints): the stride of the output tensor\n",
      "            storage_offset (int, optional): the offset in the underlying storage of the output tensor\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.randn(3, 3)\n",
      "            >>> x\n",
      "            tensor([[ 0.9039,  0.6291,  1.0795],\n",
      "                    [ 0.1586,  2.1939, -0.4900],\n",
      "                    [-0.1909, -0.7503,  1.9355]])\n",
      "            >>> t = torch.as_strided(x, (2, 2), (1, 2))\n",
      "            >>> t\n",
      "            tensor([[0.9039, 1.0795],\n",
      "                    [0.6291, 0.1586]])\n",
      "            >>> t = torch.as_strided(x, (2, 2), (1, 2), 1)\n",
      "            tensor([[0.6291, 0.1586],\n",
      "                    [1.0795, 2.1939]])\n",
      "    \n",
      "    as_strided_(...)\n",
      "    \n",
      "    as_tensor(...)\n",
      "        as_tensor(data, dtype=None, device=None) -> Tensor\n",
      "        \n",
      "        Convert the data into a `torch.Tensor`. If the data is already a `Tensor` with the same `dtype` and `device`,\n",
      "        no copy will be performed, otherwise a new `Tensor` will be returned with computational graph retained if data\n",
      "        `Tensor` has ``requires_grad=True``. Similarly, if the data is an ``ndarray`` of the corresponding `dtype` and\n",
      "        the `device` is the cpu, no copy will be performed.\n",
      "        \n",
      "        Args:\n",
      "            data (array_like): Initial data for the tensor. Can be a list, tuple,\n",
      "                NumPy ``ndarray``, scalar, and other types.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, infers data type from :attr:`data`.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = numpy.array([1, 2, 3])\n",
      "            >>> t = torch.as_tensor(a)\n",
      "            >>> t\n",
      "            tensor([ 1,  2,  3])\n",
      "            >>> t[0] = -1\n",
      "            >>> a\n",
      "            array([-1,  2,  3])\n",
      "        \n",
      "            >>> a = numpy.array([1, 2, 3])\n",
      "            >>> t = torch.as_tensor(a, device=torch.device('cuda'))\n",
      "            >>> t\n",
      "            tensor([ 1,  2,  3])\n",
      "            >>> t[0] = -1\n",
      "            >>> a\n",
      "            array([1,  2,  3])\n",
      "    \n",
      "    asin(...)\n",
      "        asin(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the arcsine  of the elements of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\sin^{-1}(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-0.5962,  1.4985, -0.4396,  1.4525])\n",
      "            >>> torch.asin(a)\n",
      "            tensor([-0.6387,     nan, -0.4552,     nan])\n",
      "    \n",
      "    asin_(...)\n",
      "    \n",
      "    asinh(...)\n",
      "        asinh(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the inverse hyperbolic sine of the elements of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\sinh^{-1}(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.1606, -1.4267, -1.0899, -1.0250 ])\n",
      "            >>> torch.asinh(a)\n",
      "            tensor([ 0.1599, -1.1534, -0.9435, -0.8990 ])\n",
      "    \n",
      "    asinh_(...)\n",
      "    \n",
      "    atan(...)\n",
      "        atan(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the arctangent  of the elements of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\tan^{-1}(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.2341,  0.2539, -0.6256, -0.6448])\n",
      "            >>> torch.atan(a)\n",
      "            tensor([ 0.2299,  0.2487, -0.5591, -0.5727])\n",
      "    \n",
      "    atan2(...)\n",
      "        atan2(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Element-wise arctangent of :math:`\\text{input}_{i} / \\text{other}_{i}`\n",
      "        with consideration of the quadrant. Returns a new tensor with the signed angles\n",
      "        in radians between vector :math:`(\\text{other}_{i}, \\text{input}_{i})`\n",
      "        and vector :math:`(1, 0)`. (Note that :math:`\\text{other}_{i}`, the second\n",
      "        parameter, is the x-coordinate, while :math:`\\text{input}_{i}`, the first\n",
      "        parameter, is the y-coordinate.)\n",
      "        \n",
      "        The shapes of ``input`` and ``other`` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the first input tensor\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.9041,  0.0196, -0.3108, -2.4423])\n",
      "            >>> torch.atan2(a, torch.randn(4))\n",
      "            tensor([ 0.9833,  0.0811, -1.9743, -1.4151])\n",
      "    \n",
      "    atan_(...)\n",
      "    \n",
      "    atanh(...)\n",
      "        atanh(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the inverse hyperbolic tangent of the elements of :attr:`input`.\n",
      "        \n",
      "        Note:\n",
      "            The domain of the inverse hyperbolic tangent is `(-1, 1)` and values outside this range\n",
      "            will be mapped to ``NaN``, except for the values `1` and `-1` for which the output is\n",
      "            mapped to `+/-INF` respectively.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\tanh^{-1}(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4).uniform_(-1, 1)\n",
      "            >>> a\n",
      "            tensor([ -0.9385, 0.2968, -0.8591, -0.1871 ])\n",
      "            >>> torch.atanh(a)\n",
      "            tensor([ -1.7253, 0.3060, -1.2899, -0.1893 ])\n",
      "    \n",
      "    atanh_(...)\n",
      "    \n",
      "    atleast_1d(*tensors)\n",
      "        Returns a 1-dimensional view of each input tensor with zero dimensions.\n",
      "        Input tensors with one or more dimensions are returned as-is.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor or list of Tensors)\n",
      "        \n",
      "        Returns:\n",
      "            output (Tensor or tuple of Tensors)\n",
      "        \n",
      "        Example::\n",
      "            >>> x = torch.randn(2)\n",
      "            >>> x\n",
      "            tensor([1.4584, 0.7583])\n",
      "            >>> torch.atleast_1d(x)\n",
      "            tensor([1.4584, 0.7583])\n",
      "            >>> x = torch.tensor(1.)\n",
      "            >>> x\n",
      "            tensor(1.)\n",
      "            >>> torch.atleast_1d(x)\n",
      "            tensor([1.])\n",
      "            >>> x = torch.tensor(0.5)\n",
      "            >>> y = torch.tensor(1.)\n",
      "            >>> torch.atleast_1d((x,y))\n",
      "            (tensor([0.5000]), tensor([1.]))\n",
      "    \n",
      "    atleast_2d(*tensors)\n",
      "        Returns a 2-dimensional view of each input tensor with zero dimensions.\n",
      "        Input tensors with two or more dimensions are returned as-is.\n",
      "        Args:\n",
      "            input (Tensor or list of Tensors)\n",
      "        \n",
      "        Returns:\n",
      "            output (Tensor or tuple of Tensors)\n",
      "        \n",
      "        Example::\n",
      "            >>> x = torch.tensor(1.)\n",
      "            >>> x\n",
      "            tensor(1.)\n",
      "            >>> torch.atleast_2d(x)\n",
      "            tensor([[1.]])\n",
      "            >>> x = torch.randn(2,2)\n",
      "            >>> x\n",
      "            tensor([[2.2086, 2.5165],\n",
      "                    [0.1757, 0.5194]])\n",
      "            >>> torch.atleast_2d(x)\n",
      "            tensor([[2.2086, 2.5165],\n",
      "                    [0.1757, 0.5194]])\n",
      "            >>> x = torch.tensor(0.5)\n",
      "            >>> y = torch.tensor(1.)\n",
      "            >>> torch.atleast_2d((x,y))\n",
      "            (tensor([[0.5000]]), tensor([[1.]]))\n",
      "    \n",
      "    atleast_3d(*tensors)\n",
      "        Returns a 3-dimensional view of each input tensor with zero dimensions.\n",
      "        Input tensors with three or more dimensions are returned as-is.\n",
      "        Args:\n",
      "            input (Tensor or list of Tensors)\n",
      "        \n",
      "        Returns:\n",
      "            output (Tensor or tuple of Tensors)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "            >>> x = torch.tensor(0.5)\n",
      "            >>> x\n",
      "            tensor(0.5000)\n",
      "            >>> torch.atleast_3d(x)\n",
      "            tensor([[[0.5000]]])\n",
      "            >>> y = torch.randn(2,2)\n",
      "            >>> y\n",
      "            tensor([[-0.8079,  0.7460],\n",
      "                    [-1.1647,  1.4734]])\n",
      "            >>> torch.atleast_3d(y)\n",
      "            tensor([[[-0.8079],\n",
      "                    [ 0.7460]],\n",
      "                    <BLANKLINE>\n",
      "                    [[-1.1647],\n",
      "                    [ 1.4734]]])\n",
      "            >>> x = torch.randn(1,1,1)\n",
      "            >>> x\n",
      "            tensor([[[-1.5689]]])\n",
      "            >>> torch.atleast_3d(x)\n",
      "            tensor([[[-1.5689]]])\n",
      "            >>> x = torch.tensor(0.5)\n",
      "            >>> y = torch.tensor(1.)\n",
      "            >>> torch.atleast_3d((x,y))\n",
      "            (tensor([[[0.5000]]]), tensor([[[1.]]]))\n",
      "    \n",
      "    autocast_decrement_nesting(...)\n",
      "    \n",
      "    autocast_increment_nesting(...)\n",
      "    \n",
      "    avg_pool1d(...)\n",
      "        avg_pool1d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True) -> Tensor\n",
      "        \n",
      "        Applies a 1D average pooling over an input signal composed of several\n",
      "        input planes.\n",
      "        \n",
      "        See :class:`~torch.nn.AvgPool1d` for details and output shape.\n",
      "        \n",
      "        Args:\n",
      "            input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iW)`\n",
      "            kernel_size: the size of the window. Can be a single number or a\n",
      "              tuple `(kW,)`\n",
      "            stride: the stride of the window. Can be a single number or a tuple\n",
      "              `(sW,)`. Default: :attr:`kernel_size`\n",
      "            padding: implicit zero paddings on both sides of the input. Can be a\n",
      "              single number or a tuple `(padW,)`. Default: 0\n",
      "            ceil_mode: when True, will use `ceil` instead of `floor` to compute the\n",
      "                output shape. Default: ``False``\n",
      "            count_include_pad: when True, will include the zero-padding in the\n",
      "                averaging calculation. Default: ``True``\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> # pool of square window of size=3, stride=2\n",
      "            >>> input = torch.tensor([[[1, 2, 3, 4, 5, 6, 7]]], dtype=torch.float32)\n",
      "            >>> F.avg_pool1d(input, kernel_size=3, stride=2)\n",
      "            tensor([[[ 2.,  4.,  6.]]])\n",
      "    \n",
      "    baddbmm(...)\n",
      "        baddbmm(input, batch1, batch2, *, beta=1, alpha=1, out=None) -> Tensor\n",
      "        \n",
      "        Performs a batch matrix-matrix product of matrices in :attr:`batch1`\n",
      "        and :attr:`batch2`.\n",
      "        :attr:`input` is added to the final result.\n",
      "        \n",
      "        :attr:`batch1` and :attr:`batch2` must be 3-D tensors each containing the same\n",
      "        number of matrices.\n",
      "        \n",
      "        If :attr:`batch1` is a :math:`(b \\times n \\times m)` tensor, :attr:`batch2` is a\n",
      "        :math:`(b \\times m \\times p)` tensor, then :attr:`input` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>` with a\n",
      "        :math:`(b \\times n \\times p)` tensor and :attr:`out` will be a\n",
      "        :math:`(b \\times n \\times p)` tensor. Both :attr:`alpha` and :attr:`beta` mean the\n",
      "        same as the scaling factors used in :meth:`torch.addbmm`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = \\beta\\ \\text{input}_i + \\alpha\\ (\\text{batch1}_i \\mathbin{@} \\text{batch2}_i)\n",
      "        \n",
      "        If :attr:`beta` is 0, then :attr:`input` will be ignored, and `nan` and `inf` in\n",
      "        it will not be propagated.\n",
      "        \n",
      "        For inputs of type `FloatTensor` or `DoubleTensor`, arguments :attr:`beta` and\n",
      "        :attr:`alpha` must be real numbers, otherwise they should be integers.\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to be added\n",
      "            batch1 (Tensor): the first batch of matrices to be multiplied\n",
      "            batch2 (Tensor): the second batch of matrices to be multiplied\n",
      "        \n",
      "        Keyword args:\n",
      "            beta (Number, optional): multiplier for :attr:`input` (:math:`\\beta`)\n",
      "            alpha (Number, optional): multiplier for :math:`\\text{batch1} \\mathbin{@} \\text{batch2}` (:math:`\\alpha`)\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> M = torch.randn(10, 3, 5)\n",
      "            >>> batch1 = torch.randn(10, 3, 4)\n",
      "            >>> batch2 = torch.randn(10, 4, 5)\n",
      "            >>> torch.baddbmm(M, batch1, batch2).size()\n",
      "            torch.Size([10, 3, 5])\n",
      "    \n",
      "    bartlett_window(...)\n",
      "        bartlett_window(window_length, periodic=True, *, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Bartlett window function.\n",
      "        \n",
      "        .. math::\n",
      "            w[n] = 1 - \\left| \\frac{2n}{N-1} - 1 \\right| = \\begin{cases}\n",
      "                \\frac{2n}{N - 1} & \\text{if } 0 \\leq n \\leq \\frac{N - 1}{2} \\\\\n",
      "                2 - \\frac{2n}{N - 1} & \\text{if } \\frac{N - 1}{2} < n < N \\\\\n",
      "            \\end{cases},\n",
      "        \n",
      "        where :math:`N` is the full window size.\n",
      "        \n",
      "        The input :attr:`window_length` is a positive integer controlling the\n",
      "        returned window size. :attr:`periodic` flag determines whether the returned\n",
      "        window trims off the last duplicate value from the symmetric window and is\n",
      "        ready to be used as a periodic window with functions like\n",
      "        :meth:`torch.stft`. Therefore, if :attr:`periodic` is true, the :math:`N` in\n",
      "        above formula is in fact :math:`\\text{window\\_length} + 1`. Also, we always have\n",
      "        ``torch.bartlett_window(L, periodic=True)`` equal to\n",
      "        ``torch.bartlett_window(L + 1, periodic=False)[:-1])``.\n",
      "        \n",
      "        .. note::\n",
      "            If :attr:`window_length` :math:`=1`, the returned window contains a single value 1.\n",
      "        \n",
      "        Arguments:\n",
      "            window_length (int): the size of returned window\n",
      "            periodic (bool, optional): If True, returns a window to be used as periodic\n",
      "                function. If False, return a symmetric window.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`). Only floating point types are supported.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned window tensor. Only\n",
      "                  ``torch.strided`` (dense layout) is supported.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A 1-D tensor of size :math:`(\\text{window\\_length},)` containing the window\n",
      "    \n",
      "    batch_norm(...)\n",
      "    \n",
      "    batch_norm_backward_elemt(...)\n",
      "    \n",
      "    batch_norm_backward_reduce(...)\n",
      "    \n",
      "    batch_norm_elemt(...)\n",
      "    \n",
      "    batch_norm_gather_stats(...)\n",
      "    \n",
      "    batch_norm_gather_stats_with_counts(...)\n",
      "    \n",
      "    batch_norm_stats(...)\n",
      "    \n",
      "    batch_norm_update_stats(...)\n",
      "    \n",
      "    bernoulli(...)\n",
      "        bernoulli(input, *, generator=None, out=None) -> Tensor\n",
      "        \n",
      "        Draws binary random numbers (0 or 1) from a Bernoulli distribution.\n",
      "        \n",
      "        The :attr:`input` tensor should be a tensor containing probabilities\n",
      "        to be used for drawing the binary random number.\n",
      "        Hence, all values in :attr:`input` have to be in the range:\n",
      "        :math:`0 \\leq \\text{input}_i \\leq 1`.\n",
      "        \n",
      "        The :math:`\\text{i}^{th}` element of the output tensor will draw a\n",
      "        value :math:`1` according to the :math:`\\text{i}^{th}` probability value given\n",
      "        in :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} \\sim \\mathrm{Bernoulli}(p = \\text{input}_{i})\n",
      "        \n",
      "        The returned :attr:`out` tensor only has values 0 or 1 and is of the same\n",
      "        shape as :attr:`input`.\n",
      "        \n",
      "        :attr:`out` can have integral ``dtype``, but :attr:`input` must have floating\n",
      "        point ``dtype``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor of probability values for the Bernoulli distribution\n",
      "        \n",
      "        Keyword args:\n",
      "            generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.empty(3, 3).uniform_(0, 1)  # generate a uniform random matrix with range [0, 1]\n",
      "            >>> a\n",
      "            tensor([[ 0.1737,  0.0950,  0.3609],\n",
      "                    [ 0.7148,  0.0289,  0.2676],\n",
      "                    [ 0.9456,  0.8937,  0.7202]])\n",
      "            >>> torch.bernoulli(a)\n",
      "            tensor([[ 1.,  0.,  0.],\n",
      "                    [ 0.,  0.,  0.],\n",
      "                    [ 1.,  1.,  1.]])\n",
      "        \n",
      "            >>> a = torch.ones(3, 3) # probability of drawing \"1\" is 1\n",
      "            >>> torch.bernoulli(a)\n",
      "            tensor([[ 1.,  1.,  1.],\n",
      "                    [ 1.,  1.,  1.],\n",
      "                    [ 1.,  1.,  1.]])\n",
      "            >>> a = torch.zeros(3, 3) # probability of drawing \"1\" is 0\n",
      "            >>> torch.bernoulli(a)\n",
      "            tensor([[ 0.,  0.,  0.],\n",
      "                    [ 0.,  0.,  0.],\n",
      "                    [ 0.,  0.,  0.]])\n",
      "    \n",
      "    bilinear(...)\n",
      "    \n",
      "    binary_cross_entropy_with_logits(...)\n",
      "    \n",
      "    bincount(...)\n",
      "        bincount(input, weights=None, minlength=0) -> Tensor\n",
      "        \n",
      "        Count the frequency of each value in an array of non-negative ints.\n",
      "        \n",
      "        The number of bins (size 1) is one larger than the largest value in\n",
      "        :attr:`input` unless :attr:`input` is empty, in which case the result is a\n",
      "        tensor of size 0. If :attr:`minlength` is specified, the number of bins is at least\n",
      "        :attr:`minlength` and if :attr:`input` is empty, then the result is tensor of size\n",
      "        :attr:`minlength` filled with zeros. If ``n`` is the value at position ``i``,\n",
      "        ``out[n] += weights[i]`` if :attr:`weights` is specified else\n",
      "        ``out[n] += 1``.\n",
      "        \n",
      "        Note:\n",
      "            This operation may produce nondeterministic gradients when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): 1-d int tensor\n",
      "            weights (Tensor): optional, weight for each value in the input tensor.\n",
      "                Should be of same size as input tensor.\n",
      "            minlength (int): optional, minimum number of bins. Should be non-negative.\n",
      "        \n",
      "        Returns:\n",
      "            output (Tensor): a tensor of shape ``Size([max(input) + 1])`` if\n",
      "            :attr:`input` is non-empty, else ``Size(0)``\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> input = torch.randint(0, 8, (5,), dtype=torch.int64)\n",
      "            >>> weights = torch.linspace(0, 1, steps=5)\n",
      "            >>> input, weights\n",
      "            (tensor([4, 3, 6, 3, 4]),\n",
      "             tensor([ 0.0000,  0.2500,  0.5000,  0.7500,  1.0000])\n",
      "        \n",
      "            >>> torch.bincount(input)\n",
      "            tensor([0, 0, 0, 2, 2, 0, 1])\n",
      "        \n",
      "            >>> input.bincount(weights)\n",
      "            tensor([0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.5000])\n",
      "    \n",
      "    binomial(...)\n",
      "    \n",
      "    bitwise_and(...)\n",
      "        bitwise_and(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the bitwise AND of :attr:`input` and :attr:`other`. The input tensor must be of\n",
      "        integral or Boolean types. For bool tensors, it computes the logical AND.\n",
      "        \n",
      "        Args:\n",
      "            input: the first input tensor\n",
      "            other: the second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "            >>> torch.bitwise_and(torch.tensor([-1, -2, 3], dtype=torch.int8), torch.tensor([1, 0, 3], dtype=torch.int8))\n",
      "            tensor([1, 0,  3], dtype=torch.int8)\n",
      "            >>> torch.bitwise_and(torch.tensor([True, True, False]), torch.tensor([False, True, False]))\n",
      "            tensor([ False, True, False])\n",
      "    \n",
      "    bitwise_not(...)\n",
      "        bitwise_not(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the bitwise NOT of the given input tensor. The input tensor must be of\n",
      "        integral or Boolean types. For bool tensors, it computes the logical NOT.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "            >>> torch.bitwise_not(torch.tensor([-1, -2, 3], dtype=torch.int8))\n",
      "            tensor([ 0,  1, -4], dtype=torch.int8)\n",
      "    \n",
      "    bitwise_or(...)\n",
      "        bitwise_or(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the bitwise OR of :attr:`input` and :attr:`other`. The input tensor must be of\n",
      "        integral or Boolean types. For bool tensors, it computes the logical OR.\n",
      "        \n",
      "        Args:\n",
      "            input: the first input tensor\n",
      "            other: the second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "            >>> torch.bitwise_or(torch.tensor([-1, -2, 3], dtype=torch.int8), torch.tensor([1, 0, 3], dtype=torch.int8))\n",
      "            tensor([-1, -2,  3], dtype=torch.int8)\n",
      "            >>> torch.bitwise_or(torch.tensor([True, True, False]), torch.tensor([False, True, False]))\n",
      "            tensor([ True, True, False])\n",
      "    \n",
      "    bitwise_xor(...)\n",
      "        bitwise_xor(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the bitwise XOR of :attr:`input` and :attr:`other`. The input tensor must be of\n",
      "        integral or Boolean types. For bool tensors, it computes the logical XOR.\n",
      "        \n",
      "        Args:\n",
      "            input: the first input tensor\n",
      "            other: the second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "            >>> torch.bitwise_xor(torch.tensor([-1, -2, 3], dtype=torch.int8), torch.tensor([1, 0, 3], dtype=torch.int8))\n",
      "            tensor([-2, -2,  0], dtype=torch.int8)\n",
      "            >>> torch.bitwise_xor(torch.tensor([True, True, False]), torch.tensor([False, True, False]))\n",
      "            tensor([ True, False, False])\n",
      "    \n",
      "    blackman_window(...)\n",
      "        blackman_window(window_length, periodic=True, *, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Blackman window function.\n",
      "        \n",
      "        .. math::\n",
      "            w[n] = 0.42 - 0.5 \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right) + 0.08 \\cos \\left( \\frac{4 \\pi n}{N - 1} \\right)\n",
      "        \n",
      "        where :math:`N` is the full window size.\n",
      "        \n",
      "        The input :attr:`window_length` is a positive integer controlling the\n",
      "        returned window size. :attr:`periodic` flag determines whether the returned\n",
      "        window trims off the last duplicate value from the symmetric window and is\n",
      "        ready to be used as a periodic window with functions like\n",
      "        :meth:`torch.stft`. Therefore, if :attr:`periodic` is true, the :math:`N` in\n",
      "        above formula is in fact :math:`\\text{window\\_length} + 1`. Also, we always have\n",
      "        ``torch.blackman_window(L, periodic=True)`` equal to\n",
      "        ``torch.blackman_window(L + 1, periodic=False)[:-1])``.\n",
      "        \n",
      "        .. note::\n",
      "            If :attr:`window_length` :math:`=1`, the returned window contains a single value 1.\n",
      "        \n",
      "        Arguments:\n",
      "            window_length (int): the size of returned window\n",
      "            periodic (bool, optional): If True, returns a window to be used as periodic\n",
      "                function. If False, return a symmetric window.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`). Only floating point types are supported.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned window tensor. Only\n",
      "                  ``torch.strided`` (dense layout) is supported.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A 1-D tensor of size :math:`(\\text{window\\_length},)` containing the window\n",
      "    \n",
      "    block_diag(*tensors)\n",
      "        Create a block diagonal matrix from provided tensors.\n",
      "        \n",
      "        Args:\n",
      "            *tensors: One or more tensors with 0, 1, or 2 dimensions.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A 2 dimensional tensor with all the input tensors arranged in\n",
      "                order such that their upper left and lower right corners are\n",
      "                diagonally adjacent. All other elements are set to 0.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> import torch\n",
      "            >>> A = torch.tensor([[0, 1], [1, 0]])\n",
      "            >>> B = torch.tensor([[3, 4, 5], [6, 7, 8]])\n",
      "            >>> C = torch.tensor(7)\n",
      "            >>> D = torch.tensor([1, 2, 3])\n",
      "            >>> E = torch.tensor([[4], [5], [6]])\n",
      "            >>> torch.block_diag(A, B, C, D, E)\n",
      "            tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "                    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "                    [0, 0, 3, 4, 5, 0, 0, 0, 0, 0],\n",
      "                    [0, 0, 6, 7, 8, 0, 0, 0, 0, 0],\n",
      "                    [0, 0, 0, 0, 0, 7, 0, 0, 0, 0],\n",
      "                    [0, 0, 0, 0, 0, 0, 1, 2, 3, 0],\n",
      "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 4],\n",
      "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],\n",
      "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 6]])\n",
      "    \n",
      "    bmm(...)\n",
      "        bmm(input, mat2, *, deterministic=False, out=None) -> Tensor\n",
      "        \n",
      "        Performs a batch matrix-matrix product of matrices stored in :attr:`input`\n",
      "        and :attr:`mat2`.\n",
      "        \n",
      "        :attr:`input` and :attr:`mat2` must be 3-D tensors each containing\n",
      "        the same number of matrices.\n",
      "        \n",
      "        If :attr:`input` is a :math:`(b \\times n \\times m)` tensor, :attr:`mat2` is a\n",
      "        :math:`(b \\times m \\times p)` tensor, :attr:`out` will be a\n",
      "        :math:`(b \\times n \\times p)` tensor.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = \\text{input}_i \\mathbin{@} \\text{mat2}_i\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        .. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
      "                  For broadcasting matrix products, see :func:`torch.matmul`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the first batch of matrices to be multiplied\n",
      "            mat2 (Tensor): the second batch of matrices to be multiplied\n",
      "        \n",
      "        Keyword Args:\n",
      "            deterministic (bool, optional): flag to choose between a faster non-deterministic\n",
      "                                            calculation, or a slower deterministic calculation.\n",
      "                                            This argument is only available for sparse-dense CUDA bmm.\n",
      "                                            Default: ``False``\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> input = torch.randn(10, 3, 4)\n",
      "            >>> mat2 = torch.randn(10, 4, 5)\n",
      "            >>> res = torch.bmm(input, mat2)\n",
      "            >>> res.size()\n",
      "            torch.Size([10, 3, 5])\n",
      "    \n",
      "    broadcast_tensors(*tensors)\n",
      "        broadcast_tensors(*tensors) -> List of Tensors\n",
      "        \n",
      "        Broadcasts the given tensors according to :ref:`broadcasting-semantics`.\n",
      "        \n",
      "        Args:\n",
      "            *tensors: any number of tensors of the same type\n",
      "        \n",
      "        .. warning::\n",
      "        \n",
      "            More than one element of a broadcasted tensor may refer to a single\n",
      "            memory location. As a result, in-place operations (especially ones that\n",
      "            are vectorized) may result in incorrect behavior. If you need to write\n",
      "            to the tensors, please clone them first.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.arange(3).view(1, 3)\n",
      "            >>> y = torch.arange(2).view(2, 1)\n",
      "            >>> a, b = torch.broadcast_tensors(x, y)\n",
      "            >>> a.size()\n",
      "            torch.Size([2, 3])\n",
      "            >>> a\n",
      "            tensor([[0, 1, 2],\n",
      "                    [0, 1, 2]])\n",
      "    \n",
      "    broadcast_to(...)\n",
      "        broadcast_to(input, shape) -> Tensor\n",
      "        \n",
      "        Broadcasts :attr:`input` to the shape :attr:`\\shape`.\n",
      "        Equivalent to calling ``input.expand(shape)``. See :meth:`~Tensor.expand` for details.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            shape (list, tuple, or :class:`torch.Size`): the new shape.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.tensor([1, 2, 3])\n",
      "            >>> torch.broadcast_to(x, (3, 3))\n",
      "            tensor([[1, 2, 3],\n",
      "                    [1, 2, 3],\n",
      "                    [1, 2, 3]])\n",
      "    \n",
      "    bucketize(...)\n",
      "        bucketize(input, boundaries, *, out_int32=False, right=False, out=None) -> Tensor\n",
      "        \n",
      "        Returns the indices of the buckets to which each value in the :attr:`input` belongs, where the\n",
      "        boundaries of the buckets are set by :attr:`boundaries`. Return a new tensor with the same size\n",
      "        as :attr:`input`. If :attr:`right` is False (default), then the left boundary is closed. More\n",
      "        formally, the returned index satisfies the following rules:\n",
      "        \n",
      "        .. list-table::\n",
      "           :widths: 15 85\n",
      "           :header-rows: 1\n",
      "        \n",
      "           * - :attr:`right`\n",
      "             - *returned index satisfies*\n",
      "           * - False\n",
      "             - ``boundaries[i-1] < input[m][n]...[l][x] <= boundaries[i]``\n",
      "           * - True\n",
      "             - ``boundaries[i-1] <= input[m][n]...[l][x] < boundaries[i]``\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor or Scalar): N-D tensor or a Scalar containing the search value(s).\n",
      "            boundaries (Tensor): 1-D tensor, must contain a monotonically increasing sequence.\n",
      "        \n",
      "        Keyword args:\n",
      "            out_int32 (bool, optional): indicate the output data type. torch.int32 if True, torch.int64 otherwise.\n",
      "                                        Default value is False, i.e. default output data type is torch.int64.\n",
      "            right (bool, optional): if False, return the first suitable location that is found. If True, return the\n",
      "                                    last such index. If no suitable index found, return 0 for non-numerical value\n",
      "                                    (eg. nan, inf) or the size of :attr:`boundaries` (one pass the last index).\n",
      "                                    In other words, if False, gets the lower bound index for each value in :attr:`input`\n",
      "                                    from :attr:`boundaries`. If True, gets the upper bound index instead.\n",
      "                                    Default value is False.\n",
      "            out (Tensor, optional): the output tensor, must be the same size as :attr:`input` if provided.\n",
      "        \n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> boundaries = torch.tensor([1, 3, 5, 7, 9])\n",
      "            >>> boundaries\n",
      "            tensor([1, 3, 5, 7, 9])\n",
      "            >>> v = torch.tensor([[3, 6, 9], [3, 6, 9]])\n",
      "            >>> v\n",
      "            tensor([[3, 6, 9],\n",
      "                    [3, 6, 9]])\n",
      "            >>> torch.bucketize(v, boundaries)\n",
      "            tensor([[1, 3, 4],\n",
      "                    [1, 3, 4]])\n",
      "            >>> torch.bucketize(v, boundaries, right=True)\n",
      "            tensor([[2, 3, 5],\n",
      "                    [2, 3, 5]])\n",
      "    \n",
      "    can_cast(...)\n",
      "        can_cast(from, to) -> bool\n",
      "        \n",
      "        Determines if a type conversion is allowed under PyTorch casting rules\n",
      "        described in the type promotion :ref:`documentation <type-promotion-doc>`.\n",
      "        \n",
      "        Args:\n",
      "            from (dtype): The original :class:`torch.dtype`.\n",
      "            to (dtype): The target :class:`torch.dtype`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.can_cast(torch.double, torch.float)\n",
      "            True\n",
      "            >>> torch.can_cast(torch.float, torch.int)\n",
      "            False\n",
      "    \n",
      "    cartesian_prod(*tensors)\n",
      "        Do cartesian product of the given sequence of tensors. The behavior is similar to\n",
      "        python's `itertools.product`.\n",
      "        \n",
      "        Args:\n",
      "            *tensors: any number of 1 dimensional tensors.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A tensor equivalent to converting all the input tensors into lists,\n",
      "                do `itertools.product` on these lists, and finally convert the resulting list\n",
      "                into tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = [1, 2, 3]\n",
      "            >>> b = [4, 5]\n",
      "            >>> list(itertools.product(a, b))\n",
      "            [(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)]\n",
      "            >>> tensor_a = torch.tensor(a)\n",
      "            >>> tensor_b = torch.tensor(b)\n",
      "            >>> torch.cartesian_prod(tensor_a, tensor_b)\n",
      "            tensor([[1, 4],\n",
      "                    [1, 5],\n",
      "                    [2, 4],\n",
      "                    [2, 5],\n",
      "                    [3, 4],\n",
      "                    [3, 5]])\n",
      "    \n",
      "    cat(...)\n",
      "        cat(tensors, dim=0, *, out=None) -> Tensor\n",
      "        \n",
      "        Concatenates the given sequence of :attr:`seq` tensors in the given dimension.\n",
      "        All tensors must either have the same shape (except in the concatenating\n",
      "        dimension) or be empty.\n",
      "        \n",
      "        :func:`torch.cat` can be seen as an inverse operation for :func:`torch.split`\n",
      "        and :func:`torch.chunk`.\n",
      "        \n",
      "        :func:`torch.cat` can be best understood via examples.\n",
      "        \n",
      "        Args:\n",
      "            tensors (sequence of Tensors): any python sequence of tensors of the same type.\n",
      "                Non-empty tensors provided must have the same shape, except in the\n",
      "                cat dimension.\n",
      "            dim (int, optional): the dimension over which the tensors are concatenated\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.randn(2, 3)\n",
      "            >>> x\n",
      "            tensor([[ 0.6580, -1.0969, -0.4614],\n",
      "                    [-0.1034, -0.5790,  0.1497]])\n",
      "            >>> torch.cat((x, x, x), 0)\n",
      "            tensor([[ 0.6580, -1.0969, -0.4614],\n",
      "                    [-0.1034, -0.5790,  0.1497],\n",
      "                    [ 0.6580, -1.0969, -0.4614],\n",
      "                    [-0.1034, -0.5790,  0.1497],\n",
      "                    [ 0.6580, -1.0969, -0.4614],\n",
      "                    [-0.1034, -0.5790,  0.1497]])\n",
      "            >>> torch.cat((x, x, x), 1)\n",
      "            tensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,\n",
      "                     -1.0969, -0.4614],\n",
      "                    [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,\n",
      "                     -0.5790,  0.1497]])\n",
      "    \n",
      "    cdist(x1, x2, p=2.0, compute_mode='use_mm_for_euclid_dist_if_necessary')\n",
      "        Computes batched the p-norm distance between each pair of the two collections of row vectors.\n",
      "        \n",
      "        Args:\n",
      "            x1 (Tensor): input tensor of shape :math:`B \\times P \\times M`.\n",
      "            x2 (Tensor): input tensor of shape :math:`B \\times R \\times M`.\n",
      "            p: p value for the p-norm distance to calculate between each vector pair\n",
      "                :math:`\\in [0, \\infty]`.\n",
      "            compute_mode:\n",
      "                'use_mm_for_euclid_dist_if_necessary' - will use matrix multiplication approach to calculate\n",
      "                euclidean distance (p = 2) if P > 25 or R > 25\n",
      "                'use_mm_for_euclid_dist' - will always use matrix multiplication approach to calculate\n",
      "                euclidean distance (p = 2)\n",
      "                'donot_use_mm_for_euclid_dist' - will never use matrix multiplication approach to calculate\n",
      "                euclidean distance (p = 2)\n",
      "                Default: use_mm_for_euclid_dist_if_necessary.\n",
      "        \n",
      "        If x1 has shape :math:`B \\times P \\times M` and x2 has shape :math:`B \\times R \\times M` then the\n",
      "        output will have shape :math:`B \\times P \\times R`.\n",
      "        \n",
      "        This function is equivalent to `scipy.spatial.distance.cdist(input,'minkowski', p=p)`\n",
      "        if :math:`p \\in (0, \\infty)`. When :math:`p = 0` it is equivalent to\n",
      "        `scipy.spatial.distance.cdist(input, 'hamming') * M`. When :math:`p = \\infty`, the closest\n",
      "        scipy function is `scipy.spatial.distance.cdist(xn, lambda x, y: np.abs(x - y).max())`.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "            >>> a = torch.tensor([[0.9041,  0.0196], [-0.3108, -2.4423], [-0.4821,  1.059]])\n",
      "            >>> a\n",
      "            tensor([[ 0.9041,  0.0196],\n",
      "                    [-0.3108, -2.4423],\n",
      "                    [-0.4821,  1.0590]])\n",
      "            >>> b = torch.tensor([[-2.1763, -0.4713], [-0.6986,  1.3702]])\n",
      "            >>> b\n",
      "            tensor([[-2.1763, -0.4713],\n",
      "                    [-0.6986,  1.3702]])\n",
      "            >>> torch.cdist(a, b, p=2)\n",
      "            tensor([[3.1193, 2.0959],\n",
      "                    [2.7138, 3.8322],\n",
      "                    [2.2830, 0.3791]])\n",
      "    \n",
      "    ceil(...)\n",
      "        ceil(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the ceil of the elements of :attr:`input`,\n",
      "        the smallest integer greater than or equal to each element.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\left\\lceil \\text{input}_{i} \\right\\rceil = \\left\\lfloor \\text{input}_{i} \\right\\rfloor + 1\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-0.6341, -1.4208, -1.0900,  0.5826])\n",
      "            >>> torch.ceil(a)\n",
      "            tensor([-0., -1., -1.,  1.])\n",
      "    \n",
      "    ceil_(...)\n",
      "    \n",
      "    celu(...)\n",
      "    \n",
      "    celu_(...)\n",
      "        celu_(input, alpha=1.) -> Tensor\n",
      "        \n",
      "        In-place version of :func:`~celu`.\n",
      "    \n",
      "    chain_matmul(*matrices)\n",
      "        Returns the matrix product of the :math:`N` 2-D tensors. This product is efficiently computed\n",
      "        using the matrix chain order algorithm which selects the order in which incurs the lowest cost in terms\n",
      "        of arithmetic operations (`[CLRS]`_). Note that since this is a function to compute the product, :math:`N`\n",
      "        needs to be greater than or equal to 2; if equal to 2 then a trivial matrix-matrix product is returned.\n",
      "        If :math:`N` is 1, then this is a no-op - the original matrix is returned as is.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            matrices (Tensors...): a sequence of 2 or more 2-D tensors whose product is to be determined.\n",
      "        \n",
      "        \n",
      "        Returns:\n",
      "            Tensor: if the :math:`i^{th}` tensor was of dimensions :math:`p_{i} \\times p_{i + 1}`, then the product\n",
      "            would be of dimensions :math:`p_{1} \\times p_{N + 1}`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(3, 4)\n",
      "            >>> b = torch.randn(4, 5)\n",
      "            >>> c = torch.randn(5, 6)\n",
      "            >>> d = torch.randn(6, 7)\n",
      "            >>> torch.chain_matmul(a, b, c, d)\n",
      "            tensor([[ -2.3375,  -3.9790,  -4.1119,  -6.6577,   9.5609, -11.5095,  -3.2614],\n",
      "                    [ 21.4038,   3.3378,  -8.4982,  -5.2457, -10.2561,  -2.4684,   2.7163],\n",
      "                    [ -0.9647,  -5.8917,  -2.3213,  -5.2284,  12.8615, -12.2816,  -2.5095]])\n",
      "        \n",
      "        .. _`[CLRS]`: https://mitpress.mit.edu/books/introduction-algorithms-third-edition\n",
      "    \n",
      "    channel_shuffle(...)\n",
      "        channel_shuffle(input, groups) -> Tensor\n",
      "        \n",
      "        Divide the channels in a tensor of shape :math:`(*, C , H, W)`\n",
      "        into g groups and rearrange them as :math:`(*, C \\frac g, g, H, W)`,\n",
      "        while keeping the original tensor shape.\n",
      "        \n",
      "        See :class:`~torch.nn.ChannelShuffle` for details.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor\n",
      "            groups (int): number of groups to divide channels in and rearrange.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> input = torch.randn(1, 4, 2, 2)\n",
      "            >>> print(input)\n",
      "            [[[[1, 2],\n",
      "               [3, 4]],\n",
      "              [[5, 6],\n",
      "               [7, 8]],\n",
      "              [[9, 10],\n",
      "               [11, 12]],\n",
      "              [[13, 14],\n",
      "               [15, 16]],\n",
      "             ]]\n",
      "            >>> output = torch.nn.functional.channel_shuffle(input, 2)\n",
      "            >>> print(output)\n",
      "            [[[[1, 2],\n",
      "               [3, 4]],\n",
      "              [[9, 10],\n",
      "               [11, 12]],\n",
      "              [[5, 6],\n",
      "               [7, 8]],\n",
      "              [[13, 14],\n",
      "               [15, 16]],\n",
      "             ]]\n",
      "    \n",
      "    cholesky(...)\n",
      "        cholesky(input, upper=False, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the Cholesky decomposition of a symmetric positive-definite\n",
      "        matrix :math:`A` or for batches of symmetric positive-definite matrices.\n",
      "        \n",
      "        If :attr:`upper` is ``True``, the returned matrix ``U`` is upper-triangular, and\n",
      "        the decomposition has the form:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "          A = U^TU\n",
      "        \n",
      "        If :attr:`upper` is ``False``, the returned matrix ``L`` is lower-triangular, and\n",
      "        the decomposition has the form:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            A = LL^T\n",
      "        \n",
      "        If :attr:`upper` is ``True``, and :math:`A` is a batch of symmetric positive-definite\n",
      "        matrices, then the returned tensor will be composed of upper-triangular Cholesky factors\n",
      "        of each of the individual matrices. Similarly, when :attr:`upper` is ``False``, the returned\n",
      "        tensor will be composed of lower-triangular Cholesky factors of each of the individual\n",
      "        matrices.\n",
      "        \n",
      "        .. note:: :func:`torch.linalg.cholesky` should be used over ``torch.cholesky`` when possible.\n",
      "                  Note however that :func:`torch.linalg.cholesky` does not yet support the :attr:`upper`\n",
      "                  parameter and instead always returns the lower triangular matrix.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor :math:`A` of size :math:`(*, n, n)` where `*` is zero or more\n",
      "                        batch dimensions consisting of symmetric positive-definite matrices.\n",
      "            upper (bool, optional): flag that indicates whether to return a\n",
      "                                    upper or lower triangular matrix. Default: ``False``\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output matrix\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(3, 3)\n",
      "            >>> a = torch.mm(a, a.t()) # make symmetric positive-definite\n",
      "            >>> l = torch.cholesky(a)\n",
      "            >>> a\n",
      "            tensor([[ 2.4112, -0.7486,  1.4551],\n",
      "                    [-0.7486,  1.3544,  0.1294],\n",
      "                    [ 1.4551,  0.1294,  1.6724]])\n",
      "            >>> l\n",
      "            tensor([[ 1.5528,  0.0000,  0.0000],\n",
      "                    [-0.4821,  1.0592,  0.0000],\n",
      "                    [ 0.9371,  0.5487,  0.7023]])\n",
      "            >>> torch.mm(l, l.t())\n",
      "            tensor([[ 2.4112, -0.7486,  1.4551],\n",
      "                    [-0.7486,  1.3544,  0.1294],\n",
      "                    [ 1.4551,  0.1294,  1.6724]])\n",
      "            >>> a = torch.randn(3, 2, 2)\n",
      "            >>> a = torch.matmul(a, a.transpose(-1, -2)) + 1e-03 # make symmetric positive-definite\n",
      "            >>> l = torch.cholesky(a)\n",
      "            >>> z = torch.matmul(l, l.transpose(-1, -2))\n",
      "            >>> torch.max(torch.abs(z - a)) # Max non-zero\n",
      "            tensor(2.3842e-07)\n",
      "    \n",
      "    cholesky_inverse(...)\n",
      "        cholesky_inverse(input, upper=False, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the inverse of a symmetric positive-definite matrix :math:`A` using its\n",
      "        Cholesky factor :math:`u`: returns matrix ``inv``. The inverse is computed using\n",
      "        LAPACK routines ``dpotri`` and ``spotri`` (and the corresponding MAGMA routines).\n",
      "        \n",
      "        If :attr:`upper` is ``False``, :math:`u` is lower triangular\n",
      "        such that the returned tensor is\n",
      "        \n",
      "        .. math::\n",
      "            inv = (uu^{{T}})^{{-1}}\n",
      "        \n",
      "        If :attr:`upper` is ``True`` or not provided, :math:`u` is upper\n",
      "        triangular such that the returned tensor is\n",
      "        \n",
      "        .. math::\n",
      "            inv = (u^T u)^{{-1}}\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input 2-D tensor :math:`u`, a upper or lower triangular\n",
      "                   Cholesky factor\n",
      "            upper (bool, optional): whether to return a lower (default) or upper triangular matrix\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor for `inv`\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(3, 3)\n",
      "            >>> a = torch.mm(a, a.t()) + 1e-05 * torch.eye(3) # make symmetric positive definite\n",
      "            >>> u = torch.cholesky(a)\n",
      "            >>> a\n",
      "            tensor([[  0.9935,  -0.6353,   1.5806],\n",
      "                    [ -0.6353,   0.8769,  -1.7183],\n",
      "                    [  1.5806,  -1.7183,  10.6618]])\n",
      "            >>> torch.cholesky_inverse(u)\n",
      "            tensor([[ 1.9314,  1.2251, -0.0889],\n",
      "                    [ 1.2251,  2.4439,  0.2122],\n",
      "                    [-0.0889,  0.2122,  0.1412]])\n",
      "            >>> a.inverse()\n",
      "            tensor([[ 1.9314,  1.2251, -0.0889],\n",
      "                    [ 1.2251,  2.4439,  0.2122],\n",
      "                    [-0.0889,  0.2122,  0.1412]])\n",
      "    \n",
      "    cholesky_solve(...)\n",
      "        cholesky_solve(input, input2, upper=False, *, out=None) -> Tensor\n",
      "        \n",
      "        Solves a linear system of equations with a positive semidefinite\n",
      "        matrix to be inverted given its Cholesky factor matrix :math:`u`.\n",
      "        \n",
      "        If :attr:`upper` is ``False``, :math:`u` is and lower triangular and `c` is\n",
      "        returned such that:\n",
      "        \n",
      "        .. math::\n",
      "            c = (u u^T)^{{-1}} b\n",
      "        \n",
      "        If :attr:`upper` is ``True`` or not provided, :math:`u` is upper triangular\n",
      "        and `c` is returned such that:\n",
      "        \n",
      "        .. math::\n",
      "            c = (u^T u)^{{-1}} b\n",
      "        \n",
      "        `torch.cholesky_solve(b, u)` can take in 2D inputs `b, u` or inputs that are\n",
      "        batches of 2D matrices. If the inputs are batches, then returns\n",
      "        batched outputs `c`\n",
      "        \n",
      "        Supports real-valued and complex-valued inputs.\n",
      "        For the complex-valued inputs the transpose operator above is the conjugate transpose.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): input matrix :math:`b` of size :math:`(*, m, k)`,\n",
      "                        where :math:`*` is zero or more batch dimensions\n",
      "            input2 (Tensor): input matrix :math:`u` of size :math:`(*, m, m)`,\n",
      "                        where :math:`*` is zero of more batch dimensions composed of\n",
      "                        upper or lower triangular Cholesky factor\n",
      "            upper (bool, optional): whether to consider the Cholesky factor as a\n",
      "                                    lower or upper triangular matrix. Default: ``False``.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor for `c`\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(3, 3)\n",
      "            >>> a = torch.mm(a, a.t()) # make symmetric positive definite\n",
      "            >>> u = torch.cholesky(a)\n",
      "            >>> a\n",
      "            tensor([[ 0.7747, -1.9549,  1.3086],\n",
      "                    [-1.9549,  6.7546, -5.4114],\n",
      "                    [ 1.3086, -5.4114,  4.8733]])\n",
      "            >>> b = torch.randn(3, 2)\n",
      "            >>> b\n",
      "            tensor([[-0.6355,  0.9891],\n",
      "                    [ 0.1974,  1.4706],\n",
      "                    [-0.4115, -0.6225]])\n",
      "            >>> torch.cholesky_solve(b, u)\n",
      "            tensor([[ -8.1625,  19.6097],\n",
      "                    [ -5.8398,  14.2387],\n",
      "                    [ -4.3771,  10.4173]])\n",
      "            >>> torch.mm(a.inverse(), b)\n",
      "            tensor([[ -8.1626,  19.6097],\n",
      "                    [ -5.8398,  14.2387],\n",
      "                    [ -4.3771,  10.4173]])\n",
      "    \n",
      "    choose_qparams_optimized(...)\n",
      "    \n",
      "    chunk(...)\n",
      "        chunk(input, chunks, dim=0) -> List of Tensors\n",
      "        \n",
      "        Splits a tensor into a specific number of chunks. Each chunk is a view of\n",
      "        the input tensor.\n",
      "        \n",
      "        Last chunk will be smaller if the tensor size along the given dimension\n",
      "        :attr:`dim` is not divisible by :attr:`chunks`.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): the tensor to split\n",
      "            chunks (int): number of chunks to return\n",
      "            dim (int): dimension along which to split the tensor\n",
      "    \n",
      "    clamp(...)\n",
      "        clamp(input, min, max, *, out=None) -> Tensor\n",
      "        \n",
      "        Clamp all elements in :attr:`input` into the range `[` :attr:`min`, :attr:`max` `]`.\n",
      "        Let min_value and max_value be :attr:`min` and :attr:`max`, respectively, this returns:\n",
      "        \n",
      "        .. math::\n",
      "            y_i = \\min(\\max(x_i, \\text{min\\_value}), \\text{max\\_value})\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            min (Number): lower-bound of the range to be clamped to\n",
      "            max (Number): upper-bound of the range to be clamped to\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-1.7120,  0.1734, -0.0478, -0.0922])\n",
      "            >>> torch.clamp(a, min=-0.5, max=0.5)\n",
      "            tensor([-0.5000,  0.1734, -0.0478, -0.0922])\n",
      "        \n",
      "        .. function:: clamp(input, *, min, out=None) -> Tensor\n",
      "        \n",
      "        Clamps all elements in :attr:`input` to be larger or equal :attr:`min`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            min (Number): minimal value of each element in the output\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-0.0299, -2.3184,  2.1593, -0.8883])\n",
      "            >>> torch.clamp(a, min=0.5)\n",
      "            tensor([ 0.5000,  0.5000,  2.1593,  0.5000])\n",
      "        \n",
      "        .. function:: clamp(input, *, max, out=None) -> Tensor\n",
      "        \n",
      "        Clamps all elements in :attr:`input` to be smaller or equal :attr:`max`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            max (Number): maximal value of each element in the output\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.7753, -0.4702, -0.4599,  1.1899])\n",
      "            >>> torch.clamp(a, max=0.5)\n",
      "            tensor([ 0.5000, -0.4702, -0.4599,  0.5000])\n",
      "    \n",
      "    clamp_(...)\n",
      "    \n",
      "    clamp_max(...)\n",
      "    \n",
      "    clamp_max_(...)\n",
      "    \n",
      "    clamp_min(...)\n",
      "    \n",
      "    clamp_min_(...)\n",
      "    \n",
      "    clear_autocast_cache(...)\n",
      "    \n",
      "    clip(...)\n",
      "        clip(input, min, max, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.clamp`.\n",
      "    \n",
      "    clip_(...)\n",
      "    \n",
      "    clone(...)\n",
      "        clone(input, *, memory_format=torch.preserve_format) -> Tensor\n",
      "        \n",
      "        Returns a copy of :attr:`input`.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            This function is differentiable, so gradients will flow back from the\n",
      "            result of this operation to :attr:`input`. To create a tensor without an\n",
      "            autograd relationship to :attr:`input` see :meth:`~Tensor.detach`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "                returned tensor. Default: ``torch.preserve_format``.\n",
      "    \n",
      "    column_stack(...)\n",
      "        column_stack(tensors, *, out=None) -> Tensor\n",
      "        \n",
      "        Creates a new tensor by horizontally stacking the tensors in :attr:`tensors`.\n",
      "        \n",
      "        Equivalent to ``torch.hstack(tensors)``, except each zero or one dimensional tensor ``t``\n",
      "        in :attr:`tensors` is first reshaped into a ``(t.numel(), 1)`` column before being stacked horizontally.\n",
      "        \n",
      "        Args:\n",
      "            tensors (sequence of Tensors): sequence of tensors to concatenate\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([1, 2, 3])\n",
      "            >>> b = torch.tensor([4, 5, 6])\n",
      "            >>> torch.column_stack((a, b))\n",
      "            tensor([[1, 4],\n",
      "                [2, 5],\n",
      "                [3, 6]])\n",
      "            >>> a = torch.arange(5)\n",
      "            >>> b = torch.arange(10).reshape(5, 2)\n",
      "            >>> torch.column_stack((a, b, b))\n",
      "            tensor([[0, 0, 1, 0, 1],\n",
      "                    [1, 2, 3, 2, 3],\n",
      "                    [2, 4, 5, 4, 5],\n",
      "                    [3, 6, 7, 6, 7],\n",
      "                    [4, 8, 9, 8, 9]])\n",
      "    \n",
      "    combinations(...)\n",
      "        combinations(input, r=2, with_replacement=False) -> seq\n",
      "        \n",
      "        Compute combinations of length :math:`r` of the given tensor. The behavior is similar to\n",
      "        python's `itertools.combinations` when `with_replacement` is set to `False`, and\n",
      "        `itertools.combinations_with_replacement` when `with_replacement` is set to `True`.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): 1D vector.\n",
      "            r (int, optional): number of elements to combine\n",
      "            with_replacement (boolean, optional): whether to allow duplication in combination\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A tensor equivalent to converting all the input tensors into lists, do\n",
      "            `itertools.combinations` or `itertools.combinations_with_replacement` on these\n",
      "            lists, and finally convert the resulting list into tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = [1, 2, 3]\n",
      "            >>> list(itertools.combinations(a, r=2))\n",
      "            [(1, 2), (1, 3), (2, 3)]\n",
      "            >>> list(itertools.combinations(a, r=3))\n",
      "            [(1, 2, 3)]\n",
      "            >>> list(itertools.combinations_with_replacement(a, r=2))\n",
      "            [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)]\n",
      "            >>> tensor_a = torch.tensor(a)\n",
      "            >>> torch.combinations(tensor_a)\n",
      "            tensor([[1, 2],\n",
      "                    [1, 3],\n",
      "                    [2, 3]])\n",
      "            >>> torch.combinations(tensor_a, r=3)\n",
      "            tensor([[1, 2, 3]])\n",
      "            >>> torch.combinations(tensor_a, with_replacement=True)\n",
      "            tensor([[1, 1],\n",
      "                    [1, 2],\n",
      "                    [1, 3],\n",
      "                    [2, 2],\n",
      "                    [2, 3],\n",
      "                    [3, 3]])\n",
      "    \n",
      "    complex(...)\n",
      "        complex(real, imag, *, out=None) -> Tensor\n",
      "        \n",
      "        Constructs a complex tensor with its real part equal to :attr:`real` and its\n",
      "        imaginary part equal to :attr:`imag`.\n",
      "        \n",
      "        Args:\n",
      "            real (Tensor): The real part of the complex tensor. Must be float or double.\n",
      "            imag (Tensor): The imaginary part of the complex tensor. Must be same dtype\n",
      "                as :attr:`real`.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor): If the inputs are ``torch.float32``, must be\n",
      "                ``torch.complex64``. If the inputs are ``torch.float64``, must be\n",
      "                ``torch.complex128``.\n",
      "        \n",
      "        Example::\n",
      "            >>> real = torch.tensor([1, 2], dtype=torch.float32)\n",
      "            >>> imag = torch.tensor([3, 4], dtype=torch.float32)\n",
      "            >>> z = torch.complex(real, imag)\n",
      "            >>> z\n",
      "            tensor([(1.+3.j), (2.+4.j)])\n",
      "            >>> z.dtype\n",
      "            torch.complex64\n",
      "    \n",
      "    conj(...)\n",
      "        conj(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise conjugate of the given :attr:`input` tensor. If :attr`input` has a non-complex dtype,\n",
      "        this function just returns :attr:`input`.\n",
      "        \n",
      "        .. warning:: In the future, :func:`torch.conj` may return a non-writeable view for an :attr:`input` of\n",
      "                     non-complex dtype. It's recommended that programs not modify the tensor returned by :func:`torch.conj`\n",
      "                     when :attr:`input` is of non-complex dtype to be compatible with this change.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = conj(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.conj(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))\n",
      "            tensor([-1 - 1j, -2 - 2j, 3 + 3j])\n",
      "    \n",
      "    constant_pad_nd(...)\n",
      "    \n",
      "    conv1d(...)\n",
      "        conv1d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n",
      "        \n",
      "        Applies a 1D convolution over an input signal composed of several input\n",
      "        planes.\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        See :class:`~torch.nn.Conv1d` for details and output shape.\n",
      "        \n",
      "        Note:\n",
      "            In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iW)`\n",
      "            weight: filters of shape :math:`(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kW)`\n",
      "            bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: ``None``\n",
      "            stride: the stride of the convolving kernel. Can be a single number or\n",
      "              a one-element tuple `(sW,)`. Default: 1\n",
      "            padding: implicit paddings on both sides of the input. Can be a\n",
      "              single number or a one-element tuple `(padW,)`. Default: 0\n",
      "            dilation: the spacing between kernel elements. Can be a single number or\n",
      "              a one-element tuple `(dW,)`. Default: 1\n",
      "            groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by\n",
      "              the number of groups. Default: 1\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> filters = torch.randn(33, 16, 3)\n",
      "            >>> inputs = torch.randn(20, 16, 50)\n",
      "            >>> F.conv1d(inputs, filters)\n",
      "    \n",
      "    conv2d(...)\n",
      "        conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n",
      "        \n",
      "        Applies a 2D convolution over an input image composed of several input\n",
      "        planes.\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        See :class:`~torch.nn.Conv2d` for details and output shape.\n",
      "        \n",
      "        Note:\n",
      "            In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
      "        \n",
      "        Args:\n",
      "            input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n",
      "            weight: filters of shape :math:`(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kH , kW)`\n",
      "            bias: optional bias tensor of shape :math:`(\\text{out\\_channels})`. Default: ``None``\n",
      "            stride: the stride of the convolving kernel. Can be a single number or a\n",
      "              tuple `(sH, sW)`. Default: 1\n",
      "            padding: implicit paddings on both sides of the input. Can be a\n",
      "              single number or a tuple `(padH, padW)`. Default: 0\n",
      "            dilation: the spacing between kernel elements. Can be a single number or\n",
      "              a tuple `(dH, dW)`. Default: 1\n",
      "            groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "              number of groups. Default: 1\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> # With square kernels and equal stride\n",
      "            >>> filters = torch.randn(8,4,3,3)\n",
      "            >>> inputs = torch.randn(1,4,5,5)\n",
      "            >>> F.conv2d(inputs, filters, padding=1)\n",
      "    \n",
      "    conv3d(...)\n",
      "        conv3d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n",
      "        \n",
      "        Applies a 3D convolution over an input image composed of several input\n",
      "        planes.\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        See :class:`~torch.nn.Conv3d` for details and output shape.\n",
      "        \n",
      "        Note:\n",
      "            In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW)`\n",
      "            weight: filters of shape :math:`(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kT , kH , kW)`\n",
      "            bias: optional bias tensor of shape :math:`(\\text{out\\_channels})`. Default: None\n",
      "            stride: the stride of the convolving kernel. Can be a single number or a\n",
      "              tuple `(sT, sH, sW)`. Default: 1\n",
      "            padding: implicit paddings on both sides of the input. Can be a\n",
      "              single number or a tuple `(padT, padH, padW)`. Default: 0\n",
      "            dilation: the spacing between kernel elements. Can be a single number or\n",
      "              a tuple `(dT, dH, dW)`. Default: 1\n",
      "            groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by\n",
      "              the number of groups. Default: 1\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> filters = torch.randn(33, 16, 3, 3, 3)\n",
      "            >>> inputs = torch.randn(20, 16, 50, 10, 20)\n",
      "            >>> F.conv3d(inputs, filters)\n",
      "    \n",
      "    conv_tbc(...)\n",
      "        Applies a 1-dimensional sequence convolution over an input sequence.\n",
      "        Input and output dimensions are (Time, Batch, Channels) - hence TBC.\n",
      "        \n",
      "        Args:\n",
      "            input: input tensor of shape :math:`(\\text{sequence length} \\times batch \\times \\text{in\\_channels})`\n",
      "            weight: filter of shape (:math:`\\text{kernel width} \\times \\text{in\\_channels} \\times \\text{out\\_channels}`)\n",
      "            bias: bias of shape (:math:`\\text{out\\_channels}`)\n",
      "            pad: number of timesteps to pad. Default: 0\n",
      "    \n",
      "    conv_transpose1d(...)\n",
      "        conv_transpose1d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor\n",
      "        \n",
      "        Applies a 1D transposed convolution operator over an input signal\n",
      "        composed of several input planes, sometimes also called \"deconvolution\".\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        See :class:`~torch.nn.ConvTranspose1d` for details and output shape.\n",
      "        \n",
      "        Note:\n",
      "            In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iW)`\n",
      "            weight: filters of shape :math:`(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kW)`\n",
      "            bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n",
      "            stride: the stride of the convolving kernel. Can be a single number or a\n",
      "              tuple ``(sW,)``. Default: 1\n",
      "            padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n",
      "              sides of each dimension in the input. Can be a single number or a tuple\n",
      "              ``(padW,)``. Default: 0\n",
      "            output_padding: additional size added to one side of each dimension in the\n",
      "              output shape. Can be a single number or a tuple ``(out_padW)``. Default: 0\n",
      "            groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "              number of groups. Default: 1\n",
      "            dilation: the spacing between kernel elements. Can be a single number or\n",
      "              a tuple ``(dW,)``. Default: 1\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> inputs = torch.randn(20, 16, 50)\n",
      "            >>> weights = torch.randn(16, 33, 5)\n",
      "            >>> F.conv_transpose1d(inputs, weights)\n",
      "    \n",
      "    conv_transpose2d(...)\n",
      "        conv_transpose2d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor\n",
      "        \n",
      "        Applies a 2D transposed convolution operator over an input image\n",
      "        composed of several input planes, sometimes also called \"deconvolution\".\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        See :class:`~torch.nn.ConvTranspose2d` for details and output shape.\n",
      "        \n",
      "        Note:\n",
      "            In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n",
      "            weight: filters of shape :math:`(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kH , kW)`\n",
      "            bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n",
      "            stride: the stride of the convolving kernel. Can be a single number or a\n",
      "              tuple ``(sH, sW)``. Default: 1\n",
      "            padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n",
      "              sides of each dimension in the input. Can be a single number or a tuple\n",
      "              ``(padH, padW)``. Default: 0\n",
      "            output_padding: additional size added to one side of each dimension in the\n",
      "              output shape. Can be a single number or a tuple ``(out_padH, out_padW)``.\n",
      "              Default: 0\n",
      "            groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "              number of groups. Default: 1\n",
      "            dilation: the spacing between kernel elements. Can be a single number or\n",
      "              a tuple ``(dH, dW)``. Default: 1\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> # With square kernels and equal stride\n",
      "            >>> inputs = torch.randn(1, 4, 5, 5)\n",
      "            >>> weights = torch.randn(4, 8, 3, 3)\n",
      "            >>> F.conv_transpose2d(inputs, weights, padding=1)\n",
      "    \n",
      "    conv_transpose3d(...)\n",
      "        conv_transpose3d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor\n",
      "        \n",
      "        Applies a 3D transposed convolution operator over an input image\n",
      "        composed of several input planes, sometimes also called \"deconvolution\"\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        See :class:`~torch.nn.ConvTranspose3d` for details and output shape.\n",
      "        \n",
      "        Note:\n",
      "            In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW)`\n",
      "            weight: filters of shape :math:`(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kT , kH , kW)`\n",
      "            bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n",
      "            stride: the stride of the convolving kernel. Can be a single number or a\n",
      "              tuple ``(sT, sH, sW)``. Default: 1\n",
      "            padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n",
      "              sides of each dimension in the input. Can be a single number or a tuple\n",
      "              ``(padT, padH, padW)``. Default: 0\n",
      "            output_padding: additional size added to one side of each dimension in the\n",
      "              output shape. Can be a single number or a tuple\n",
      "              ``(out_padT, out_padH, out_padW)``. Default: 0\n",
      "            groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "              number of groups. Default: 1\n",
      "            dilation: the spacing between kernel elements. Can be a single number or\n",
      "              a tuple `(dT, dH, dW)`. Default: 1\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> inputs = torch.randn(20, 16, 50, 10, 20)\n",
      "            >>> weights = torch.randn(16, 33, 3, 3, 3)\n",
      "            >>> F.conv_transpose3d(inputs, weights)\n",
      "    \n",
      "    convolution(...)\n",
      "    \n",
      "    copysign(...)\n",
      "        copysign(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Create a new floating-point tensor with the magnitude of :attr:`input` and the sign of :attr:`other`, elementwise.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\begin{cases}\n",
      "                -|\\text{input}_{i}| & \\text{if} \\text{other}_{i} \\leq -0.0 \\\\\n",
      "                |\\text{input}_{i}| & \\text{if} \\text{other}_{i} \\geq 0.0 \\\\\n",
      "            \\end{cases}\n",
      "        \n",
      "        \n",
      "        Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`,\n",
      "        and integer and float inputs.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): magnitudes.\n",
      "            other (Tensor or Number): contains value(s) whose signbit(s) are\n",
      "                applied to the magnitudes in :attr:`input`.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(5)\n",
      "            >>> a\n",
      "            tensor([-1.2557, -0.0026, -0.5387,  0.4740, -0.9244])\n",
      "            >>> torch.copysign(a, 1)\n",
      "            tensor([1.2557, 0.0026, 0.5387, 0.4740, 0.9244])\n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[ 0.7079,  0.2778, -1.0249,  0.5719],\n",
      "                    [-0.0059, -0.2600, -0.4475, -1.3948],\n",
      "                    [ 0.3667, -0.9567, -2.5757, -0.1751],\n",
      "                    [ 0.2046, -0.0742,  0.2998, -0.1054]])\n",
      "            >>> b = torch.randn(4)\n",
      "            tensor([ 0.2373,  0.3120,  0.3190, -1.1128])\n",
      "            >>> torch.copysign(a, b)\n",
      "            tensor([[ 0.7079,  0.2778,  1.0249, -0.5719],\n",
      "                    [ 0.0059,  0.2600,  0.4475, -1.3948],\n",
      "                    [ 0.3667,  0.9567,  2.5757, -0.1751],\n",
      "                    [ 0.2046,  0.0742,  0.2998, -0.1054]])\n",
      "    \n",
      "    cos(...)\n",
      "        cos(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the cosine  of the elements of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\cos(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 1.4309,  1.2706, -0.8562,  0.9796])\n",
      "            >>> torch.cos(a)\n",
      "            tensor([ 0.1395,  0.2957,  0.6553,  0.5574])\n",
      "    \n",
      "    cos_(...)\n",
      "    \n",
      "    cosh(...)\n",
      "        cosh(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the hyperbolic cosine  of the elements of\n",
      "        :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\cosh(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.1632,  1.1835, -0.6979, -0.7325])\n",
      "            >>> torch.cosh(a)\n",
      "            tensor([ 1.0133,  1.7860,  1.2536,  1.2805])\n",
      "        \n",
      "        .. note::\n",
      "           When :attr:`input` is on the CPU, the implementation of torch.cosh may use\n",
      "           the Sleef library, which rounds very large results to infinity or negative\n",
      "           infinity. See `here <https://sleef.org/purec.xhtml>`_ for details.\n",
      "    \n",
      "    cosh_(...)\n",
      "    \n",
      "    cosine_embedding_loss(...)\n",
      "    \n",
      "    cosine_similarity(...)\n",
      "        cosine_similarity(x1, x2, dim=1, eps=1e-8) -> Tensor\n",
      "        \n",
      "        Returns cosine similarity between x1 and x2, computed along dim.\n",
      "        \n",
      "        .. math ::\n",
      "            \\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)}\n",
      "        \n",
      "        Args:\n",
      "            x1 (Tensor): First input.\n",
      "            x2 (Tensor): Second input (of size matching x1).\n",
      "            dim (int, optional): Dimension of vectors. Default: 1\n",
      "            eps (float, optional): Small value to avoid division by zero.\n",
      "                Default: 1e-8\n",
      "        \n",
      "        Shape:\n",
      "            - Input: :math:`(\\ast_1, D, \\ast_2)` where D is at position `dim`.\n",
      "            - Output: :math:`(\\ast_1, \\ast_2)` where 1 is at position `dim`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> input1 = torch.randn(100, 128)\n",
      "            >>> input2 = torch.randn(100, 128)\n",
      "            >>> output = F.cosine_similarity(input1, input2)\n",
      "            >>> print(output)\n",
      "    \n",
      "    count_nonzero(...)\n",
      "        count_nonzero(input, dim=None) -> Tensor\n",
      "        \n",
      "        Counts the number of non-zero values in the tensor :attr:`input` along the given :attr:`dim`.\n",
      "        If no dim is specified then all non-zeros in the tensor are counted.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int or tuple of ints, optional): Dim or tuple of dims along which to count non-zeros.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.zeros(3,3)\n",
      "            >>> x[torch.randn(3,3) > 0.5] = 1\n",
      "            >>> x\n",
      "            tensor([[0., 1., 1.],\n",
      "                    [0., 0., 0.],\n",
      "                    [0., 0., 1.]])\n",
      "            >>> torch.count_nonzero(x)\n",
      "            tensor(3)\n",
      "            >>> torch.count_nonzero(x, dim=0)\n",
      "            tensor([0, 1, 2])\n",
      "    \n",
      "    cross(...)\n",
      "        cross(input, other, dim=None, *, out=None) -> Tensor\n",
      "        \n",
      "        \n",
      "        Returns the cross product of vectors in dimension :attr:`dim` of :attr:`input`\n",
      "        and :attr:`other`.\n",
      "        \n",
      "        :attr:`input` and :attr:`other` must have the same size, and the size of their\n",
      "        :attr:`dim` dimension should be 3.\n",
      "        \n",
      "        If :attr:`dim` is not given, it defaults to the first dimension found with the\n",
      "        size 3. Note that this might be unexpected.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the second input tensor\n",
      "            dim  (int, optional): the dimension to take the cross-product in.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 3)\n",
      "            >>> a\n",
      "            tensor([[-0.3956,  1.1455,  1.6895],\n",
      "                    [-0.5849,  1.3672,  0.3599],\n",
      "                    [-1.1626,  0.7180, -0.0521],\n",
      "                    [-0.1339,  0.9902, -2.0225]])\n",
      "            >>> b = torch.randn(4, 3)\n",
      "            >>> b\n",
      "            tensor([[-0.0257, -1.4725, -1.2251],\n",
      "                    [-1.1479, -0.7005, -1.9757],\n",
      "                    [-1.3904,  0.3726, -1.1836],\n",
      "                    [-0.9688, -0.7153,  0.2159]])\n",
      "            >>> torch.cross(a, b, dim=1)\n",
      "            tensor([[ 1.0844, -0.5281,  0.6120],\n",
      "                    [-2.4490, -1.5687,  1.9792],\n",
      "                    [-0.8304, -1.3037,  0.5650],\n",
      "                    [-1.2329,  1.9883,  1.0551]])\n",
      "            >>> torch.cross(a, b)\n",
      "            tensor([[ 1.0844, -0.5281,  0.6120],\n",
      "                    [-2.4490, -1.5687,  1.9792],\n",
      "                    [-0.8304, -1.3037,  0.5650],\n",
      "                    [-1.2329,  1.9883,  1.0551]])\n",
      "    \n",
      "    ctc_loss(...)\n",
      "    \n",
      "    cudnn_affine_grid_generator(...)\n",
      "    \n",
      "    cudnn_batch_norm(...)\n",
      "    \n",
      "    cudnn_convolution(...)\n",
      "    \n",
      "    cudnn_convolution_transpose(...)\n",
      "    \n",
      "    cudnn_grid_sampler(...)\n",
      "    \n",
      "    cudnn_is_acceptable(...)\n",
      "    \n",
      "    cummax(...)\n",
      "        cummax(input, dim, *, out=None) -> (Tensor, LongTensor)\n",
      "        Returns a namedtuple ``(values, indices)`` where ``values`` is the cumulative maximum of\n",
      "        elements of :attr:`input` in the dimension :attr:`dim`. And ``indices`` is the index\n",
      "        location of each maximum value found in the dimension :attr:`dim`.\n",
      "        \n",
      "        .. math::\n",
      "            y_i = max(x_1, x_2, x_3, \\dots, x_i)\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim  (int): the dimension to do the operation over\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the result tuple of two output tensors (values, indices)\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(10)\n",
      "            >>> a\n",
      "            tensor([-0.3449, -1.5447,  0.0685, -1.5104, -1.1706,  0.2259,  1.4696, -1.3284,\n",
      "                 1.9946, -0.8209])\n",
      "            >>> torch.cummax(a, dim=0)\n",
      "            torch.return_types.cummax(\n",
      "                values=tensor([-0.3449, -0.3449,  0.0685,  0.0685,  0.0685,  0.2259,  1.4696,  1.4696,\n",
      "                 1.9946,  1.9946]),\n",
      "                indices=tensor([0, 0, 2, 2, 2, 5, 6, 6, 8, 8]))\n",
      "    \n",
      "    cummin(...)\n",
      "        cummin(input, dim, *, out=None) -> (Tensor, LongTensor)\n",
      "        Returns a namedtuple ``(values, indices)`` where ``values`` is the cumulative minimum of\n",
      "        elements of :attr:`input` in the dimension :attr:`dim`. And ``indices`` is the index\n",
      "        location of each maximum value found in the dimension :attr:`dim`.\n",
      "        \n",
      "        .. math::\n",
      "            y_i = min(x_1, x_2, x_3, \\dots, x_i)\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim  (int): the dimension to do the operation over\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the result tuple of two output tensors (values, indices)\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(10)\n",
      "            >>> a\n",
      "            tensor([-0.2284, -0.6628,  0.0975,  0.2680, -1.3298, -0.4220, -0.3885,  1.1762,\n",
      "                 0.9165,  1.6684])\n",
      "            >>> torch.cummin(a, dim=0)\n",
      "            torch.return_types.cummin(\n",
      "                values=tensor([-0.2284, -0.6628, -0.6628, -0.6628, -1.3298, -1.3298, -1.3298, -1.3298,\n",
      "                -1.3298, -1.3298]),\n",
      "                indices=tensor([0, 1, 1, 1, 4, 4, 4, 4, 4, 4]))\n",
      "    \n",
      "    cumprod(...)\n",
      "        cumprod(input, dim, *, dtype=None, out=None) -> Tensor\n",
      "        \n",
      "        Returns the cumulative product of elements of :attr:`input` in the dimension\n",
      "        :attr:`dim`.\n",
      "        \n",
      "        For example, if :attr:`input` is a vector of size N, the result will also be\n",
      "        a vector of size N, with elements.\n",
      "        \n",
      "        .. math::\n",
      "            y_i = x_1 \\times x_2\\times x_3\\times \\dots \\times x_i\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim  (int): the dimension to do the operation over\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "                is performed. This is useful for preventing data type overflows. Default: None.\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(10)\n",
      "            >>> a\n",
      "            tensor([ 0.6001,  0.2069, -0.1919,  0.9792,  0.6727,  1.0062,  0.4126,\n",
      "                    -0.2129, -0.4206,  0.1968])\n",
      "            >>> torch.cumprod(a, dim=0)\n",
      "            tensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0158, -0.0065,\n",
      "                     0.0014, -0.0006, -0.0001])\n",
      "        \n",
      "            >>> a[5] = 0.0\n",
      "            >>> torch.cumprod(a, dim=0)\n",
      "            tensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0000, -0.0000,\n",
      "                     0.0000, -0.0000, -0.0000])\n",
      "    \n",
      "    cumsum(...)\n",
      "        cumsum(input, dim, *, dtype=None, out=None) -> Tensor\n",
      "        \n",
      "        Returns the cumulative sum of elements of :attr:`input` in the dimension\n",
      "        :attr:`dim`.\n",
      "        \n",
      "        For example, if :attr:`input` is a vector of size N, the result will also be\n",
      "        a vector of size N, with elements.\n",
      "        \n",
      "        .. math::\n",
      "            y_i = x_1 + x_2 + x_3 + \\dots + x_i\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim  (int): the dimension to do the operation over\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "                is performed. This is useful for preventing data type overflows. Default: None.\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(10)\n",
      "            >>> a\n",
      "            tensor([-0.8286, -0.4890,  0.5155,  0.8443,  0.1865, -0.1752, -2.0595,\n",
      "                     0.1850, -1.1571, -0.4243])\n",
      "            >>> torch.cumsum(a, dim=0)\n",
      "            tensor([-0.8286, -1.3175, -0.8020,  0.0423,  0.2289,  0.0537, -2.0058,\n",
      "                    -1.8209, -2.9780, -3.4022])\n",
      "    \n",
      "    deg2rad(...)\n",
      "        deg2rad(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with each of the elements of :attr:`input`\n",
      "        converted from angles in degrees to radians.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([[180.0, -180.0], [360.0, -360.0], [90.0, -90.0]])\n",
      "            >>> torch.deg2rad(a)\n",
      "            tensor([[ 3.1416, -3.1416],\n",
      "                    [ 6.2832, -6.2832],\n",
      "                    [ 1.5708, -1.5708]])\n",
      "    \n",
      "    deg2rad_(...)\n",
      "    \n",
      "    dequantize(...)\n",
      "        dequantize(tensor) -> Tensor\n",
      "        \n",
      "        Returns an fp32 Tensor by dequantizing a quantized Tensor\n",
      "        \n",
      "        Args:\n",
      "            tensor (Tensor): A quantized Tensor\n",
      "        \n",
      "        .. function:: dequantize(tensors) -> sequence of Tensors\n",
      "        \n",
      "        Given a list of quantized Tensors, dequantize them and return a list of fp32 Tensors\n",
      "        \n",
      "        Args:\n",
      "             tensors (sequence of Tensors): A list of quantized Tensors\n",
      "    \n",
      "    det(...)\n",
      "        det(input) -> Tensor\n",
      "        \n",
      "        Calculates determinant of a square matrix or batches of square matrices.\n",
      "        \n",
      "        .. note:: :func:`torch.det` is deprecated. Please use :func:`torch.linalg.det` instead.\n",
      "        \n",
      "        .. note::\n",
      "            Backward through :math:`det` internally uses SVD results when :attr:`input` is\n",
      "            not invertible. In this case, double backward through :math:`det` will be\n",
      "            unstable when :attr:`input` doesn't have distinct singular values. See\n",
      "            :math:`~torch.svd` for details.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): the input tensor of size ``(*, n, n)`` where ``*`` is zero or more\n",
      "                            batch dimensions.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> A = torch.randn(3, 3)\n",
      "            >>> torch.det(A)\n",
      "            tensor(3.7641)\n",
      "        \n",
      "            >>> A = torch.randn(3, 2, 2)\n",
      "            >>> A\n",
      "            tensor([[[ 0.9254, -0.6213],\n",
      "                     [-0.5787,  1.6843]],\n",
      "        \n",
      "                    [[ 0.3242, -0.9665],\n",
      "                     [ 0.4539, -0.0887]],\n",
      "        \n",
      "                    [[ 1.1336, -0.4025],\n",
      "                     [-0.7089,  0.9032]]])\n",
      "            >>> A.det()\n",
      "            tensor([1.1990, 0.4099, 0.7386])\n",
      "    \n",
      "    detach(...)\n",
      "    \n",
      "    detach_(...)\n",
      "    \n",
      "    diag(...)\n",
      "        diag(input, diagonal=0, *, out=None) -> Tensor\n",
      "        \n",
      "        - If :attr:`input` is a vector (1-D tensor), then returns a 2-D square tensor\n",
      "          with the elements of :attr:`input` as the diagonal.\n",
      "        - If :attr:`input` is a matrix (2-D tensor), then returns a 1-D tensor with\n",
      "          the diagonal elements of :attr:`input`.\n",
      "        \n",
      "        The argument :attr:`diagonal` controls which diagonal to consider:\n",
      "        \n",
      "        - If :attr:`diagonal` = 0, it is the main diagonal.\n",
      "        - If :attr:`diagonal` > 0, it is above the main diagonal.\n",
      "        - If :attr:`diagonal` < 0, it is below the main diagonal.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            diagonal (int, optional): the diagonal to consider\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        .. seealso::\n",
      "        \n",
      "                :func:`torch.diagonal` always returns the diagonal of its input.\n",
      "        \n",
      "                :func:`torch.diagflat` always constructs a tensor with diagonal elements\n",
      "                specified by the input.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        Get the square matrix where the input vector is the diagonal::\n",
      "        \n",
      "            >>> a = torch.randn(3)\n",
      "            >>> a\n",
      "            tensor([ 0.5950,-0.0872, 2.3298])\n",
      "            >>> torch.diag(a)\n",
      "            tensor([[ 0.5950, 0.0000, 0.0000],\n",
      "                    [ 0.0000,-0.0872, 0.0000],\n",
      "                    [ 0.0000, 0.0000, 2.3298]])\n",
      "            >>> torch.diag(a, 1)\n",
      "            tensor([[ 0.0000, 0.5950, 0.0000, 0.0000],\n",
      "                    [ 0.0000, 0.0000,-0.0872, 0.0000],\n",
      "                    [ 0.0000, 0.0000, 0.0000, 2.3298],\n",
      "                    [ 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "        \n",
      "        Get the k-th diagonal of a given matrix::\n",
      "        \n",
      "            >>> a = torch.randn(3, 3)\n",
      "            >>> a\n",
      "            tensor([[-0.4264, 0.0255,-0.1064],\n",
      "                    [ 0.8795,-0.2429, 0.1374],\n",
      "                    [ 0.1029,-0.6482,-1.6300]])\n",
      "            >>> torch.diag(a, 0)\n",
      "            tensor([-0.4264,-0.2429,-1.6300])\n",
      "            >>> torch.diag(a, 1)\n",
      "            tensor([ 0.0255, 0.1374])\n",
      "    \n",
      "    diag_embed(...)\n",
      "        diag_embed(input, offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "        \n",
      "        Creates a tensor whose diagonals of certain 2D planes (specified by\n",
      "        :attr:`dim1` and :attr:`dim2`) are filled by :attr:`input`.\n",
      "        To facilitate creating batched diagonal matrices, the 2D planes formed by\n",
      "        the last two dimensions of the returned tensor are chosen by default.\n",
      "        \n",
      "        The argument :attr:`offset` controls which diagonal to consider:\n",
      "        \n",
      "        - If :attr:`offset` = 0, it is the main diagonal.\n",
      "        - If :attr:`offset` > 0, it is above the main diagonal.\n",
      "        - If :attr:`offset` < 0, it is below the main diagonal.\n",
      "        \n",
      "        The size of the new matrix will be calculated to make the specified diagonal\n",
      "        of the size of the last input dimension.\n",
      "        Note that for :attr:`offset` other than :math:`0`, the order of :attr:`dim1`\n",
      "        and :attr:`dim2` matters. Exchanging them is equivalent to changing the\n",
      "        sign of :attr:`offset`.\n",
      "        \n",
      "        Applying :meth:`torch.diagonal` to the output of this function with\n",
      "        the same arguments yields a matrix identical to input. However,\n",
      "        :meth:`torch.diagonal` has different default dimensions, so those\n",
      "        need to be explicitly specified.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor. Must be at least 1-dimensional.\n",
      "            offset (int, optional): which diagonal to consider. Default: 0\n",
      "                (main diagonal).\n",
      "            dim1 (int, optional): first dimension with respect to which to\n",
      "                take diagonal. Default: -2.\n",
      "            dim2 (int, optional): second dimension with respect to which to\n",
      "                take diagonal. Default: -1.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(2, 3)\n",
      "            >>> torch.diag_embed(a)\n",
      "            tensor([[[ 1.5410,  0.0000,  0.0000],\n",
      "                     [ 0.0000, -0.2934,  0.0000],\n",
      "                     [ 0.0000,  0.0000, -2.1788]],\n",
      "        \n",
      "                    [[ 0.5684,  0.0000,  0.0000],\n",
      "                     [ 0.0000, -1.0845,  0.0000],\n",
      "                     [ 0.0000,  0.0000, -1.3986]]])\n",
      "        \n",
      "            >>> torch.diag_embed(a, offset=1, dim1=0, dim2=2)\n",
      "            tensor([[[ 0.0000,  1.5410,  0.0000,  0.0000],\n",
      "                     [ 0.0000,  0.5684,  0.0000,  0.0000]],\n",
      "        \n",
      "                    [[ 0.0000,  0.0000, -0.2934,  0.0000],\n",
      "                     [ 0.0000,  0.0000, -1.0845,  0.0000]],\n",
      "        \n",
      "                    [[ 0.0000,  0.0000,  0.0000, -2.1788],\n",
      "                     [ 0.0000,  0.0000,  0.0000, -1.3986]],\n",
      "        \n",
      "                    [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "                     [ 0.0000,  0.0000,  0.0000,  0.0000]]])\n",
      "    \n",
      "    diagflat(...)\n",
      "        diagflat(input, offset=0) -> Tensor\n",
      "        \n",
      "        - If :attr:`input` is a vector (1-D tensor), then returns a 2-D square tensor\n",
      "          with the elements of :attr:`input` as the diagonal.\n",
      "        - If :attr:`input` is a tensor with more than one dimension, then returns a\n",
      "          2-D tensor with diagonal elements equal to a flattened :attr:`input`.\n",
      "        \n",
      "        The argument :attr:`offset` controls which diagonal to consider:\n",
      "        \n",
      "        - If :attr:`offset` = 0, it is the main diagonal.\n",
      "        - If :attr:`offset` > 0, it is above the main diagonal.\n",
      "        - If :attr:`offset` < 0, it is below the main diagonal.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            offset (int, optional): the diagonal to consider. Default: 0 (main\n",
      "                diagonal).\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> a = torch.randn(3)\n",
      "            >>> a\n",
      "            tensor([-0.2956, -0.9068,  0.1695])\n",
      "            >>> torch.diagflat(a)\n",
      "            tensor([[-0.2956,  0.0000,  0.0000],\n",
      "                    [ 0.0000, -0.9068,  0.0000],\n",
      "                    [ 0.0000,  0.0000,  0.1695]])\n",
      "            >>> torch.diagflat(a, 1)\n",
      "            tensor([[ 0.0000, -0.2956,  0.0000,  0.0000],\n",
      "                    [ 0.0000,  0.0000, -0.9068,  0.0000],\n",
      "                    [ 0.0000,  0.0000,  0.0000,  0.1695],\n",
      "                    [ 0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "        \n",
      "            >>> a = torch.randn(2, 2)\n",
      "            >>> a\n",
      "            tensor([[ 0.2094, -0.3018],\n",
      "                    [-0.1516,  1.9342]])\n",
      "            >>> torch.diagflat(a)\n",
      "            tensor([[ 0.2094,  0.0000,  0.0000,  0.0000],\n",
      "                    [ 0.0000, -0.3018,  0.0000,  0.0000],\n",
      "                    [ 0.0000,  0.0000, -0.1516,  0.0000],\n",
      "                    [ 0.0000,  0.0000,  0.0000,  1.9342]])\n",
      "    \n",
      "    diagonal(...)\n",
      "        diagonal(input, offset=0, dim1=0, dim2=1) -> Tensor\n",
      "        \n",
      "        Returns a partial view of :attr:`input` with the its diagonal elements\n",
      "        with respect to :attr:`dim1` and :attr:`dim2` appended as a dimension\n",
      "        at the end of the shape.\n",
      "        \n",
      "        The argument :attr:`offset` controls which diagonal to consider:\n",
      "        \n",
      "        - If :attr:`offset` = 0, it is the main diagonal.\n",
      "        - If :attr:`offset` > 0, it is above the main diagonal.\n",
      "        - If :attr:`offset` < 0, it is below the main diagonal.\n",
      "        \n",
      "        Applying :meth:`torch.diag_embed` to the output of this function with\n",
      "        the same arguments yields a diagonal matrix with the diagonal entries\n",
      "        of the input. However, :meth:`torch.diag_embed` has different default\n",
      "        dimensions, so those need to be explicitly specified.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor. Must be at least 2-dimensional.\n",
      "            offset (int, optional): which diagonal to consider. Default: 0\n",
      "                (main diagonal).\n",
      "            dim1 (int, optional): first dimension with respect to which to\n",
      "                take diagonal. Default: 0.\n",
      "            dim2 (int, optional): second dimension with respect to which to\n",
      "                take diagonal. Default: 1.\n",
      "        \n",
      "        .. note::  To take a batch diagonal, pass in dim1=-2, dim2=-1.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> a = torch.randn(3, 3)\n",
      "            >>> a\n",
      "            tensor([[-1.0854,  1.1431, -0.1752],\n",
      "                    [ 0.8536, -0.0905,  0.0360],\n",
      "                    [ 0.6927, -0.3735, -0.4945]])\n",
      "        \n",
      "        \n",
      "            >>> torch.diagonal(a, 0)\n",
      "            tensor([-1.0854, -0.0905, -0.4945])\n",
      "        \n",
      "        \n",
      "            >>> torch.diagonal(a, 1)\n",
      "            tensor([ 1.1431,  0.0360])\n",
      "        \n",
      "        \n",
      "            >>> x = torch.randn(2, 5, 4, 2)\n",
      "            >>> torch.diagonal(x, offset=-1, dim1=1, dim2=2)\n",
      "            tensor([[[-1.2631,  0.3755, -1.5977, -1.8172],\n",
      "                     [-1.1065,  1.0401, -0.2235, -0.7938]],\n",
      "        \n",
      "                    [[-1.7325, -0.3081,  0.6166,  0.2335],\n",
      "                     [ 1.0500,  0.7336, -0.3836, -1.1015]]])\n",
      "    \n",
      "    diff(...)\n",
      "        diff(input, n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "        \n",
      "        Computes the n-th forward difference along the given dimension.\n",
      "        \n",
      "        The first-order differences are given by `out[i] = input[i + 1] - input[i]`. Higher-order\n",
      "        differences are calculated by using :func:`torch.diff` recursively.\n",
      "        \n",
      "        .. note::  Only `n = 1` is currently supported\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to compute the differences on\n",
      "            n (int, optional): the number of times to recursively compute the difference\n",
      "            dim (int, optional): the dimension to compute the difference along.\n",
      "                Default is the last dimension.\n",
      "            prepend, append (Tensor, optional): values to prepend or append to\n",
      "                :attr:`input` along :attr:`dim` before computing the difference.\n",
      "                Their dimensions must be equivalent to that of input, and their shapes\n",
      "                must match input's shape except on :attr:`dim`.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([1, 3, 2])\n",
      "            >>> torch.diff(a)\n",
      "            tensor([ 2, -1])\n",
      "            >>> b = torch.tensor([4, 5])\n",
      "            >>> torch.diff(a, append=b)\n",
      "            tensor([ 2, -1,  2,  1])\n",
      "            >>> c = torch.tensor([[1, 2, 3], [3, 4, 5]])\n",
      "            >>> torch.diff(c, dim=0)\n",
      "            tensor([[2, 2, 2]])\n",
      "            >>> torch.diff(c, dim=1)\n",
      "            tensor([[1, 1],\n",
      "                    [1, 1]])\n",
      "    \n",
      "    digamma(...)\n",
      "        digamma(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the logarithmic derivative of the gamma function on `input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\psi(x) = \\frac{d}{dx} \\ln\\left(\\Gamma\\left(x\\right)\\right) = \\frac{\\Gamma'(x)}{\\Gamma(x)}\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to compute the digamma function on\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        .. note::  This function is similar to SciPy's `scipy.special.digamma`.\n",
      "        \n",
      "        .. note::  From PyTorch 1.8 onwards, the digamma function returns `-Inf` for `0`.\n",
      "                   Previously it returned `NaN` for `0`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([1, 0.5])\n",
      "            >>> torch.digamma(a)\n",
      "            tensor([-0.5772, -1.9635])\n",
      "    \n",
      "    dist(...)\n",
      "        dist(input, other, p=2) -> Tensor\n",
      "        \n",
      "        Returns the p-norm of (:attr:`input` - :attr:`other`)\n",
      "        \n",
      "        The shapes of :attr:`input` and :attr:`other` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the Right-hand-side input tensor\n",
      "            p (float, optional): the norm to be computed\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.randn(4)\n",
      "            >>> x\n",
      "            tensor([-1.5393, -0.8675,  0.5916,  1.6321])\n",
      "            >>> y = torch.randn(4)\n",
      "            >>> y\n",
      "            tensor([ 0.0967, -1.0511,  0.6295,  0.8360])\n",
      "            >>> torch.dist(x, y, 3.5)\n",
      "            tensor(1.6727)\n",
      "            >>> torch.dist(x, y, 3)\n",
      "            tensor(1.6973)\n",
      "            >>> torch.dist(x, y, 0)\n",
      "            tensor(inf)\n",
      "            >>> torch.dist(x, y, 1)\n",
      "            tensor(2.6537)\n",
      "    \n",
      "    div(...)\n",
      "        div(input, other, *, rounding_mode=None, out=None) -> Tensor\n",
      "        \n",
      "        Divides each element of the input ``input`` by the corresponding element of\n",
      "        :attr:`other`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = \\frac{\\text{input}_i}{\\text{other}_i}\n",
      "        \n",
      "        .. note::\n",
      "            By default, this performs a \"true\" division like Python 3.\n",
      "            See the :attr:`rounding_mode` argument for floor division.\n",
      "        \n",
      "        Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`,\n",
      "        :ref:`type promotion <type-promotion-doc>`, and integer, float, and complex inputs.\n",
      "        Always promotes integer types to the default scalar type.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the dividend\n",
      "            other (Tensor or Number): the divisor\n",
      "        \n",
      "        Keyword args:\n",
      "            rounding_mode (str, optional): Type of rounding applied to the result:\n",
      "        \n",
      "                * None - default behavior. Performs no rounding and, if both :attr:`input` and\n",
      "                  :attr:`other` are integer types, promotes the inputs to the default scalar type.\n",
      "                  Equivalent to true division in Python (the ``/`` operator) and NumPy's ``np.true_divide``.\n",
      "                * ``\"trunc\"`` - rounds the results of the division towards zero.\n",
      "                  Equivalent to C-style integer division.\n",
      "                * ``\"floor\"`` - rounds the results of the division down.\n",
      "                  Equivalent to floor division in Python (the ``//`` operator) and NumPy's ``np.floor_divide``.\n",
      "        \n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> x = torch.tensor([ 0.3810,  1.2774, -0.2972, -0.3719,  0.4637])\n",
      "            >>> torch.div(x, 0.5)\n",
      "            tensor([ 0.7620,  2.5548, -0.5944, -0.7438,  0.9274])\n",
      "        \n",
      "            >>> a = torch.tensor([[-0.3711, -1.9353, -0.4605, -0.2917],\n",
      "            ...                   [ 0.1815, -1.0111,  0.9805, -1.5923],\n",
      "            ...                   [ 0.1062,  1.4581,  0.7759, -1.2344],\n",
      "            ...                   [-0.1830, -0.0313,  1.1908, -1.4757]])\n",
      "            >>> b = torch.tensor([ 0.8032,  0.2930, -0.8113, -0.2308])\n",
      "            >>> torch.div(a, b)\n",
      "            tensor([[-0.4620, -6.6051,  0.5676,  1.2639],\n",
      "                    [ 0.2260, -3.4509, -1.2086,  6.8990],\n",
      "                    [ 0.1322,  4.9764, -0.9564,  5.3484],\n",
      "                    [-0.2278, -0.1068, -1.4678,  6.3938]])\n",
      "        \n",
      "            >>> torch.div(a, b, rounding_mode='trunc')\n",
      "            tensor([[-0., -6.,  0.,  1.],\n",
      "                    [ 0., -3., -1.,  6.],\n",
      "                    [ 0.,  4., -0.,  5.],\n",
      "                    [-0., -0., -1.,  6.]])\n",
      "        \n",
      "            >>> torch.div(a, b, rounding_mode='floor')\n",
      "            tensor([[-1., -7.,  0.,  1.],\n",
      "                    [ 0., -4., -2.,  6.],\n",
      "                    [ 0.,  4., -1.,  5.],\n",
      "                    [-1., -1., -2.,  6.]])\n",
      "    \n",
      "    divide(...)\n",
      "        divide(input, other, *, rounding_mode=None, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.div`.\n",
      "    \n",
      "    dot(...)\n",
      "        dot(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the dot product of two 1D tensors.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            Unlike NumPy's dot, torch.dot intentionally only supports computing the dot product\n",
      "            of two 1D tensors with the same number of elements.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): first tensor in the dot product, must be 1D.\n",
      "            other (Tensor): second tensor in the dot product, must be 1D.\n",
      "        \n",
      "        Keyword args:\n",
      "            {out}\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))\n",
      "            tensor(7)\n",
      "    \n",
      "    dropout(...)\n",
      "    \n",
      "    dropout_(...)\n",
      "    \n",
      "    dsmm(...)\n",
      "    \n",
      "    dstack(...)\n",
      "        dstack(tensors, *, out=None) -> Tensor\n",
      "        \n",
      "        Stack tensors in sequence depthwise (along third axis).\n",
      "        \n",
      "        This is equivalent to concatenation along the third axis after 1-D and 2-D tensors have been reshaped by :func:`torch.atleast_3d`.\n",
      "        \n",
      "        Args:\n",
      "            tensors (sequence of Tensors): sequence of tensors to concatenate\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> a = torch.tensor([1, 2, 3])\n",
      "            >>> b = torch.tensor([4, 5, 6])\n",
      "            >>> torch.dstack((a,b))\n",
      "            tensor([[[1, 4],\n",
      "                     [2, 5],\n",
      "                     [3, 6]]])\n",
      "            >>> a = torch.tensor([[1],[2],[3]])\n",
      "            >>> b = torch.tensor([[4],[5],[6]])\n",
      "            >>> torch.dstack((a,b))\n",
      "            tensor([[[1, 4]],\n",
      "                    [[2, 5]],\n",
      "                    [[3, 6]]])\n",
      "    \n",
      "    eig(...)\n",
      "        eig(input, eigenvectors=False, *, out=None) -> (Tensor, Tensor)\n",
      "        \n",
      "        Computes the eigenvalues and eigenvectors of a real square matrix.\n",
      "        \n",
      "        .. note::\n",
      "            Since eigenvalues and eigenvectors might be complex, backward pass is supported only\n",
      "            if eigenvalues and eigenvectors are all real valued.\n",
      "        \n",
      "            When :attr:`input` is on CUDA, :func:`torch.eig() <torch.eig>` causes\n",
      "            host-device synchronization.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the square matrix of shape :math:`(n \\times n)` for which the eigenvalues and eigenvectors\n",
      "                will be computed\n",
      "            eigenvectors (bool): ``True`` to compute both eigenvalues and eigenvectors;\n",
      "                otherwise, only eigenvalues will be computed\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the output tensors\n",
      "        \n",
      "        Returns:\n",
      "            (Tensor, Tensor): A namedtuple (eigenvalues, eigenvectors) containing\n",
      "        \n",
      "                - **eigenvalues** (*Tensor*): Shape :math:`(n \\times 2)`. Each row is an eigenvalue of ``input``,\n",
      "                  where the first element is the real part and the second element is the imaginary part.\n",
      "                  The eigenvalues are not necessarily ordered.\n",
      "                - **eigenvectors** (*Tensor*): If ``eigenvectors=False``, it's an empty tensor.\n",
      "                  Otherwise, this tensor of shape :math:`(n \\times n)` can be used to compute normalized (unit length)\n",
      "                  eigenvectors of corresponding eigenvalues as follows.\n",
      "                  If the corresponding `eigenvalues[j]` is a real number, column `eigenvectors[:, j]` is the eigenvector\n",
      "                  corresponding to `eigenvalues[j]`.\n",
      "                  If the corresponding `eigenvalues[j]` and `eigenvalues[j + 1]` form a complex conjugate pair, then the\n",
      "                  true eigenvectors can be computed as\n",
      "                  :math:`\\text{true eigenvector}[j] = eigenvectors[:, j] + i \\times eigenvectors[:, j + 1]`,\n",
      "                  :math:`\\text{true eigenvector}[j + 1] = eigenvectors[:, j] - i \\times eigenvectors[:, j + 1]`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            Trivial example with a diagonal matrix. By default, only eigenvalues are computed:\n",
      "        \n",
      "            >>> a = torch.diag(torch.tensor([1, 2, 3], dtype=torch.double))\n",
      "            >>> e, v = torch.eig(a)\n",
      "            >>> e\n",
      "            tensor([[1., 0.],\n",
      "                    [2., 0.],\n",
      "                    [3., 0.]], dtype=torch.float64)\n",
      "            >>> v\n",
      "            tensor([], dtype=torch.float64)\n",
      "        \n",
      "            Compute also the eigenvectors:\n",
      "        \n",
      "            >>> e, v = torch.eig(a, eigenvectors=True)\n",
      "            >>> e\n",
      "            tensor([[1., 0.],\n",
      "                    [2., 0.],\n",
      "                    [3., 0.]], dtype=torch.float64)\n",
      "            >>> v\n",
      "            tensor([[1., 0., 0.],\n",
      "                    [0., 1., 0.],\n",
      "                    [0., 0., 1.]], dtype=torch.float64)\n",
      "    \n",
      "    einsum(equation, *operands)\n",
      "        einsum(equation, *operands) -> Tensor\n",
      "        \n",
      "        Sums the product of the elements of the input :attr:`operands` along dimensions specified using a notation\n",
      "        based on the Einstein summation convention.\n",
      "        \n",
      "        Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\n",
      "        in a short-hand format based on the Einstein summation convention, given by :attr:`equation`. The details of\n",
      "        this format are described below, but the general idea is to label every dimension of the input :attr:`operands`\n",
      "        with some subscript and define which subscripts are part of the output. The output is then computed by summing\n",
      "        the product of the elements of the :attr:`operands` along the dimensions whose subscripts are not part of the\n",
      "        output. For example, matrix multiplication can be computed using einsum as `torch.einsum(\"ij,jk->ik\", A, B)`.\n",
      "        Here, j is the summation subscript and i and k the output subscripts (see section below for more details on why).\n",
      "        \n",
      "        Equation:\n",
      "        \n",
      "            The :attr:`equation` string specifies the subscripts (lower case letters `['a', 'z']`) for each dimension of\n",
      "            the input :attr:`operands` in the same order as the dimensions, separating subcripts for each operand by a\n",
      "            comma (','), e.g. `'ij,jk'` specify subscripts for two 2D operands. The dimensions labeled with the same subscript\n",
      "            must be broadcastable, that is, their size must either match or be `1`. The exception is if a subscript is\n",
      "            repeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\n",
      "            must match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\n",
      "            appear exactly once in the :attr:`equation` will be part of the output, sorted in increasing alphabetical order.\n",
      "            The output is computed by multiplying the input :attr:`operands` element-wise, with their dimensions aligned based\n",
      "            on the subscripts, and then summing out the dimensions whose subscripts are not part of the output.\n",
      "        \n",
      "            Optionally, the output subscripts can be explicitly defined by adding an arrow ('->') at the end of the equation\n",
      "            followed by the subscripts for the output. For instance, the following equation computes the transpose of a\n",
      "            matrix multiplication: 'ij,jk->ki'. The output subscripts must appear at least once for some input operand and\n",
      "            at most once for the output.\n",
      "        \n",
      "            Ellipsis ('...') can be used in place of subscripts to broadcast the dimensions covered by the ellipsis.\n",
      "            Each input operand may contain at most one ellipsis which will cover the dimensions not covered by subscripts,\n",
      "            e.g. for an input operand with 5 dimensions, the ellipsis in the equation `'ab...c'` cover the third and fourth\n",
      "            dimensions. The ellipsis does not need to cover the same number of dimensions across the :attr:`operands` but the\n",
      "            'shape' of the ellipsis (the size of the dimensions covered by them) must broadcast together. If the output is not\n",
      "            explicitly defined with the arrow ('->') notation, the ellipsis will come first in the output (left-most dimensions),\n",
      "            before the subscript labels that appear exactly once for the input operands. e.g. the following equation implements\n",
      "            batch matrix multiplication `'...ij,...jk'`.\n",
      "        \n",
      "            A few final notes: the equation may contain whitespaces between the different elements (subscripts, ellipsis,\n",
      "            arrow and comma) but something like `'. . .'` is not valid. An empty string `''` is valid for scalar operands.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            ``torch.einsum`` handles ellipsis ('...') differently from NumPy in that it allows dimensions\n",
      "            covered by the ellipsis to be summed over, that is, ellipsis are not required to be part of the output.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            This function does not optimize the given expression, so a different formula for the same computation may\n",
      "            run faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)\n",
      "            can optimize the formula for you.\n",
      "        \n",
      "        Args:\n",
      "            equation (string): The subscripts for the Einstein summation.\n",
      "            operands (Tensor): The operands to compute the Einstein sum of.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            # trace\n",
      "            >>> torch.einsum('ii', torch.randn(4, 4))\n",
      "            tensor(-1.2104)\n",
      "        \n",
      "            # diagonal\n",
      "            >>> torch.einsum('ii->i', torch.randn(4, 4))\n",
      "            tensor([-0.1034,  0.7952, -0.2433,  0.4545])\n",
      "        \n",
      "            # outer product\n",
      "            >>> x = torch.randn(5)\n",
      "            >>> y = torch.randn(4)\n",
      "            >>> torch.einsum('i,j->ij', x, y)\n",
      "            tensor([[ 0.1156, -0.2897, -0.3918,  0.4963],\n",
      "                    [-0.3744,  0.9381,  1.2685, -1.6070],\n",
      "                    [ 0.7208, -1.8058, -2.4419,  3.0936],\n",
      "                    [ 0.1713, -0.4291, -0.5802,  0.7350],\n",
      "                    [ 0.5704, -1.4290, -1.9323,  2.4480]])\n",
      "        \n",
      "            # batch matrix multiplication\n",
      "            >>> As = torch.randn(3,2,5)\n",
      "            >>> Bs = torch.randn(3,5,4)\n",
      "            >>> torch.einsum('bij,bjk->bik', As, Bs)\n",
      "            tensor([[[-1.0564, -1.5904,  3.2023,  3.1271],\n",
      "                    [-1.6706, -0.8097, -0.8025, -2.1183]],\n",
      "        \n",
      "                    [[ 4.2239,  0.3107, -0.5756, -0.2354],\n",
      "                    [-1.4558, -0.3460,  1.5087, -0.8530]],\n",
      "        \n",
      "                    [[ 2.8153,  1.8787, -4.3839, -1.2112],\n",
      "                    [ 0.3728, -2.1131,  0.0921,  0.8305]]])\n",
      "        \n",
      "            # batch permute\n",
      "            >>> A = torch.randn(2, 3, 4, 5)\n",
      "            >>> torch.einsum('...ij->...ji', A).shape\n",
      "            torch.Size([2, 3, 5, 4])\n",
      "        \n",
      "            # equivalent to torch.nn.functional.bilinear\n",
      "            >>> A = torch.randn(3,5,4)\n",
      "            >>> l = torch.randn(2,5)\n",
      "            >>> r = torch.randn(2,4)\n",
      "            >>> torch.einsum('bn,anm,bm->ba', l, A, r)\n",
      "            tensor([[-0.3430, -5.2405,  0.4494],\n",
      "                    [ 0.3311,  5.5201, -3.0356]])\n",
      "    \n",
      "    embedding(...)\n",
      "    \n",
      "    embedding_bag(...)\n",
      "    \n",
      "    embedding_renorm_(...)\n",
      "    \n",
      "    empty(...)\n",
      "        empty(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with uninitialized data. The shape of the tensor is\n",
      "        defined by the variable argument :attr:`size`.\n",
      "        \n",
      "        Args:\n",
      "            size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "                Can be a variable number of arguments or a collection like a list or tuple.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "            pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
      "                the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
      "            memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "                returned Tensor. Default: ``torch.contiguous_format``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.empty(2, 3)\n",
      "            tensor(1.00000e-08 *\n",
      "                   [[ 6.3984,  0.0000,  0.0000],\n",
      "                    [ 0.0000,  0.0000,  0.0000]])\n",
      "    \n",
      "    empty_like(...)\n",
      "        empty_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) -> Tensor\n",
      "        \n",
      "        Returns an uninitialized tensor with the same size as :attr:`input`.\n",
      "        ``torch.empty_like(input)`` is equivalent to\n",
      "        ``torch.empty(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the size of :attr:`input` will determine size of the output tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned Tensor.\n",
      "                Default: if ``None``, defaults to the dtype of :attr:`input`.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned tensor.\n",
      "                Default: if ``None``, defaults to the layout of :attr:`input`.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, defaults to the device of :attr:`input`.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "            memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "                returned Tensor. Default: ``torch.preserve_format``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.empty((2,3), dtype=torch.int64)\n",
      "            tensor([[ 9.4064e+13,  2.8000e+01,  9.3493e+13],\n",
      "                    [ 7.5751e+18,  7.1428e+18,  7.5955e+18]])\n",
      "    \n",
      "    empty_meta(...)\n",
      "    \n",
      "    empty_quantized(...)\n",
      "    \n",
      "    empty_strided(...)\n",
      "        empty_strided(size, stride, *, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with uninitialized data. The shape and strides of the tensor is\n",
      "        defined by the variable argument :attr:`size` and :attr:`stride` respectively.\n",
      "        ``torch.empty_strided(size, stride)`` is equivalent to\n",
      "        ``torch.empty(size).as_strided(size, stride)``.\n",
      "        \n",
      "        .. warning::\n",
      "            More than one element of the created tensor may refer to a single memory\n",
      "            location. As a result, in-place operations (especially ones that are\n",
      "            vectorized) may result in incorrect behavior. If you need to write to\n",
      "            the tensors, please clone them first.\n",
      "        \n",
      "        Args:\n",
      "            size (tuple of ints): the shape of the output tensor\n",
      "            stride (tuple of ints): the strides of the output tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "            pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
      "                the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.empty_strided((2, 3), (1, 2))\n",
      "            >>> a\n",
      "            tensor([[8.9683e-44, 4.4842e-44, 5.1239e+07],\n",
      "                    [0.0000e+00, 0.0000e+00, 3.0705e-41]])\n",
      "            >>> a.stride()\n",
      "            (1, 2)\n",
      "            >>> a.size()\n",
      "            torch.Size([2, 3])\n",
      "    \n",
      "    eq(...)\n",
      "        eq(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes element-wise equality\n",
      "        \n",
      "        The second argument can be a number or a tensor whose shape is\n",
      "        :ref:`broadcastable <broadcasting-semantics>` with the first argument.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to compare\n",
      "            other (Tensor or float): the tensor or value to compare\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Returns:\n",
      "            A boolean tensor that is True where :attr:`input` is equal to :attr:`other` and False elsewhere\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.eq(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\n",
      "            tensor([[ True, False],\n",
      "                    [False, True]])\n",
      "    \n",
      "    equal(...)\n",
      "        equal(input, other) -> bool\n",
      "        \n",
      "        ``True`` if two tensors have the same size and elements, ``False`` otherwise.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.equal(torch.tensor([1, 2]), torch.tensor([1, 2]))\n",
      "            True\n",
      "    \n",
      "    erf(...)\n",
      "        erf(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the error function of each element. The error function is defined as follows:\n",
      "        \n",
      "        .. math::\n",
      "            \\mathrm{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2} dt\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.erf(torch.tensor([0, -1., 10.]))\n",
      "            tensor([ 0.0000, -0.8427,  1.0000])\n",
      "    \n",
      "    erf_(...)\n",
      "    \n",
      "    erfc(...)\n",
      "        erfc(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the complementary error function of each element of :attr:`input`.\n",
      "        The complementary error function is defined as follows:\n",
      "        \n",
      "        .. math::\n",
      "            \\mathrm{erfc}(x) = 1 - \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2} dt\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.erfc(torch.tensor([0, -1., 10.]))\n",
      "            tensor([ 1.0000, 1.8427,  0.0000])\n",
      "    \n",
      "    erfc_(...)\n",
      "    \n",
      "    erfinv(...)\n",
      "        erfinv(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the inverse error function of each element of :attr:`input`.\n",
      "        The inverse error function is defined in the range :math:`(-1, 1)` as:\n",
      "        \n",
      "        .. math::\n",
      "            \\mathrm{erfinv}(\\mathrm{erf}(x)) = x\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.erfinv(torch.tensor([0, 0.5, -1.]))\n",
      "            tensor([ 0.0000,  0.4769,    -inf])\n",
      "    \n",
      "    exp(...)\n",
      "        exp(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the exponential of the elements\n",
      "        of the input tensor :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            y_{i} = e^{x_{i}}\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.exp(torch.tensor([0, math.log(2.)]))\n",
      "            tensor([ 1.,  2.])\n",
      "    \n",
      "    exp2(...)\n",
      "        exp2(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the base two exponential function of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            y_{i} = 2^{x_{i}}\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.exp2(torch.tensor([0, math.log2(2.), 3, 4]))\n",
      "            tensor([ 1.,  2.,  8., 16.])\n",
      "    \n",
      "    exp2_(...)\n",
      "    \n",
      "    exp_(...)\n",
      "    \n",
      "    expm1(...)\n",
      "        expm1(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the exponential of the elements minus 1\n",
      "        of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            y_{i} = e^{x_{i}} - 1\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.expm1(torch.tensor([0, math.log(2.)]))\n",
      "            tensor([ 0.,  1.])\n",
      "    \n",
      "    expm1_(...)\n",
      "    \n",
      "    eye(...)\n",
      "        eye(n, m=None, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
      "        \n",
      "        Args:\n",
      "            n (int): the number of rows\n",
      "            m (int, optional): the number of columns with default being :attr:`n`\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A 2-D tensor with ones on the diagonal and zeros elsewhere\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.eye(3)\n",
      "            tensor([[ 1.,  0.,  0.],\n",
      "                    [ 0.,  1.,  0.],\n",
      "                    [ 0.,  0.,  1.]])\n",
      "    \n",
      "    fake_quantize_per_channel_affine(...)\n",
      "        fake_quantize_per_channel_affine(input, scale, zero_point, quant_min, quant_max) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the data in :attr:`input` fake quantized per channel using :attr:`scale`,\n",
      "        :attr:`zero_point`, :attr:`quant_min` and :attr:`quant_max`, across the channel specified by :attr:`axis`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{output} = min(\n",
      "                \\text{quant\\_max},\n",
      "                max(\n",
      "                    \\text{quant\\_min},\n",
      "                    \\text{std::nearby\\_int}(\\text{input} / \\text{scale}) + \\text{zero\\_point}\n",
      "                )\n",
      "            )\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input value(s), in ``torch.float32``.\n",
      "            scale (Tensor): quantization scale, per channel\n",
      "            zero_point (Tensor): quantization zero_point, per channel\n",
      "            axis (int32): channel axis\n",
      "            quant_min (int64): lower bound of the quantized domain\n",
      "            quant_max (int64): upper bound of the quantized domain\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A newly fake_quantized per channel tensor\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.randn(2, 2, 2)\n",
      "            >>> x\n",
      "            tensor([[[-0.2525, -0.0466],\n",
      "                     [ 0.3491, -0.2168]],\n",
      "        \n",
      "                    [[-0.5906,  1.6258],\n",
      "                     [ 0.6444, -0.0542]]])\n",
      "            >>> scales = (torch.randn(2) + 1) * 0.05\n",
      "            >>> scales\n",
      "            tensor([0.0475, 0.0486])\n",
      "            >>> zero_points = torch.zeros(2).to(torch.long)\n",
      "            >>> zero_points\n",
      "            tensor([0, 0])\n",
      "            >>> torch.fake_quantize_per_channel_affine(x, scales, zero_points, 1, 0, 255)\n",
      "            tensor([[[0.0000, 0.0000],\n",
      "                     [0.3405, 0.0000]],\n",
      "        \n",
      "                    [[0.0000, 1.6134],\n",
      "                    [0.6323, 0.0000]]])\n",
      "    \n",
      "    fake_quantize_per_tensor_affine(...)\n",
      "        fake_quantize_per_tensor_affine(input, scale, zero_point, quant_min, quant_max) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the data in :attr:`input` fake quantized using :attr:`scale`,\n",
      "        :attr:`zero_point`, :attr:`quant_min` and :attr:`quant_max`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{output} = min(\n",
      "                \\text{quant\\_max},\n",
      "                max(\n",
      "                    \\text{quant\\_min},\n",
      "                    \\text{std::nearby\\_int}(\\text{input} / \\text{scale}) + \\text{zero\\_point}\n",
      "                )\n",
      "            )\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input value(s), in ``torch.float32``.\n",
      "            scale (double): quantization scale\n",
      "            zero_point (int64): quantization zero_point\n",
      "            quant_min (int64): lower bound of the quantized domain\n",
      "            quant_max (int64): upper bound of the quantized domain\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A newly fake_quantized tensor\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.randn(4)\n",
      "            >>> x\n",
      "            tensor([ 0.0552,  0.9730,  0.3973, -1.0780])\n",
      "            >>> torch.fake_quantize_per_tensor_affine(x, 0.1, 0, 0, 255)\n",
      "            tensor([0.1000, 1.0000, 0.4000, 0.0000])\n",
      "    \n",
      "    fbgemm_linear_fp16_weight(...)\n",
      "    \n",
      "    fbgemm_linear_fp16_weight_fp32_activation(...)\n",
      "    \n",
      "    fbgemm_linear_int8_weight(...)\n",
      "    \n",
      "    fbgemm_linear_int8_weight_fp32_activation(...)\n",
      "    \n",
      "    fbgemm_linear_quantize_weight(...)\n",
      "    \n",
      "    fbgemm_pack_gemm_matrix_fp16(...)\n",
      "    \n",
      "    fbgemm_pack_quantized_matrix(...)\n",
      "    \n",
      "    feature_alpha_dropout(...)\n",
      "    \n",
      "    feature_alpha_dropout_(...)\n",
      "    \n",
      "    feature_dropout(...)\n",
      "    \n",
      "    feature_dropout_(...)\n",
      "    \n",
      "    fill_(...)\n",
      "    \n",
      "    fix(...)\n",
      "        fix(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.trunc`\n",
      "    \n",
      "    fix_(...)\n",
      "    \n",
      "    flatten(...)\n",
      "        flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "        \n",
      "        Flattens :attr:`input` by reshaping it into a one-dimensional tensor. If :attr:`start_dim` or :attr:`end_dim`\n",
      "        are passed, only dimensions starting with :attr:`start_dim` and ending with :attr:`end_dim` are flattened.\n",
      "        The order of elements in :attr:`input` is unchanged.\n",
      "        \n",
      "        Unlike NumPy's flatten, which always copies input's data, this function may return the original object, a view,\n",
      "        or copy. If no dimensions are flattened, then the original object :attr:`input` is returned. Otherwise, if input can\n",
      "        be viewed as the flattened shape, then that view is returned. Finally, only if the input cannot be viewed as the\n",
      "        flattened shape is input's data copied. See :meth:`torch.Tensor.view` for details on when a view will be returned.\n",
      "        \n",
      "        .. note::\n",
      "            Flattening a zero-dimensional tensor will return a one-dimensional view.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            start_dim (int): the first dim to flatten\n",
      "            end_dim (int): the last dim to flatten\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> t = torch.tensor([[[1, 2],\n",
      "            ...                    [3, 4]],\n",
      "            ...                   [[5, 6],\n",
      "            ...                    [7, 8]]])\n",
      "            >>> torch.flatten(t)\n",
      "            tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "            >>> torch.flatten(t, start_dim=1)\n",
      "            tensor([[1, 2, 3, 4],\n",
      "                    [5, 6, 7, 8]])\n",
      "    \n",
      "    flip(...)\n",
      "        flip(input, dims) -> Tensor\n",
      "        \n",
      "        Reverse the order of a n-D tensor along given axis in dims.\n",
      "        \n",
      "        .. note::\n",
      "            `torch.flip` makes a copy of :attr:`input`'s data. This is different from NumPy's `np.flip`,\n",
      "            which returns a view in constant time. Since copying a tensor's data is more work than viewing that data,\n",
      "            `torch.flip` is expected to be slower than `np.flip`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dims (a list or tuple): axis to flip on\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.arange(8).view(2, 2, 2)\n",
      "            >>> x\n",
      "            tensor([[[ 0,  1],\n",
      "                     [ 2,  3]],\n",
      "        \n",
      "                    [[ 4,  5],\n",
      "                     [ 6,  7]]])\n",
      "            >>> torch.flip(x, [0, 1])\n",
      "            tensor([[[ 6,  7],\n",
      "                     [ 4,  5]],\n",
      "        \n",
      "                    [[ 2,  3],\n",
      "                     [ 0,  1]]])\n",
      "    \n",
      "    fliplr(...)\n",
      "        fliplr(input) -> Tensor\n",
      "        \n",
      "        Flip tensor in the left/right direction, returning a new tensor.\n",
      "        \n",
      "        Flip the entries in each row in the left/right direction.\n",
      "        Columns are preserved, but appear in a different order than before.\n",
      "        \n",
      "        Note:\n",
      "            Requires the tensor to be at least 2-D.\n",
      "        \n",
      "        .. note::\n",
      "            `torch.fliplr` makes a copy of :attr:`input`'s data. This is different from NumPy's `np.fliplr`,\n",
      "            which returns a view in constant time. Since copying a tensor's data is more work than viewing that data,\n",
      "            `torch.fliplr` is expected to be slower than `np.fliplr`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): Must be at least 2-dimensional.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.arange(4).view(2, 2)\n",
      "            >>> x\n",
      "            tensor([[0, 1],\n",
      "                    [2, 3]])\n",
      "            >>> torch.fliplr(x)\n",
      "            tensor([[1, 0],\n",
      "                    [3, 2]])\n",
      "    \n",
      "    flipud(...)\n",
      "        flipud(input) -> Tensor\n",
      "        \n",
      "        Flip tensor in the up/down direction, returning a new tensor.\n",
      "        \n",
      "        Flip the entries in each column in the up/down direction.\n",
      "        Rows are preserved, but appear in a different order than before.\n",
      "        \n",
      "        Note:\n",
      "            Requires the tensor to be at least 1-D.\n",
      "        \n",
      "        .. note::\n",
      "            `torch.flipud` makes a copy of :attr:`input`'s data. This is different from NumPy's `np.flipud`,\n",
      "            which returns a view in constant time. Since copying a tensor's data is more work than viewing that data,\n",
      "            `torch.flipud` is expected to be slower than `np.flipud`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): Must be at least 1-dimensional.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.arange(4).view(2, 2)\n",
      "            >>> x\n",
      "            tensor([[0, 1],\n",
      "                    [2, 3]])\n",
      "            >>> torch.flipud(x)\n",
      "            tensor([[2, 3],\n",
      "                    [0, 1]])\n",
      "    \n",
      "    float_power(...)\n",
      "        float_power(input, exponent, *, out=None) -> Tensor\n",
      "        \n",
      "        Raises :attr:`input` to the power of :attr:`exponent`, elementwise, in double precision.\n",
      "        If neither input is complex returns a ``torch.float64`` tensor,\n",
      "        and if one or more inputs is complex returns a ``torch.complex128`` tensor.\n",
      "        \n",
      "        .. note::\n",
      "            This function always computes in double precision, unlike :func:`torch.pow`,\n",
      "            which implements more typical :ref:`type promotion <type-promotion-doc>`.\n",
      "            This is useful when the computation needs to be performed in a wider or more precise dtype,\n",
      "            or the results of the computation may contain fractional values not representable in the input dtypes,\n",
      "            like when an integer base is raised to a negative integer exponent.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor or Number): the base value(s)\n",
      "            exponent (Tensor or Number): the exponent value(s)\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randint(10, (4,))\n",
      "            >>> a\n",
      "            tensor([6, 4, 7, 1])\n",
      "            >>> torch.float_power(a, 2)\n",
      "            tensor([36., 16., 49.,  1.], dtype=torch.float64)\n",
      "        \n",
      "            >>> a = torch.arange(1, 5)\n",
      "            >>> a\n",
      "            tensor([ 1,  2,  3,  4])\n",
      "            >>> exp = torch.tensor([2, -3, 4, -5])\n",
      "            >>> exp\n",
      "            tensor([ 2, -3,  4, -5])\n",
      "            >>> torch.float_power(a, exp)\n",
      "            tensor([1.0000e+00, 1.2500e-01, 8.1000e+01, 9.7656e-04], dtype=torch.float64)\n",
      "    \n",
      "    floor(...)\n",
      "        floor(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the floor of the elements of :attr:`input`,\n",
      "        the largest integer less than or equal to each element.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\left\\lfloor \\text{input}_{i} \\right\\rfloor\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-0.8166,  1.5308, -0.2530, -0.2091])\n",
      "            >>> torch.floor(a)\n",
      "            tensor([-1.,  1., -1., -1.])\n",
      "    \n",
      "    floor_(...)\n",
      "    \n",
      "    floor_divide(...)\n",
      "        floor_divide(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        .. warning::\n",
      "            This function's name is a misnomer. It actually rounds the\n",
      "            quotient towards zero instead of taking its floor. This behavior\n",
      "            will be deprecated in a future PyTorch release.\n",
      "        \n",
      "        Computes :attr:`input` divided by :attr:`other`, elementwise, and rounds each\n",
      "        quotient towards zero. Equivalently, it truncates the quotient(s):\n",
      "        \n",
      "        .. math::\n",
      "            \\text{{out}}_i = \\text{trunc} \\left( \\frac{{\\text{{input}}_i}}{{\\text{{other}}_i}} \\right)\n",
      "        \n",
      "        \n",
      "        \n",
      "        Supports broadcasting to a common shape, type promotion, and integer and float inputs.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor or Number): the dividend\n",
      "            other (Tensor or Number): the divisor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([4.0, 3.0])\n",
      "            >>> b = torch.tensor([2.0, 2.0])\n",
      "            >>> torch.floor_divide(a, b)\n",
      "            tensor([2.0, 1.0])\n",
      "            >>> torch.floor_divide(a, 1.4)\n",
      "            tensor([2.0, 2.0])\n",
      "    \n",
      "    fmax(...)\n",
      "        fmax(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise maximum of :attr:`input` and :attr:`other`.\n",
      "        \n",
      "        This is like :func:`torch.maximum` except it handles NaNs differently:\n",
      "        if exactly one of the two elements being compared is a NaN then the non-NaN element is taken as the maximum.\n",
      "        Only if both elements are NaN is NaN propagated.\n",
      "        \n",
      "        This function is a wrapper around C++'s ``std::fmax`` and is similar to NumPy's ``fmax`` function.\n",
      "        \n",
      "        Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`,\n",
      "        :ref:`type promotion <type-promotion-doc>`, and integer and floating-point inputs.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([9.7, float('nan'), 3.1, float('nan')])\n",
      "            >>> b = torch.tensor([-2.2, 0.5, float('nan'), float('nan')])\n",
      "            >>> torch.fmax(a, b)\n",
      "            tensor([9.7000, 0.5000, 3.1000,    nan])\n",
      "    \n",
      "    fmin(...)\n",
      "        fmin(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise minimum of :attr:`input` and :attr:`other`.\n",
      "        \n",
      "        This is like :func:`torch.minimum` except it handles NaNs differently:\n",
      "        if exactly one of the two elements being compared is a NaN then the non-NaN element is taken as the minimum.\n",
      "        Only if both elements are NaN is NaN propagated.\n",
      "        \n",
      "        This function is a wrapper around C++'s ``std::fmin`` and is similar to NumPy's ``fmin`` function.\n",
      "        \n",
      "        Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`,\n",
      "        :ref:`type promotion <type-promotion-doc>`, and integer and floating-point inputs.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([2.2, float('nan'), 2.1, float('nan')])\n",
      "            >>> b = torch.tensor([-9.3, 0.1, float('nan'), float('nan')])\n",
      "            >>> torch.fmin(a, b)\n",
      "            tensor([-9.3000, 0.1000, 2.1000,    nan])\n",
      "    \n",
      "    fmod(...)\n",
      "        fmod(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise remainder of division.\n",
      "        \n",
      "        The dividend and divisor may contain both for integer and floating point\n",
      "        numbers. The remainder has the same sign as the dividend :attr:`input`.\n",
      "        \n",
      "        Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`,\n",
      "        :ref:`type promotion <type-promotion-doc>`, and integer and float inputs.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            When the divisor is zero, returns ``NaN`` for floating point dtypes\n",
      "            on both CPU and GPU; raises ``RuntimeError`` for integer division by\n",
      "            zero on CPU; Integer division by zero on GPU may return any value.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the dividend\n",
      "            other (Tensor or Scalar): the divisor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.fmod(torch.tensor([-3., -2, -1, 1, 2, 3]), 2)\n",
      "            tensor([-1., -0., -1.,  1.,  0.,  1.])\n",
      "            >>> torch.fmod(torch.tensor([1, 2, 3, 4, 5]), 1.5)\n",
      "            tensor([1.0000, 0.5000, 0.0000, 1.0000, 0.5000])\n",
      "    \n",
      "    fork(...) method of builtins.PyCapsule instance\n",
      "        fork(*args, **kwargs) -> torch._C.Future\n",
      "    \n",
      "    frac(...)\n",
      "        frac(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the fractional portion of each element in :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\text{input}_{i} - \\left\\lfloor |\\text{input}_{i}| \\right\\rfloor * \\operatorname{sgn}(\\text{input}_{i})\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.frac(torch.tensor([1, 2.5, -3.2]))\n",
      "            tensor([ 0.0000,  0.5000, -0.2000])\n",
      "    \n",
      "    frac_(...)\n",
      "    \n",
      "    frobenius_norm(...)\n",
      "    \n",
      "    from_file(...)\n",
      "    \n",
      "    from_numpy(...)\n",
      "        from_numpy(ndarray) -> Tensor\n",
      "        \n",
      "        Creates a :class:`Tensor` from a :class:`numpy.ndarray`.\n",
      "        \n",
      "        The returned tensor and :attr:`ndarray` share the same memory. Modifications to\n",
      "        the tensor will be reflected in the :attr:`ndarray` and vice versa. The returned\n",
      "        tensor is not resizable.\n",
      "        \n",
      "        It currently accepts :attr:`ndarray` with dtypes of ``numpy.float64``,\n",
      "        ``numpy.float32``, ``numpy.float16``, ``numpy.complex64``, ``numpy.complex128``,\n",
      "        ``numpy.int64``, ``numpy.int32``, ``numpy.int16``, ``numpy.int8``, ``numpy.uint8``,\n",
      "        and ``numpy.bool``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = numpy.array([1, 2, 3])\n",
      "            >>> t = torch.from_numpy(a)\n",
      "            >>> t\n",
      "            tensor([ 1,  2,  3])\n",
      "            >>> t[0] = -1\n",
      "            >>> a\n",
      "            array([-1,  2,  3])\n",
      "    \n",
      "    full(...)\n",
      "        full(size, fill_value, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Creates a tensor of size :attr:`size` filled with :attr:`fill_value`. The\n",
      "        tensor's dtype is inferred from :attr:`fill_value`.\n",
      "        \n",
      "        Args:\n",
      "            size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "                shape of the output tensor.\n",
      "            fill_value (Scalar): the value to fill the output tensor with.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.full((2, 3), 3.141592)\n",
      "            tensor([[ 3.1416,  3.1416,  3.1416],\n",
      "                    [ 3.1416,  3.1416,  3.1416]])\n",
      "    \n",
      "    full_like(...)\n",
      "        full_like(input, fill_value, \\*, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format) -> Tensor\n",
      "        \n",
      "        Returns a tensor with the same size as :attr:`input` filled with :attr:`fill_value`.\n",
      "        ``torch.full_like(input, fill_value)`` is equivalent to\n",
      "        ``torch.full(input.size(), fill_value, dtype=input.dtype, layout=input.layout, device=input.device)``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the size of :attr:`input` will determine size of the output tensor.\n",
      "            fill_value: the number to fill the output tensor with.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned Tensor.\n",
      "                Default: if ``None``, defaults to the dtype of :attr:`input`.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned tensor.\n",
      "                Default: if ``None``, defaults to the layout of :attr:`input`.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, defaults to the device of :attr:`input`.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "            memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "                returned Tensor. Default: ``torch.preserve_format``.\n",
      "    \n",
      "    gather(...)\n",
      "        gather(input, dim, index, *, sparse_grad=False, out=None) -> Tensor\n",
      "        \n",
      "        Gathers values along an axis specified by `dim`.\n",
      "        \n",
      "        For a 3-D tensor the output is specified by::\n",
      "        \n",
      "            out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\n",
      "            out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\n",
      "            out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n",
      "        \n",
      "        :attr:`input` and :attr:`index` must have the same number of dimensions.\n",
      "        It is also required that ``index.size(d) <= input.size(d)`` for all\n",
      "        dimensions ``d != dim``.  :attr:`out` will have the same shape as :attr:`index`.\n",
      "        Note that ``input`` and ``index`` do not broadcast against each other.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the source tensor\n",
      "            dim (int): the axis along which to index\n",
      "            index (LongTensor): the indices of elements to gather\n",
      "        \n",
      "        Keyword arguments:\n",
      "            sparse_grad (bool, optional): If ``True``, gradient w.r.t. :attr:`input` will be a sparse tensor.\n",
      "            out (Tensor, optional): the destination tensor\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> t = torch.tensor([[1, 2], [3, 4]])\n",
      "            >>> torch.gather(t, 1, torch.tensor([[0, 0], [1, 0]]))\n",
      "            tensor([[ 1,  1],\n",
      "                    [ 4,  3]])\n",
      "    \n",
      "    gcd(...)\n",
      "        gcd(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise greatest common divisor (GCD) of :attr:`input` and :attr:`other`.\n",
      "        \n",
      "        Both :attr:`input` and :attr:`other` must have integer types.\n",
      "        \n",
      "        .. note::\n",
      "            This defines :math:`gcd(0, 0) = 0`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([5, 10, 15])\n",
      "            >>> b = torch.tensor([3, 4, 5])\n",
      "            >>> torch.gcd(a, b)\n",
      "            tensor([1, 2, 5])\n",
      "            >>> c = torch.tensor([3])\n",
      "            >>> torch.gcd(a, c)\n",
      "            tensor([1, 1, 3])\n",
      "    \n",
      "    gcd_(...)\n",
      "    \n",
      "    ge(...)\n",
      "        ge(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes :math:`\\text{input} \\geq \\text{other}` element-wise.\n",
      "        \n",
      "        \n",
      "        The second argument can be a number or a tensor whose shape is\n",
      "        :ref:`broadcastable <broadcasting-semantics>` with the first argument.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to compare\n",
      "            other (Tensor or float): the tensor or value to compare\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Returns:\n",
      "            A boolean tensor that is True where :attr:`input` is greater than or equal to :attr:`other` and False elsewhere\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.ge(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\n",
      "            tensor([[True, True], [False, True]])\n",
      "    \n",
      "    geqrf(...)\n",
      "        geqrf(input, *, out=None) -> (Tensor, Tensor)\n",
      "        \n",
      "        This is a low-level function for calling LAPACK directly. This function\n",
      "        returns a namedtuple (a, tau) as defined in `LAPACK documentation for geqrf`_ .\n",
      "        \n",
      "        You'll generally want to use :func:`torch.qr` instead.\n",
      "        \n",
      "        Computes a QR decomposition of :attr:`input`, but without constructing\n",
      "        :math:`Q` and :math:`R` as explicit separate matrices.\n",
      "        \n",
      "        Rather, this directly calls the underlying LAPACK function `?geqrf`\n",
      "        which produces a sequence of 'elementary reflectors'.\n",
      "        \n",
      "        See `LAPACK documentation for geqrf`_ for further details.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input matrix\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the output tuple of (Tensor, Tensor)\n",
      "        \n",
      "        .. _LAPACK documentation for geqrf:\n",
      "            https://software.intel.com/en-us/node/521004\n",
      "    \n",
      "    ger(...)\n",
      "        ger(input, vec2, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias of :func:`torch.outer`.\n",
      "        \n",
      "        .. warning::\n",
      "            This function is deprecated and will be removed in a future PyTorch release.\n",
      "            Use :func:`torch.outer` instead.\n",
      "    \n",
      "    get_default_dtype(...)\n",
      "        get_default_dtype() -> torch.dtype\n",
      "        \n",
      "        Get the current default floating point :class:`torch.dtype`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.get_default_dtype()  # initial default for floating point is torch.float32\n",
      "            torch.float32\n",
      "            >>> torch.set_default_dtype(torch.float64)\n",
      "            >>> torch.get_default_dtype()  # default is now changed to torch.float64\n",
      "            torch.float64\n",
      "            >>> torch.set_default_tensor_type(torch.FloatTensor)  # setting tensor type also affects this\n",
      "            >>> torch.get_default_dtype()  # changed to torch.float32, the dtype for torch.FloatTensor\n",
      "            torch.float32\n",
      "    \n",
      "    get_device(...)\n",
      "    \n",
      "    get_num_interop_threads(...)\n",
      "        get_num_interop_threads() -> int\n",
      "        \n",
      "        Returns the number of threads used for inter-op parallelism on CPU\n",
      "        (e.g. in JIT interpreter)\n",
      "    \n",
      "    get_num_threads(...)\n",
      "        get_num_threads() -> int\n",
      "        \n",
      "        Returns the number of threads used for parallelizing CPU operations\n",
      "    \n",
      "    get_rng_state() -> torch.Tensor\n",
      "        Returns the random number generator state as a `torch.ByteTensor`.\n",
      "    \n",
      "    greater(...)\n",
      "        greater(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.gt`.\n",
      "    \n",
      "    greater_equal(...)\n",
      "        greater_equal(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.ge`.\n",
      "    \n",
      "    grid_sampler(...)\n",
      "    \n",
      "    grid_sampler_2d(...)\n",
      "    \n",
      "    grid_sampler_3d(...)\n",
      "    \n",
      "    group_norm(...)\n",
      "    \n",
      "    gru(...)\n",
      "    \n",
      "    gru_cell(...)\n",
      "    \n",
      "    gt(...)\n",
      "        gt(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes :math:`\\text{input} > \\text{other}` element-wise.\n",
      "        \n",
      "        \n",
      "        The second argument can be a number or a tensor whose shape is\n",
      "        :ref:`broadcastable <broadcasting-semantics>` with the first argument.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to compare\n",
      "            other (Tensor or float): the tensor or value to compare\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Returns:\n",
      "            A boolean tensor that is True where :attr:`input` is greater than :attr:`other` and False elsewhere\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.gt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\n",
      "            tensor([[False, True], [False, False]])\n",
      "    \n",
      "    hamming_window(...)\n",
      "        hamming_window(window_length, periodic=True, alpha=0.54, beta=0.46, *, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Hamming window function.\n",
      "        \n",
      "        .. math::\n",
      "            w[n] = \\alpha - \\beta\\ \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right),\n",
      "        \n",
      "        where :math:`N` is the full window size.\n",
      "        \n",
      "        The input :attr:`window_length` is a positive integer controlling the\n",
      "        returned window size. :attr:`periodic` flag determines whether the returned\n",
      "        window trims off the last duplicate value from the symmetric window and is\n",
      "        ready to be used as a periodic window with functions like\n",
      "        :meth:`torch.stft`. Therefore, if :attr:`periodic` is true, the :math:`N` in\n",
      "        above formula is in fact :math:`\\text{window\\_length} + 1`. Also, we always have\n",
      "        ``torch.hamming_window(L, periodic=True)`` equal to\n",
      "        ``torch.hamming_window(L + 1, periodic=False)[:-1])``.\n",
      "        \n",
      "        .. note::\n",
      "            If :attr:`window_length` :math:`=1`, the returned window contains a single value 1.\n",
      "        \n",
      "        .. note::\n",
      "            This is a generalized version of :meth:`torch.hann_window`.\n",
      "        \n",
      "        Arguments:\n",
      "            window_length (int): the size of returned window\n",
      "            periodic (bool, optional): If True, returns a window to be used as periodic\n",
      "                function. If False, return a symmetric window.\n",
      "            alpha (float, optional): The coefficient :math:`\\alpha` in the equation above\n",
      "            beta (float, optional): The coefficient :math:`\\beta` in the equation above\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`). Only floating point types are supported.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned window tensor. Only\n",
      "                  ``torch.strided`` (dense layout) is supported.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A 1-D tensor of size :math:`(\\text{window\\_length},)` containing the window\n",
      "    \n",
      "    hann_window(...)\n",
      "        hann_window(window_length, periodic=True, *, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Hann window function.\n",
      "        \n",
      "        .. math::\n",
      "            w[n] = \\frac{1}{2}\\ \\left[1 - \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right)\\right] =\n",
      "                    \\sin^2 \\left( \\frac{\\pi n}{N - 1} \\right),\n",
      "        \n",
      "        where :math:`N` is the full window size.\n",
      "        \n",
      "        The input :attr:`window_length` is a positive integer controlling the\n",
      "        returned window size. :attr:`periodic` flag determines whether the returned\n",
      "        window trims off the last duplicate value from the symmetric window and is\n",
      "        ready to be used as a periodic window with functions like\n",
      "        :meth:`torch.stft`. Therefore, if :attr:`periodic` is true, the :math:`N` in\n",
      "        above formula is in fact :math:`\\text{window\\_length} + 1`. Also, we always have\n",
      "        ``torch.hann_window(L, periodic=True)`` equal to\n",
      "        ``torch.hann_window(L + 1, periodic=False)[:-1])``.\n",
      "        \n",
      "        .. note::\n",
      "            If :attr:`window_length` :math:`=1`, the returned window contains a single value 1.\n",
      "        \n",
      "        Arguments:\n",
      "            window_length (int): the size of returned window\n",
      "            periodic (bool, optional): If True, returns a window to be used as periodic\n",
      "                function. If False, return a symmetric window.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`). Only floating point types are supported.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned window tensor. Only\n",
      "                  ``torch.strided`` (dense layout) is supported.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A 1-D tensor of size :math:`(\\text{window\\_length},)` containing the window\n",
      "    \n",
      "    hardshrink(...)\n",
      "    \n",
      "    heaviside(...)\n",
      "        heaviside(input, values, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the Heaviside step function for each element in :attr:`input`.\n",
      "        The Heaviside step function is defined as:\n",
      "        \n",
      "        .. math::\n",
      "            \\text{{heaviside}}(input, values) = \\begin{cases}\n",
      "                0, & \\text{if input < 0}\\\\\n",
      "                values, & \\text{if input == 0}\\\\\n",
      "                1, & \\text{if input > 0}\n",
      "            \\end{cases}\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            values (Tensor): The values to use where :attr:`input` is zero.\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> input = torch.tensor([-1.5, 0, 2.0])\n",
      "            >>> values = torch.tensor([0.5])\n",
      "            >>> torch.heaviside(input, values)\n",
      "            tensor([0.0000, 0.5000, 1.0000])\n",
      "            >>> values = torch.tensor([1.2, -2.0, 3.5])\n",
      "            >>> torch.heaviside(input, values)\n",
      "            tensor([0., -2., 1.])\n",
      "    \n",
      "    hinge_embedding_loss(...)\n",
      "    \n",
      "    histc(...)\n",
      "        histc(input, bins=100, min=0, max=0, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the histogram of a tensor.\n",
      "        \n",
      "        The elements are sorted into equal width bins between :attr:`min` and\n",
      "        :attr:`max`. If :attr:`min` and :attr:`max` are both zero, the minimum and\n",
      "        maximum values of the data are used.\n",
      "        \n",
      "        Elements lower than min and higher than max are ignored.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            bins (int): number of histogram bins\n",
      "            min (int): lower end of the range (inclusive)\n",
      "            max (int): upper end of the range (inclusive)\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: Histogram represented as a tensor\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.histc(torch.tensor([1., 2, 1]), bins=4, min=0, max=3)\n",
      "            tensor([ 0.,  2.,  1.,  0.])\n",
      "    \n",
      "    hsmm(...)\n",
      "    \n",
      "    hspmm(...)\n",
      "        hspmm(mat1, mat2, *, out=None) -> Tensor\n",
      "        \n",
      "        Performs a matrix multiplication of a :ref:`sparse COO matrix\n",
      "        <sparse-coo-docs>` :attr:`mat1` and a strided matrix :attr:`mat2`. The\n",
      "        result is a (1 + 1)-dimensional :ref:`hybrid COO matrix\n",
      "        <sparse-hybrid-coo-docs>`.\n",
      "        \n",
      "        Args:\n",
      "            mat1 (Tensor): the first sparse matrix to be matrix multiplied\n",
      "            mat2 (Tensor): the second strided matrix to be matrix multiplied\n",
      "        \n",
      "        Keyword args:\n",
      "            {out}\n",
      "    \n",
      "    hstack(...)\n",
      "        hstack(tensors, *, out=None) -> Tensor\n",
      "        \n",
      "        Stack tensors in sequence horizontally (column wise).\n",
      "        \n",
      "        This is equivalent to concatenation along the first axis for 1-D tensors, and along the second axis for all other tensors.\n",
      "        \n",
      "        Args:\n",
      "            tensors (sequence of Tensors): sequence of tensors to concatenate\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([1, 2, 3])\n",
      "            >>> b = torch.tensor([4, 5, 6])\n",
      "            >>> torch.hstack((a,b))\n",
      "            tensor([1, 2, 3, 4, 5, 6])\n",
      "            >>> a = torch.tensor([[1],[2],[3]])\n",
      "            >>> b = torch.tensor([[4],[5],[6]])\n",
      "            >>> torch.hstack((a,b))\n",
      "            tensor([[1, 4],\n",
      "                    [2, 5],\n",
      "                    [3, 6]])\n",
      "    \n",
      "    hypot(...)\n",
      "        hypot(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Given the legs of a right triangle, return its hypotenuse.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\sqrt{\\text{input}_{i}^{2} + \\text{other}_{i}^{2}}\n",
      "        \n",
      "        The shapes of ``input`` and ``other`` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the first input tensor\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.hypot(torch.tensor([4.0]), torch.tensor([3.0, 4.0, 5.0]))\n",
      "            tensor([5.0000, 5.6569, 6.4031])\n",
      "    \n",
      "    i0(...)\n",
      "        i0(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the zeroth order modified Bessel function of the first kind for each element of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = I_0(\\text{input}_{i}) = \\sum_{k=0}^{\\infty} \\frac{(\\text{input}_{i}^2/4)^k}{(k!)^2}\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.i0(torch.arange(5, dtype=torch.float32))\n",
      "            tensor([ 1.0000,  1.2661,  2.2796,  4.8808, 11.3019])\n",
      "    \n",
      "    i0_(...)\n",
      "    \n",
      "    igamma(...)\n",
      "        igamma(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the regularized lower incomplete gamma function:\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\frac{1}{\\Gamma(\\text{input}_i)} \\int_0^{\\text{other}_i} t^{\\text{input}_i-1} e^{-t} dt\n",
      "        \n",
      "        where both :math:`\\text{input}_i` and :math:`\\text{other}_i` are weakly positive\n",
      "        and at least one is strictly positive.\n",
      "        If both are zero or either is negative then :math:`\\text{out}_i=\\text{nan}`.\n",
      "        :math:`\\Gamma(\\cdot)` in the equation above is the gamma function,\n",
      "        \n",
      "        .. math::\n",
      "            \\Gamma(\\text{input}_i) = \\int_0^\\infty t^{(\\text{input}_i-1)} e^{-t} dt.\n",
      "        \n",
      "        See :func:`torch.igammac` and :func:`torch.lgamma` for related functions.\n",
      "        \n",
      "        Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`\n",
      "        and float inputs.\n",
      "        \n",
      "        .. note::\n",
      "            The backward pass with respect to :attr:`input` is not yet supported.\n",
      "            Please open an issue on PyTorch's Github to request it.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the first non-negative input tensor\n",
      "            other (Tensor): the second non-negative input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a1 = torch.tensor([4.0])\n",
      "            >>> a2 = torch.tensor([3.0, 4.0, 5.0])\n",
      "            >>> a = torch.igammac(a1, a2)\n",
      "            tensor([0.3528, 0.5665, 0.7350])\n",
      "            tensor([0.3528, 0.5665, 0.7350])\n",
      "            >>> b = torch.igamma(a1, a2) + torch.igammac(a1, a2)\n",
      "            tensor([1., 1., 1.])\n",
      "    \n",
      "    igammac(...)\n",
      "        igammac(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the regularized upper incomplete gamma function:\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\frac{1}{\\Gamma(\\text{input}_i)} \\int_{\\text{other}_i}^{\\infty} t^{\\text{input}_i-1} e^{-t} dt\n",
      "        \n",
      "        where both :math:`\\text{input}_i` and :math:`\\text{other}_i` are weakly positive\n",
      "        and at least one is strictly positive.\n",
      "        If both are zero or either is negative then :math:`\\text{out}_i=\\text{nan}`.\n",
      "        :math:`\\Gamma(\\cdot)` in the equation above is the gamma function,\n",
      "        \n",
      "        .. math::\n",
      "            \\Gamma(\\text{input}_i) = \\int_0^\\infty t^{(\\text{input}_i-1)} e^{-t} dt.\n",
      "        \n",
      "        See :func:`torch.igamma` and :func:`torch.lgamma` for related functions.\n",
      "        \n",
      "        Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`\n",
      "        and float inputs.\n",
      "        \n",
      "        .. note::\n",
      "            The backward pass with respect to :attr:`input` is not yet supported.\n",
      "            Please open an issue on PyTorch's Github to request it.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the first non-negative input tensor\n",
      "            other (Tensor): the second non-negative input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a1 = torch.tensor([4.0])\n",
      "            >>> a2 = torch.tensor([3.0, 4.0, 5.0])\n",
      "            >>> a = torch.igammac(a1, a2)\n",
      "            tensor([0.6472, 0.4335, 0.2650])\n",
      "            >>> b = torch.igamma(a1, a2) + torch.igammac(a1, a2)\n",
      "            tensor([1., 1., 1.])\n",
      "    \n",
      "    imag(...)\n",
      "        imag(input) -> Tensor\n",
      "        \n",
      "        Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "        The returned tensor and :attr:`self` share the same underlying storage.\n",
      "        \n",
      "        .. warning::\n",
      "            :func:`imag` is only supported for tensors with complex dtypes.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "            >>> x\n",
      "            tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "            >>> x.imag\n",
      "            tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "    \n",
      "    import_ir_module(...) method of builtins.PyCapsule instance\n",
      "        import_ir_module(arg0: torch._C.CompilationUnit, arg1: str, arg2: object, arg3: dict) -> torch._C.ScriptModule\n",
      "    \n",
      "    import_ir_module_from_buffer(...) method of builtins.PyCapsule instance\n",
      "        import_ir_module_from_buffer(arg0: torch._C.CompilationUnit, arg1: str, arg2: object, arg3: dict) -> torch._C.ScriptModule\n",
      "    \n",
      "    index_add(...)\n",
      "    \n",
      "    index_copy(...)\n",
      "    \n",
      "    index_fill(...)\n",
      "    \n",
      "    index_put(...)\n",
      "    \n",
      "    index_put_(...)\n",
      "    \n",
      "    index_select(...)\n",
      "        index_select(input, dim, index, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor which indexes the :attr:`input` tensor along dimension\n",
      "        :attr:`dim` using the entries in :attr:`index` which is a `LongTensor`.\n",
      "        \n",
      "        The returned tensor has the same number of dimensions as the original tensor\n",
      "        (:attr:`input`).  The :attr:`dim`\\ th dimension has the same size as the length\n",
      "        of :attr:`index`; other dimensions have the same size as in the original tensor.\n",
      "        \n",
      "        .. note:: The returned tensor does **not** use the same storage as the original\n",
      "                  tensor.  If :attr:`out` has a different shape than expected, we\n",
      "                  silently change it to the correct shape, reallocating the underlying\n",
      "                  storage if necessary.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the dimension in which we index\n",
      "            index (IntTensor or LongTensor): the 1-D tensor containing the indices to index\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.randn(3, 4)\n",
      "            >>> x\n",
      "            tensor([[ 0.1427,  0.0231, -0.5414, -1.0009],\n",
      "                    [-0.4664,  0.2647, -0.1228, -1.1068],\n",
      "                    [-1.1734, -0.6571,  0.7230, -0.6004]])\n",
      "            >>> indices = torch.tensor([0, 2])\n",
      "            >>> torch.index_select(x, 0, indices)\n",
      "            tensor([[ 0.1427,  0.0231, -0.5414, -1.0009],\n",
      "                    [-1.1734, -0.6571,  0.7230, -0.6004]])\n",
      "            >>> torch.index_select(x, 1, indices)\n",
      "            tensor([[ 0.1427, -0.5414],\n",
      "                    [-0.4664, -0.1228],\n",
      "                    [-1.1734,  0.7230]])\n",
      "    \n",
      "    init_num_threads(...) method of builtins.PyCapsule instance\n",
      "        init_num_threads() -> None\n",
      "        \n",
      "        \n",
      "        init_num_threads()\n",
      "        \n",
      "        Initializes the number of parallel threads used on the current thread.\n",
      "        \n",
      "        Call this whenever a new thread is created in order to propagate values from\n",
      "        :func:`torch.set_num_threads` onto the new thread.\n",
      "    \n",
      "    initial_seed() -> int\n",
      "        Returns the initial seed for generating random numbers as a\n",
      "        Python `long`.\n",
      "    \n",
      "    inner(...)\n",
      "        inner(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the dot product for 1D tensors. For higher dimensions, sums the product\n",
      "        of elements from :attr:`input` and :attr:`other` along their last dimension.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            If either :attr:`input` or :attr:`other` is a scalar, the result is equivalent\n",
      "            to `torch.mul(input, other)`.\n",
      "        \n",
      "            If both :attr:`input` and :attr:`other` are non-scalars, the size of their last\n",
      "            dimension must match and the result is equivalent to `torch.tensordot(input,\n",
      "            other, dims=([-1], [-1]))`\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): First input tensor\n",
      "            other (Tensor): Second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): Optional output tensor to write result into. The output\n",
      "                                    shape is `input.shape[:-1] + other.shape[:-1]`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            # Dot product\n",
      "            >>> torch.inner(torch.tensor([1, 2, 3]), torch.tensor([0, 2, 1]))\n",
      "            tensor(7)\n",
      "        \n",
      "            # Multidimensional input tensors\n",
      "            >>> a = torch.randn(2, 3)\n",
      "            >>> a\n",
      "            tensor([[0.8173, 1.0874, 1.1784],\n",
      "                    [0.3279, 0.1234, 2.7894]])\n",
      "            >>> b = torch.randn(2, 4, 3)\n",
      "            >>> b\n",
      "            tensor([[[-0.4682, -0.7159,  0.1506],\n",
      "                    [ 0.4034, -0.3657,  1.0387],\n",
      "                    [ 0.9892, -0.6684,  0.1774],\n",
      "                    [ 0.9482,  1.3261,  0.3917]],\n",
      "        \n",
      "                    [[ 0.4537,  0.7493,  1.1724],\n",
      "                    [ 0.2291,  0.5749, -0.2267],\n",
      "                    [-0.7920,  0.3607, -0.3701],\n",
      "                    [ 1.3666, -0.5850, -1.7242]]])\n",
      "            >>> torch.inner(a, b)\n",
      "            tensor([[[-0.9837,  1.1560,  0.2907,  2.6785],\n",
      "                    [ 2.5671,  0.5452, -0.6912, -1.5509]],\n",
      "        \n",
      "                    [[ 0.1782,  2.9843,  0.7366,  1.5672],\n",
      "                    [ 3.5115, -0.4864, -1.2476, -4.4337]]])\n",
      "        \n",
      "            # Scalar input\n",
      "            >>> torch.inner(a, torch.tensor(2))\n",
      "            tensor([[1.6347, 2.1748, 2.3567],\n",
      "                    [0.6558, 0.2469, 5.5787]])\n",
      "    \n",
      "    instance_norm(...)\n",
      "    \n",
      "    int_repr(...)\n",
      "    \n",
      "    inverse(...)\n",
      "        inverse(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Takes the inverse of the square matrix :attr:`input`. :attr:`input` can be batches\n",
      "        of 2D square tensors, in which case this function would return a tensor composed of\n",
      "        individual inverses.\n",
      "        \n",
      "        Supports real and complex input.\n",
      "        \n",
      "        .. note:: :func:`torch.inverse` is deprecated. Please use :func:`torch.linalg.inv` instead.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            Irrespective of the original strides, the returned tensors will be\n",
      "            transposed, i.e. with strides like `input.contiguous().transpose(-2, -1).stride()`\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor of size :math:`(*, n, n)` where `*` is zero or more\n",
      "                            batch dimensions\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> x = torch.rand(4, 4)\n",
      "            >>> y = torch.inverse(x)\n",
      "            >>> z = torch.mm(x, y)\n",
      "            >>> z\n",
      "            tensor([[ 1.0000, -0.0000, -0.0000,  0.0000],\n",
      "                    [ 0.0000,  1.0000,  0.0000,  0.0000],\n",
      "                    [ 0.0000,  0.0000,  1.0000,  0.0000],\n",
      "                    [ 0.0000, -0.0000, -0.0000,  1.0000]])\n",
      "            >>> torch.max(torch.abs(z - torch.eye(4))) # Max non-zero\n",
      "            tensor(1.1921e-07)\n",
      "        \n",
      "            >>> # Batched inverse example\n",
      "            >>> x = torch.randn(2, 3, 4, 4)\n",
      "            >>> y = torch.inverse(x)\n",
      "            >>> z = torch.matmul(x, y)\n",
      "            >>> torch.max(torch.abs(z - torch.eye(4).expand_as(x))) # Max non-zero\n",
      "            tensor(1.9073e-06)\n",
      "        \n",
      "            >>> x = torch.rand(4, 4, dtype=torch.cdouble)\n",
      "            >>> y = torch.inverse(x)\n",
      "            >>> z = torch.mm(x, y)\n",
      "            >>> z\n",
      "            tensor([[ 1.0000e+00+0.0000e+00j, -1.3878e-16+3.4694e-16j,\n",
      "                    5.5511e-17-1.1102e-16j,  0.0000e+00-1.6653e-16j],\n",
      "                    [ 5.5511e-16-1.6653e-16j,  1.0000e+00+6.9389e-17j,\n",
      "                    2.2204e-16-1.1102e-16j, -2.2204e-16+1.1102e-16j],\n",
      "                    [ 3.8858e-16-1.2490e-16j,  2.7756e-17+3.4694e-17j,\n",
      "                    1.0000e+00+0.0000e+00j, -4.4409e-16+5.5511e-17j],\n",
      "                    [ 4.4409e-16+5.5511e-16j, -3.8858e-16+1.8041e-16j,\n",
      "                    2.2204e-16+0.0000e+00j,  1.0000e+00-3.4694e-16j]],\n",
      "                dtype=torch.complex128)\n",
      "            >>> torch.max(torch.abs(z - torch.eye(4, dtype=torch.cdouble))) # Max non-zero\n",
      "            tensor(7.5107e-16, dtype=torch.float64)\n",
      "    \n",
      "    is_anomaly_enabled(...)\n",
      "    \n",
      "    is_autocast_enabled(...)\n",
      "    \n",
      "    is_complex(...)\n",
      "        is_complex(input) -> (bool)\n",
      "        \n",
      "        Returns True if the data type of :attr:`input` is a complex data type i.e.,\n",
      "        one of ``torch.complex64``, and ``torch.complex128``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "    \n",
      "    is_deterministic()\n",
      "        This function is deprecated and will be removed in a future release.\n",
      "        Please use :func:`torch.are_deterministic_algorithms_enabled` instead.\n",
      "    \n",
      "    is_distributed(...)\n",
      "    \n",
      "    is_floating_point(...)\n",
      "        is_floating_point(input) -> (bool)\n",
      "        \n",
      "        Returns True if the data type of :attr:`input` is a floating point data type i.e.,\n",
      "        one of ``torch.float64``, ``torch.float32``, ``torch.float16``, and ``torch.bfloat16``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "    \n",
      "    is_grad_enabled(...)\n",
      "    \n",
      "    is_nonzero(...)\n",
      "        is_nonzero(input) -> (bool)\n",
      "        \n",
      "        Returns True if the :attr:`input` is a single element tensor which is not equal to zero\n",
      "        after type conversions.\n",
      "        i.e. not equal to ``torch.tensor([0.])`` or ``torch.tensor([0])`` or\n",
      "        ``torch.tensor([False])``.\n",
      "        Throws a ``RuntimeError`` if ``torch.numel() != 1`` (even in case\n",
      "        of sparse tensors).\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> torch.is_nonzero(torch.tensor([0.]))\n",
      "            False\n",
      "            >>> torch.is_nonzero(torch.tensor([1.5]))\n",
      "            True\n",
      "            >>> torch.is_nonzero(torch.tensor([False]))\n",
      "            False\n",
      "            >>> torch.is_nonzero(torch.tensor([3]))\n",
      "            True\n",
      "            >>> torch.is_nonzero(torch.tensor([1, 3, 5]))\n",
      "            Traceback (most recent call last):\n",
      "            ...\n",
      "            RuntimeError: bool value of Tensor with more than one value is ambiguous\n",
      "            >>> torch.is_nonzero(torch.tensor([]))\n",
      "            Traceback (most recent call last):\n",
      "            ...\n",
      "            RuntimeError: bool value of Tensor with no values is ambiguous\n",
      "    \n",
      "    is_same_size(...)\n",
      "    \n",
      "    is_signed(...)\n",
      "    \n",
      "    is_storage(obj)\n",
      "        Returns True if `obj` is a PyTorch storage object.\n",
      "        \n",
      "        Args:\n",
      "            obj (Object): Object to test\n",
      "    \n",
      "    is_tensor(obj)\n",
      "        Returns True if `obj` is a PyTorch tensor.\n",
      "        \n",
      "        Note that this function is simply doing ``isinstance(obj, Tensor)``.\n",
      "        Using that ``isinstance`` check is better for typechecking with mypy,\n",
      "        and more explicit - so it's recommended to use that instead of\n",
      "        ``is_tensor``.\n",
      "        \n",
      "        Args:\n",
      "            obj (Object): Object to test\n",
      "    \n",
      "    is_vulkan_available(...)\n",
      "    \n",
      "    isclose(...)\n",
      "        isclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with boolean elements representing if each element of\n",
      "        :attr:`input` is \"close\" to the corresponding element of :attr:`other`.\n",
      "        Closeness is defined as:\n",
      "        \n",
      "        .. math::\n",
      "            \\lvert \\text{input} - \\text{other} \\rvert \\leq \\texttt{atol} + \\texttt{rtol} \\times \\lvert \\text{other} \\rvert\n",
      "        \n",
      "        \n",
      "        where :attr:`input` and :attr:`other` are finite. Where :attr:`input`\n",
      "        and/or :attr:`other` are nonfinite they are close if and only if\n",
      "        they are equal, with NaNs being considered equal to each other when\n",
      "        :attr:`equal_nan` is True.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): first tensor to compare\n",
      "            other (Tensor): second tensor to compare\n",
      "            atol (float, optional): absolute tolerance. Default: 1e-08\n",
      "            rtol (float, optional): relative tolerance. Default: 1e-05\n",
      "            equal_nan (bool, optional): if ``True``, then two ``NaN`` s will be considered equal. Default: ``False``\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> torch.isclose(torch.tensor((1., 2, 3)), torch.tensor((1 + 1e-10, 3, 4)))\n",
      "            tensor([ True, False, False])\n",
      "            >>> torch.isclose(torch.tensor((float('inf'), 4)), torch.tensor((float('inf'), 6)), rtol=.5)\n",
      "            tensor([True, True])\n",
      "    \n",
      "    isfinite(...)\n",
      "        isfinite(input) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with boolean elements representing if each element is `finite` or not.\n",
      "        \n",
      "        Real values are finite when they are not NaN, negative infinity, or infinity.\n",
      "        Complex values are finite when both their real and imaginary parts are finite.\n",
      "        \n",
      "            Args:\n",
      "                input (Tensor): the input tensor.\n",
      "        \n",
      "            Returns:\n",
      "                A boolean tensor that is True where :attr:`input` is finite and False elsewhere\n",
      "        \n",
      "            Example::\n",
      "        \n",
      "                >>> torch.isfinite(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')]))\n",
      "                tensor([True,  False,  True,  False,  False])\n",
      "    \n",
      "    isinf(...)\n",
      "        isinf(input) -> Tensor\n",
      "        \n",
      "        Tests if each element of :attr:`input` is infinite\n",
      "        (positive or negative infinity) or not.\n",
      "        \n",
      "        .. note::\n",
      "            Complex values are infinite when their real or imaginary part is\n",
      "            infinite.\n",
      "        \n",
      "            Args:\n",
      "                {input}\n",
      "        \n",
      "            Returns:\n",
      "                A boolean tensor that is True where :attr:`input` is infinite and False elsewhere\n",
      "        \n",
      "            Example::\n",
      "        \n",
      "                >>> torch.isinf(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')]))\n",
      "                tensor([False,  True,  False,  True,  False])\n",
      "    \n",
      "    isnan(...)\n",
      "        isnan(input) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with boolean elements representing if each element of :attr:`input`\n",
      "        is NaN or not. Complex values are considered NaN when either their real\n",
      "        and/or imaginary part is NaN.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Returns:\n",
      "            A boolean tensor that is True where :attr:`input` is NaN and False elsewhere\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.isnan(torch.tensor([1, float('nan'), 2]))\n",
      "            tensor([False, True, False])\n",
      "    \n",
      "    isneginf(...)\n",
      "        isneginf(input, *, out=None) -> Tensor\n",
      "        Tests if each element of :attr:`input` is negative infinity or not.\n",
      "        \n",
      "        Args:\n",
      "          input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "          out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> a = torch.tensor([-float('inf'), float('inf'), 1.2])\n",
      "            >>> torch.isneginf(a)\n",
      "            tensor([ True, False, False])\n",
      "    \n",
      "    isposinf(...)\n",
      "        isposinf(input, *, out=None) -> Tensor\n",
      "        Tests if each element of :attr:`input` is positive infinity or not.\n",
      "        \n",
      "        Args:\n",
      "          input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "          out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> a = torch.tensor([-float('inf'), float('inf'), 1.2])\n",
      "            >>> torch.isposinf(a)\n",
      "            tensor([False,  True, False])\n",
      "    \n",
      "    isreal(...)\n",
      "        isreal(input) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with boolean elements representing if each element of :attr:`input` is real-valued or not.\n",
      "        All real-valued types are considered real. Complex values are considered real when their imaginary part is 0.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Returns:\n",
      "            A boolean tensor that is True where :attr:`input` is real and False elsewhere\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.isreal(torch.tensor([1, 1+1j, 2+0j]))\n",
      "            tensor([True, False, True])\n",
      "    \n",
      "    istft(input: torch.Tensor, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: Union[torch.Tensor, NoneType] = None, center: bool = True, normalized: bool = False, onesided: Union[bool, NoneType] = None, length: Union[int, NoneType] = None, return_complex: bool = False) -> torch.Tensor\n",
      "        Inverse short time Fourier Transform. This is expected to be the inverse of :func:`~torch.stft`.\n",
      "        It has the same parameters (+ additional optional parameter of :attr:`length`) and it should return the\n",
      "        least squares estimation of the original signal. The algorithm will check using the NOLA condition (\n",
      "        nonzero overlap).\n",
      "        \n",
      "        Important consideration in the parameters :attr:`window` and :attr:`center` so that the envelop\n",
      "        created by the summation of all the windows is never zero at certain point in time. Specifically,\n",
      "        :math:`\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0`.\n",
      "        \n",
      "        Since :func:`~torch.stft` discards elements at the end of the signal if they do not fit in a frame,\n",
      "        ``istft`` may return a shorter signal than the original signal (can occur if :attr:`center` is False\n",
      "        since the signal isn't padded).\n",
      "        \n",
      "        If :attr:`center` is ``True``, then there will be padding e.g. ``'constant'``, ``'reflect'``, etc.\n",
      "        Left padding can be trimmed off exactly because they can be calculated but right padding cannot be\n",
      "        calculated without additional information.\n",
      "        \n",
      "        Example: Suppose the last window is:\n",
      "        ``[17, 18, 0, 0, 0]`` vs ``[18, 0, 0, 0, 0]``\n",
      "        \n",
      "        The :attr:`n_fft`, :attr:`hop_length`, :attr:`win_length` are all the same which prevents the calculation\n",
      "        of right padding. These additional values could be zeros or a reflection of the signal so providing\n",
      "        :attr:`length` could be useful. If :attr:`length` is ``None`` then padding will be aggressively removed\n",
      "        (some loss of signal).\n",
      "        \n",
      "        [1] D. W. Griffin and J. S. Lim, \"Signal estimation from modified short-time Fourier transform,\"\n",
      "        IEEE Trans. ASSP, vol.32, no.2, pp.236-243, Apr. 1984.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): The input tensor. Expected to be output of :func:`~torch.stft`,\n",
      "                can either be complex (``channel``, ``fft_size``, ``n_frame``), or real\n",
      "                (``channel``, ``fft_size``, ``n_frame``, 2) where the ``channel``\n",
      "                dimension is optional.\n",
      "        \n",
      "                .. deprecated:: 1.8.0\n",
      "                   Real input is deprecated, use complex inputs as returned by\n",
      "                   ``stft(..., return_complex=True)`` instead.\n",
      "            n_fft (int): Size of Fourier transform\n",
      "            hop_length (Optional[int]): The distance between neighboring sliding window frames.\n",
      "                (Default: ``n_fft // 4``)\n",
      "            win_length (Optional[int]): The size of window frame and STFT filter. (Default: ``n_fft``)\n",
      "            window (Optional[torch.Tensor]): The optional window function.\n",
      "                (Default: ``torch.ones(win_length)``)\n",
      "            center (bool): Whether :attr:`input` was padded on both sides so that the :math:`t`-th frame is\n",
      "                centered at time :math:`t \\times \\text{hop\\_length}`.\n",
      "                (Default: ``True``)\n",
      "            normalized (bool): Whether the STFT was normalized. (Default: ``False``)\n",
      "            onesided (Optional[bool]): Whether the STFT was onesided.\n",
      "                (Default: ``True`` if ``n_fft != fft_size`` in the input size)\n",
      "            length (Optional[int]): The amount to trim the signal by (i.e. the\n",
      "                original signal length). (Default: whole signal)\n",
      "            return_complex (Optional[bool]):\n",
      "                Whether the output should be complex, or if the input should be\n",
      "                assumed to derive from a real signal and window.\n",
      "                Note that this is incompatible with ``onesided=True``.\n",
      "                (Default: ``False``)\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: Least squares estimation of the original signal of size (..., signal_length)\n",
      "    \n",
      "    kaiser_window(...)\n",
      "        kaiser_window(window_length, periodic=True, beta=12.0, *, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Computes the Kaiser window with window length :attr:`window_length` and shape parameter :attr:`beta`.\n",
      "        \n",
      "        Let I_0 be the zeroth order modified Bessel function of the first kind (see :func:`torch.i0`) and\n",
      "        ``N = L - 1`` if :attr:`periodic` is False and ``L`` if :attr:`periodic` is True,\n",
      "        where ``L`` is the :attr:`window_length`. This function computes:\n",
      "        \n",
      "        .. math::\n",
      "            out_i = I_0 \\left( \\beta \\sqrt{1 - \\left( {\\frac{i - N/2}{N/2}} \\right) ^2 } \\right) / I_0( \\beta )\n",
      "        \n",
      "        Calling ``torch.kaiser_window(L, B, periodic=True)`` is equivalent to calling\n",
      "        ``torch.kaiser_window(L + 1, B, periodic=False)[:-1])``.\n",
      "        The :attr:`periodic` argument is intended as a helpful shorthand\n",
      "        to produce a periodic window as input to functions like :func:`torch.stft`.\n",
      "        \n",
      "        .. note::\n",
      "            If :attr:`window_length` is one, then the returned window is a single element tensor containing a one.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            window_length (int): length of the window.\n",
      "            periodic (bool, optional): If True, returns a periodic window suitable for use in spectral analysis.\n",
      "                If False, returns a symmetric window suitable for use in filter design.\n",
      "            beta (float, optional): shape parameter for the window.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned window tensor. Only\n",
      "                  ``torch.strided`` (dense layout) is supported.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "    \n",
      "    kl_div(...)\n",
      "    \n",
      "    kron(...)\n",
      "        kron(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the Kronecker product, denoted by :math:`\\otimes`, of :attr:`input` and :attr:`other`.\n",
      "        \n",
      "        If :attr:`input` is a :math:`(a_0 \\times a_1 \\times \\dots \\times a_n)` tensor and :attr:`other` is a\n",
      "        :math:`(b_0 \\times b_1 \\times \\dots \\times b_n)` tensor, the result will be a\n",
      "        :math:`(a_0*b_0 \\times a_1*b_1 \\times \\dots \\times a_n*b_n)` tensor with the following entries:\n",
      "        \n",
      "        .. math::\n",
      "            (\\text{input} \\otimes \\text{other})_{k_0, k_1, \\dots, k_n} =\n",
      "                \\text{input}_{i_0, i_1, \\dots, i_n} * \\text{other}_{j_0, j_1, \\dots, j_n},\n",
      "        \n",
      "        where :math:`k_t = i_t * b_t + j_t` for :math:`0 \\leq t \\leq n`.\n",
      "        If one tensor has fewer dimensions than the other it is unsqueezed until it has the same number of dimensions.\n",
      "        \n",
      "        Supports real-valued and complex-valued inputs.\n",
      "        \n",
      "        .. note::\n",
      "            This function generalizes the typical definition of the Kronecker product for two matrices to two tensors,\n",
      "            as described above. When :attr:`input` is a :math:`(m \\times n)` matrix and :attr:`other` is a\n",
      "            :math:`(p \\times q)` matrix, the result will be a :math:`(p*m \\times q*n)` block matrix:\n",
      "        \n",
      "            .. math::\n",
      "                \\mathbf{A} \\otimes \\mathbf{B}=\\begin{bmatrix}\n",
      "                a_{11} \\mathbf{B} & \\cdots & a_{1 n} \\mathbf{B} \\\\\n",
      "                \\vdots & \\ddots & \\vdots \\\\\n",
      "                a_{m 1} \\mathbf{B} & \\cdots & a_{m n} \\mathbf{B} \\end{bmatrix}\n",
      "        \n",
      "            where :attr:`input` is :math:`\\mathbf{A}` and :attr:`other` is :math:`\\mathbf{B}`.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor)\n",
      "            other (Tensor)\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): The output tensor. Ignored if ``None``. Default: ``None``\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> mat1 = torch.eye(2)\n",
      "            >>> mat2 = torch.ones(2, 2)\n",
      "            >>> torch.kron(mat1, mat2)\n",
      "            tensor([[1., 1., 0., 0.],\n",
      "                    [1., 1., 0., 0.],\n",
      "                    [0., 0., 1., 1.],\n",
      "                    [0., 0., 1., 1.]])\n",
      "        \n",
      "            >>> mat1 = torch.eye(2)\n",
      "            >>> mat2 = torch.arange(1, 5).reshape(2, 2)\n",
      "            >>> torch.kron(mat1, mat2)\n",
      "            tensor([[1., 2., 0., 0.],\n",
      "                    [3., 4., 0., 0.],\n",
      "                    [0., 0., 1., 2.],\n",
      "                    [0., 0., 3., 4.]])\n",
      "    \n",
      "    kthvalue(...)\n",
      "        kthvalue(input, k, dim=None, keepdim=False, *, out=None) -> (Tensor, LongTensor)\n",
      "        \n",
      "        Returns a namedtuple ``(values, indices)`` where ``values`` is the :attr:`k` th\n",
      "        smallest element of each row of the :attr:`input` tensor in the given dimension\n",
      "        :attr:`dim`. And ``indices`` is the index location of each element found.\n",
      "        \n",
      "        If :attr:`dim` is not given, the last dimension of the `input` is chosen.\n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, both the :attr:`values` and :attr:`indices` tensors\n",
      "        are the same size as :attr:`input`, except in the dimension :attr:`dim` where\n",
      "        they are of size 1. Otherwise, :attr:`dim` is squeezed\n",
      "        (see :func:`torch.squeeze`), resulting in both the :attr:`values` and\n",
      "        :attr:`indices` tensors having 1 fewer dimension than the :attr:`input` tensor.\n",
      "        \n",
      "        .. note::\n",
      "            When :attr:`input` is a CUDA tensor and there are multiple valid\n",
      "            :attr:`k` th values, this function may nondeterministically return\n",
      "            :attr:`indices` for any of them.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            k (int): k for the k-th smallest element\n",
      "            dim (int, optional): the dimension to find the kth value along\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the output tuple of (Tensor, LongTensor)\n",
      "                                   can be optionally given to be used as output buffers\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.arange(1., 6.)\n",
      "            >>> x\n",
      "            tensor([ 1.,  2.,  3.,  4.,  5.])\n",
      "            >>> torch.kthvalue(x, 4)\n",
      "            torch.return_types.kthvalue(values=tensor(4.), indices=tensor(3))\n",
      "        \n",
      "            >>> x=torch.arange(1.,7.).resize_(2,3)\n",
      "            >>> x\n",
      "            tensor([[ 1.,  2.,  3.],\n",
      "                    [ 4.,  5.,  6.]])\n",
      "            >>> torch.kthvalue(x, 2, 0, True)\n",
      "            torch.return_types.kthvalue(values=tensor([[4., 5., 6.]]), indices=tensor([[1, 1, 1]]))\n",
      "    \n",
      "    layer_norm(...)\n",
      "    \n",
      "    lcm(...)\n",
      "        lcm(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise least common multiple (LCM) of :attr:`input` and :attr:`other`.\n",
      "        \n",
      "        Both :attr:`input` and :attr:`other` must have integer types.\n",
      "        \n",
      "        .. note::\n",
      "            This defines :math:`lcm(0, 0) = 0` and :math:`lcm(0, a) = 0`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([5, 10, 15])\n",
      "            >>> b = torch.tensor([3, 4, 5])\n",
      "            >>> torch.lcm(a, b)\n",
      "            tensor([15, 20, 15])\n",
      "            >>> c = torch.tensor([3])\n",
      "            >>> torch.lcm(a, c)\n",
      "            tensor([15, 30, 15])\n",
      "    \n",
      "    lcm_(...)\n",
      "    \n",
      "    ldexp(...)\n",
      "        ldexp(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Multiplies :attr:`input` by 2**:attr:`other`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{{out}}_i = \\text{{input}}_i * 2^\\text{{other}}_i\n",
      "        \n",
      "        \n",
      "        Typically this function is used to construct floating point numbers by multiplying\n",
      "        mantissas in :attr:`input` with integral powers of two created from the exponents\n",
      "        in :attr:'other'.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): a tensor of exponents, typically integers.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> torch.ldexp(torch.tensor([1.]), torch.tensor([1]))\n",
      "            tensor([2.])\n",
      "            >>> torch.ldexp(torch.tensor([1.0]), torch.tensor([1, 2, 3, 4]))\n",
      "            tensor([ 2.,  4.,  8., 16.])\n",
      "    \n",
      "    ldexp_(...)\n",
      "    \n",
      "    le(...)\n",
      "        le(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes :math:`\\text{input} \\leq \\text{other}` element-wise.\n",
      "        \n",
      "        \n",
      "        The second argument can be a number or a tensor whose shape is\n",
      "        :ref:`broadcastable <broadcasting-semantics>` with the first argument.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to compare\n",
      "            other (Tensor or Scalar): the tensor or value to compare\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Returns:\n",
      "            A boolean tensor that is True where :attr:`input` is less than or equal to\n",
      "            :attr:`other` and False elsewhere\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.le(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\n",
      "            tensor([[True, False], [True, True]])\n",
      "    \n",
      "    lerp(...)\n",
      "        lerp(input, end, weight, *, out=None)\n",
      "        \n",
      "        Does a linear interpolation of two tensors :attr:`start` (given by :attr:`input`) and :attr:`end` based\n",
      "        on a scalar or tensor :attr:`weight` and returns the resulting :attr:`out` tensor.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = \\text{start}_i + \\text{weight}_i \\times (\\text{end}_i - \\text{start}_i)\n",
      "        \n",
      "        The shapes of :attr:`start` and :attr:`end` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>`. If :attr:`weight` is a tensor, then\n",
      "        the shapes of :attr:`weight`, :attr:`start`, and :attr:`end` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor with the starting points\n",
      "            end (Tensor): the tensor with the ending points\n",
      "            weight (float or tensor): the weight for the interpolation formula\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> start = torch.arange(1., 5.)\n",
      "            >>> end = torch.empty(4).fill_(10)\n",
      "            >>> start\n",
      "            tensor([ 1.,  2.,  3.,  4.])\n",
      "            >>> end\n",
      "            tensor([ 10.,  10.,  10.,  10.])\n",
      "            >>> torch.lerp(start, end, 0.5)\n",
      "            tensor([ 5.5000,  6.0000,  6.5000,  7.0000])\n",
      "            >>> torch.lerp(start, end, torch.full_like(start, 0.5))\n",
      "            tensor([ 5.5000,  6.0000,  6.5000,  7.0000])\n",
      "    \n",
      "    less(...)\n",
      "        less(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.lt`.\n",
      "    \n",
      "    less_equal(...)\n",
      "        less_equal(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.le`.\n",
      "    \n",
      "    lgamma(...)\n",
      "        lgamma(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the logarithm of the gamma function on :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\log \\Gamma(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.arange(0.5, 2, 0.5)\n",
      "            >>> torch.lgamma(a)\n",
      "            tensor([ 0.5724,  0.0000, -0.1208])\n",
      "    \n",
      "    linspace(...)\n",
      "        linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Creates a one-dimensional tensor of size :attr:`steps` whose values are evenly\n",
      "        spaced from :attr:`start` to :attr:`end`, inclusive. That is, the value are:\n",
      "        \n",
      "        .. math::\n",
      "            (\\text{start},\n",
      "            \\text{start} + \\frac{\\text{end} - \\text{start}}{\\text{steps} - 1},\n",
      "            \\ldots,\n",
      "            \\text{start} + (\\text{steps} - 2) * \\frac{\\text{end} - \\text{start}}{\\text{steps} - 1},\n",
      "            \\text{end})\n",
      "        \n",
      "        \n",
      "        .. warning::\n",
      "            Not providing a value for :attr:`steps` is deprecated. For backwards\n",
      "            compatibility, not providing a value for :attr:`steps` will create a tensor\n",
      "            with 100 elements. Note that this behavior is not reflected in the\n",
      "            documented function signature and should not be relied on. In a future\n",
      "            PyTorch release, failing to provide a value for :attr:`steps` will throw a\n",
      "            runtime error.\n",
      "        \n",
      "        Args:\n",
      "            start (float): the starting value for the set of points\n",
      "            end (float): the ending value for the set of points\n",
      "            steps (int): size of the constructed tensor\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.linspace(3, 10, steps=5)\n",
      "            tensor([  3.0000,   4.7500,   6.5000,   8.2500,  10.0000])\n",
      "            >>> torch.linspace(-10, 10, steps=5)\n",
      "            tensor([-10.,  -5.,   0.,   5.,  10.])\n",
      "            >>> torch.linspace(start=-10, end=10, steps=5)\n",
      "            tensor([-10.,  -5.,   0.,   5.,  10.])\n",
      "            >>> torch.linspace(start=-10, end=10, steps=1)\n",
      "            tensor([-10.])\n",
      "    \n",
      "    load(f, map_location=None, pickle_module=<module 'pickle' from 'd:\\\\anaconda\\\\envs\\\\pytorch\\\\lib\\\\pickle.py'>, **pickle_load_args)\n",
      "        Loads an object saved with :func:`torch.save` from a file.\n",
      "        \n",
      "        :func:`torch.load` uses Python's unpickling facilities but treats storages,\n",
      "        which underlie tensors, specially. They are first deserialized on the\n",
      "        CPU and are then moved to the device they were saved from. If this fails\n",
      "        (e.g. because the run time system doesn't have certain devices), an exception\n",
      "        is raised. However, storages can be dynamically remapped to an alternative\n",
      "        set of devices using the :attr:`map_location` argument.\n",
      "        \n",
      "        If :attr:`map_location` is a callable, it will be called once for each serialized\n",
      "        storage with two arguments: storage and location. The storage argument\n",
      "        will be the initial deserialization of the storage, residing on the CPU.\n",
      "        Each serialized storage has a location tag associated with it which\n",
      "        identifies the device it was saved from, and this tag is the second\n",
      "        argument passed to :attr:`map_location`. The builtin location tags are ``'cpu'``\n",
      "        for CPU tensors and ``'cuda:device_id'`` (e.g. ``'cuda:2'``) for CUDA tensors.\n",
      "        :attr:`map_location` should return either ``None`` or a storage. If\n",
      "        :attr:`map_location` returns a storage, it will be used as the final deserialized\n",
      "        object, already moved to the right device. Otherwise, :func:`torch.load` will\n",
      "        fall back to the default behavior, as if :attr:`map_location` wasn't specified.\n",
      "        \n",
      "        If :attr:`map_location` is a :class:`torch.device` object or a string containing\n",
      "        a device tag, it indicates the location where all tensors should be loaded.\n",
      "        \n",
      "        Otherwise, if :attr:`map_location` is a dict, it will be used to remap location tags\n",
      "        appearing in the file (keys), to ones that specify where to put the\n",
      "        storages (values).\n",
      "        \n",
      "        User extensions can register their own location tags and tagging and\n",
      "        deserialization methods using :func:`torch.serialization.register_package`.\n",
      "        \n",
      "        Args:\n",
      "            f: a file-like object (has to implement :meth:`read`, :meth:`readline`, :meth:`tell`, and :meth:`seek`),\n",
      "                or a string or os.PathLike object containing a file name\n",
      "            map_location: a function, :class:`torch.device`, string or a dict specifying how to remap storage\n",
      "                locations\n",
      "            pickle_module: module used for unpickling metadata and objects (has to\n",
      "                match the :attr:`pickle_module` used to serialize file)\n",
      "            pickle_load_args: (Python 3 only) optional keyword arguments passed over to\n",
      "                :func:`pickle_module.load` and :func:`pickle_module.Unpickler`, e.g.,\n",
      "                :attr:`errors=...`.\n",
      "        \n",
      "        .. warning::\n",
      "            :func:`torch.load()` uses ``pickle`` module implicitly, which is known to be insecure.\n",
      "            It is possible to construct malicious pickle data which will execute arbitrary code\n",
      "            during unpickling. Never load data that could have come from an untrusted\n",
      "            source, or that could have been tampered with. **Only load data you trust**.\n",
      "        \n",
      "        .. note::\n",
      "            When you call :func:`torch.load()` on a file which contains GPU tensors, those tensors\n",
      "            will be loaded to GPU by default. You can call ``torch.load(.., map_location='cpu')``\n",
      "            and then :meth:`load_state_dict` to avoid GPU RAM surge when loading a model checkpoint.\n",
      "        \n",
      "        .. note::\n",
      "            By default, we decode byte strings as ``utf-8``.  This is to avoid a common error\n",
      "            case ``UnicodeDecodeError: 'ascii' codec can't decode byte 0x...``\n",
      "            when loading files saved by Python 2 in Python 3.  If this default\n",
      "            is incorrect, you may use an extra :attr:`encoding` keyword argument to specify how\n",
      "            these objects should be loaded, e.g., :attr:`encoding='latin1'` decodes them\n",
      "            to strings using ``latin1`` encoding, and :attr:`encoding='bytes'` keeps them\n",
      "            as byte arrays which can be decoded later with ``byte_array.decode(...)``.\n",
      "        \n",
      "        Example:\n",
      "            >>> torch.load('tensors.pt')\n",
      "            # Load all tensors onto the CPU\n",
      "            >>> torch.load('tensors.pt', map_location=torch.device('cpu'))\n",
      "            # Load all tensors onto the CPU, using a function\n",
      "            >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage)\n",
      "            # Load all tensors onto GPU 1\n",
      "            >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1))\n",
      "            # Map tensors from GPU 1 to GPU 0\n",
      "            >>> torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'})\n",
      "            # Load tensor from io.BytesIO object\n",
      "            >>> with open('tensor.pt', 'rb') as f:\n",
      "            ...     buffer = io.BytesIO(f.read())\n",
      "            >>> torch.load(buffer)\n",
      "            # Load a module with 'ascii' encoding for unpickling\n",
      "            >>> torch.load('module.pt', encoding='ascii')\n",
      "    \n",
      "    lobpcg(A: torch.Tensor, k: Union[int, NoneType] = None, B: Union[torch.Tensor, NoneType] = None, X: Union[torch.Tensor, NoneType] = None, n: Union[int, NoneType] = None, iK: Union[torch.Tensor, NoneType] = None, niter: Union[int, NoneType] = None, tol: Union[float, NoneType] = None, largest: Union[bool, NoneType] = None, method: Union[str, NoneType] = None, tracker: NoneType = None, ortho_iparams: Union[Dict[str, int], NoneType] = None, ortho_fparams: Union[Dict[str, float], NoneType] = None, ortho_bparams: Union[Dict[str, bool], NoneType] = None) -> Tuple[torch.Tensor, torch.Tensor]\n",
      "        Find the k largest (or smallest) eigenvalues and the corresponding\n",
      "        eigenvectors of a symmetric positive defined generalized\n",
      "        eigenvalue problem using matrix-free LOBPCG methods.\n",
      "        \n",
      "        This function is a front-end to the following LOBPCG algorithms\n",
      "        selectable via `method` argument:\n",
      "        \n",
      "          `method=\"basic\"` - the LOBPCG method introduced by Andrew\n",
      "          Knyazev, see [Knyazev2001]. A less robust method, may fail when\n",
      "          Cholesky is applied to singular input.\n",
      "        \n",
      "          `method=\"ortho\"` - the LOBPCG method with orthogonal basis\n",
      "          selection [StathopoulosEtal2002]. A robust method.\n",
      "        \n",
      "        Supported inputs are dense, sparse, and batches of dense matrices.\n",
      "        \n",
      "        .. note:: In general, the basic method spends least time per\n",
      "          iteration. However, the robust methods converge much faster and\n",
      "          are more stable. So, the usage of the basic method is generally\n",
      "          not recommended but there exist cases where the usage of the\n",
      "          basic method may be preferred.\n",
      "        \n",
      "        .. warning:: The backward method does not support sparse and complex inputs.\n",
      "          It works only when `B` is not provided (i.e. `B == None`).\n",
      "          We are actively working on extensions, and the details of\n",
      "          the algorithms are going to be published promptly.\n",
      "        \n",
      "        .. warning:: While it is assumed that `A` is symmetric, `A.grad` is not.\n",
      "          To make sure that `A.grad` is symmetric, so that `A - t * A.grad` is symmetric\n",
      "          in first-order optimization routines, prior to running `lobpcg`\n",
      "          we do the following symmetrization map: `A -> (A + A.t()) / 2`.\n",
      "          The map is performed only when the `A` requires gradients.\n",
      "        \n",
      "        Args:\n",
      "        \n",
      "          A (Tensor): the input tensor of size :math:`(*, m, m)`\n",
      "        \n",
      "          B (Tensor, optional): the input tensor of size :math:`(*, m,\n",
      "                      m)`. When not specified, `B` is interpereted as\n",
      "                      identity matrix.\n",
      "        \n",
      "          X (tensor, optional): the input tensor of size :math:`(*, m, n)`\n",
      "                      where `k <= n <= m`. When specified, it is used as\n",
      "                      initial approximation of eigenvectors. X must be a\n",
      "                      dense tensor.\n",
      "        \n",
      "          iK (tensor, optional): the input tensor of size :math:`(*, m,\n",
      "                      m)`. When specified, it will be used as preconditioner.\n",
      "        \n",
      "          k (integer, optional): the number of requested\n",
      "                      eigenpairs. Default is the number of :math:`X`\n",
      "                      columns (when specified) or `1`.\n",
      "        \n",
      "          n (integer, optional): if :math:`X` is not specified then `n`\n",
      "                      specifies the size of the generated random\n",
      "                      approximation of eigenvectors. Default value for `n`\n",
      "                      is `k`. If :math:`X` is specified, the value of `n`\n",
      "                      (when specified) must be the number of :math:`X`\n",
      "                      columns.\n",
      "        \n",
      "          tol (float, optional): residual tolerance for stopping\n",
      "                     criterion. Default is `feps ** 0.5` where `feps` is\n",
      "                     smallest non-zero floating-point number of the given\n",
      "                     input tensor `A` data type.\n",
      "        \n",
      "          largest (bool, optional): when True, solve the eigenproblem for\n",
      "                     the largest eigenvalues. Otherwise, solve the\n",
      "                     eigenproblem for smallest eigenvalues. Default is\n",
      "                     `True`.\n",
      "        \n",
      "          method (str, optional): select LOBPCG method. See the\n",
      "                     description of the function above. Default is\n",
      "                     \"ortho\".\n",
      "        \n",
      "          niter (int, optional): maximum number of iterations. When\n",
      "                     reached, the iteration process is hard-stopped and\n",
      "                     the current approximation of eigenpairs is returned.\n",
      "                     For infinite iteration but until convergence criteria\n",
      "                     is met, use `-1`.\n",
      "        \n",
      "          tracker (callable, optional) : a function for tracing the\n",
      "                     iteration process. When specified, it is called at\n",
      "                     each iteration step with LOBPCG instance as an\n",
      "                     argument. The LOBPCG instance holds the full state of\n",
      "                     the iteration process in the following attributes:\n",
      "        \n",
      "                       `iparams`, `fparams`, `bparams` - dictionaries of\n",
      "                       integer, float, and boolean valued input\n",
      "                       parameters, respectively\n",
      "        \n",
      "                       `ivars`, `fvars`, `bvars`, `tvars` - dictionaries\n",
      "                       of integer, float, boolean, and Tensor valued\n",
      "                       iteration variables, respectively.\n",
      "        \n",
      "                       `A`, `B`, `iK` - input Tensor arguments.\n",
      "        \n",
      "                       `E`, `X`, `S`, `R` - iteration Tensor variables.\n",
      "        \n",
      "                     For instance:\n",
      "        \n",
      "                       `ivars[\"istep\"]` - the current iteration step\n",
      "                       `X` - the current approximation of eigenvectors\n",
      "                       `E` - the current approximation of eigenvalues\n",
      "                       `R` - the current residual\n",
      "                       `ivars[\"converged_count\"]` - the current number of converged eigenpairs\n",
      "                       `tvars[\"rerr\"]` - the current state of convergence criteria\n",
      "        \n",
      "                     Note that when `tracker` stores Tensor objects from\n",
      "                     the LOBPCG instance, it must make copies of these.\n",
      "        \n",
      "                     If `tracker` sets `bvars[\"force_stop\"] = True`, the\n",
      "                     iteration process will be hard-stopped.\n",
      "        \n",
      "          ortho_iparams, ortho_fparams, ortho_bparams (dict, optional):\n",
      "                     various parameters to LOBPCG algorithm when using\n",
      "                     `method=\"ortho\"`.\n",
      "        \n",
      "        Returns:\n",
      "        \n",
      "          E (Tensor): tensor of eigenvalues of size :math:`(*, k)`\n",
      "        \n",
      "          X (Tensor): tensor of eigenvectors of size :math:`(*, m, k)`\n",
      "        \n",
      "        References:\n",
      "        \n",
      "          [Knyazev2001] Andrew V. Knyazev. (2001) Toward the Optimal\n",
      "          Preconditioned Eigensolver: Locally Optimal Block Preconditioned\n",
      "          Conjugate Gradient Method. SIAM J. Sci. Comput., 23(2),\n",
      "          517-541. (25 pages)\n",
      "          https://epubs.siam.org/doi/abs/10.1137/S1064827500366124\n",
      "        \n",
      "          [StathopoulosEtal2002] Andreas Stathopoulos and Kesheng\n",
      "          Wu. (2002) A Block Orthogonalization Procedure with Constant\n",
      "          Synchronization Requirements. SIAM J. Sci. Comput., 23(6),\n",
      "          2165-2182. (18 pages)\n",
      "          https://epubs.siam.org/doi/10.1137/S1064827500370883\n",
      "        \n",
      "          [DuerschEtal2018] Jed A. Duersch, Meiyue Shao, Chao Yang, Ming\n",
      "          Gu. (2018) A Robust and Efficient Implementation of LOBPCG.\n",
      "          SIAM J. Sci. Comput., 40(5), C655-C676. (22 pages)\n",
      "          https://epubs.siam.org/doi/abs/10.1137/17M1129830\n",
      "    \n",
      "    log(...)\n",
      "        log(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the natural logarithm of the elements\n",
      "        of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            y_{i} = \\log_{e} (x_{i})\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(5)\n",
      "            >>> a\n",
      "            tensor([-0.7168, -0.5471, -0.8933, -1.4428, -0.1190])\n",
      "            >>> torch.log(a)\n",
      "            tensor([ nan,  nan,  nan,  nan,  nan])\n",
      "    \n",
      "    log10(...)\n",
      "        log10(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the logarithm to the base 10 of the elements\n",
      "        of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            y_{i} = \\log_{10} (x_{i})\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.rand(5)\n",
      "            >>> a\n",
      "            tensor([ 0.5224,  0.9354,  0.7257,  0.1301,  0.2251])\n",
      "        \n",
      "        \n",
      "            >>> torch.log10(a)\n",
      "            tensor([-0.2820, -0.0290, -0.1392, -0.8857, -0.6476])\n",
      "    \n",
      "    log10_(...)\n",
      "    \n",
      "    log1p(...)\n",
      "        log1p(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the natural logarithm of (1 + :attr:`input`).\n",
      "        \n",
      "        .. math::\n",
      "            y_i = \\log_{e} (x_i + 1)\n",
      "        \n",
      "        .. note:: This function is more accurate than :func:`torch.log` for small\n",
      "                  values of :attr:`input`\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(5)\n",
      "            >>> a\n",
      "            tensor([-1.0090, -0.9923,  1.0249, -0.5372,  0.2492])\n",
      "            >>> torch.log1p(a)\n",
      "            tensor([    nan, -4.8653,  0.7055, -0.7705,  0.2225])\n",
      "    \n",
      "    log1p_(...)\n",
      "    \n",
      "    log2(...)\n",
      "        log2(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the logarithm to the base 2 of the elements\n",
      "        of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            y_{i} = \\log_{2} (x_{i})\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.rand(5)\n",
      "            >>> a\n",
      "            tensor([ 0.8419,  0.8003,  0.9971,  0.5287,  0.0490])\n",
      "        \n",
      "        \n",
      "            >>> torch.log2(a)\n",
      "            tensor([-0.2483, -0.3213, -0.0042, -0.9196, -4.3504])\n",
      "    \n",
      "    log2_(...)\n",
      "    \n",
      "    log_(...)\n",
      "    \n",
      "    log_softmax(...)\n",
      "    \n",
      "    logaddexp(...)\n",
      "        logaddexp(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Logarithm of the sum of exponentiations of the inputs.\n",
      "        \n",
      "        Calculates pointwise :math:`\\log\\left(e^x + e^y\\right)`. This function is useful\n",
      "        in statistics where the calculated probabilities of events may be so small as to\n",
      "        exceed the range of normal floating point numbers. In such cases the logarithm\n",
      "        of the calculated probability is stored. This function allows adding\n",
      "        probabilities stored in such a fashion.\n",
      "        \n",
      "        This op should be disambiguated with :func:`torch.logsumexp` which performs a\n",
      "        reduction on a single tensor.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.logaddexp(torch.tensor([-1.0]), torch.tensor([-1.0, -2, -3]))\n",
      "            tensor([-0.3069, -0.6867, -0.8731])\n",
      "            >>> torch.logaddexp(torch.tensor([-100.0, -200, -300]), torch.tensor([-1.0, -2, -3]))\n",
      "            tensor([-1., -2., -3.])\n",
      "            >>> torch.logaddexp(torch.tensor([1.0, 2000, 30000]), torch.tensor([-1.0, -2, -3]))\n",
      "            tensor([1.1269e+00, 2.0000e+03, 3.0000e+04])\n",
      "    \n",
      "    logaddexp2(...)\n",
      "        logaddexp2(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Logarithm of the sum of exponentiations of the inputs in base-2.\n",
      "        \n",
      "        Calculates pointwise :math:`\\log_2\\left(2^x + 2^y\\right)`. See\n",
      "        :func:`torch.logaddexp` for more details.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    logcumsumexp(...)\n",
      "        logcumsumexp(input, dim, *, out=None) -> Tensor\n",
      "        Returns the logarithm of the cumulative summation of the exponentiation of\n",
      "        elements of :attr:`input` in the dimension :attr:`dim`.\n",
      "        \n",
      "        For summation index :math:`j` given by `dim` and other indices :math:`i`, the result is\n",
      "        \n",
      "            .. math::\n",
      "                \\text{logcumsumexp}(x)_{ij} = \\log \\sum\\limits_{j=0}^{i} \\exp(x_{ij})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim  (int): the dimension to do the operation over\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> a = torch.randn(10)\n",
      "            >>> torch.logcumsumexp(a, dim=0)\n",
      "            tensor([-0.42296738, -0.04462666,  0.86278635,  0.94622083,  1.05277811,\n",
      "                     1.39202815,  1.83525007,  1.84492621,  2.06084887,  2.06844475]))\n",
      "    \n",
      "    logdet(...)\n",
      "        logdet(input) -> Tensor\n",
      "        \n",
      "        Calculates log determinant of a square matrix or batches of square matrices.\n",
      "        \n",
      "        .. note::\n",
      "            Result is ``-inf`` if :attr:`input` has zero log determinant, and is ``nan`` if\n",
      "            :attr:`input` has negative determinant.\n",
      "        \n",
      "        .. note::\n",
      "            Backward through :meth:`logdet` internally uses SVD results when :attr:`input`\n",
      "            is not invertible. In this case, double backward through :meth:`logdet` will\n",
      "            be unstable in when :attr:`input` doesn't have distinct singular values. See\n",
      "            :meth:`~torch.svd` for details.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): the input tensor of size ``(*, n, n)`` where ``*`` is zero or more\n",
      "                        batch dimensions.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> A = torch.randn(3, 3)\n",
      "            >>> torch.det(A)\n",
      "            tensor(0.2611)\n",
      "            >>> torch.logdet(A)\n",
      "            tensor(-1.3430)\n",
      "            >>> A\n",
      "            tensor([[[ 0.9254, -0.6213],\n",
      "                     [-0.5787,  1.6843]],\n",
      "        \n",
      "                    [[ 0.3242, -0.9665],\n",
      "                     [ 0.4539, -0.0887]],\n",
      "        \n",
      "                    [[ 1.1336, -0.4025],\n",
      "                     [-0.7089,  0.9032]]])\n",
      "            >>> A.det()\n",
      "            tensor([1.1990, 0.4099, 0.7386])\n",
      "            >>> A.det().log()\n",
      "            tensor([ 0.1815, -0.8917, -0.3031])\n",
      "    \n",
      "    logical_and(...)\n",
      "        logical_and(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise logical AND of the given input tensors. Zeros are treated as ``False`` and nonzeros are\n",
      "        treated as ``True``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the tensor to compute AND with\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.logical_and(torch.tensor([True, False, True]), torch.tensor([True, False, False]))\n",
      "            tensor([ True, False, False])\n",
      "            >>> a = torch.tensor([0, 1, 10, 0], dtype=torch.int8)\n",
      "            >>> b = torch.tensor([4, 0, 1, 0], dtype=torch.int8)\n",
      "            >>> torch.logical_and(a, b)\n",
      "            tensor([False, False,  True, False])\n",
      "            >>> torch.logical_and(a.double(), b.double())\n",
      "            tensor([False, False,  True, False])\n",
      "            >>> torch.logical_and(a.double(), b)\n",
      "            tensor([False, False,  True, False])\n",
      "            >>> torch.logical_and(a, b, out=torch.empty(4, dtype=torch.bool))\n",
      "            tensor([False, False,  True, False])\n",
      "    \n",
      "    logical_not(...)\n",
      "        logical_not(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise logical NOT of the given input tensor. If not specified, the output tensor will have the bool\n",
      "        dtype. If the input tensor is not a bool tensor, zeros are treated as ``False`` and non-zeros are treated as ``True``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.logical_not(torch.tensor([True, False]))\n",
      "            tensor([False,  True])\n",
      "            >>> torch.logical_not(torch.tensor([0, 1, -10], dtype=torch.int8))\n",
      "            tensor([ True, False, False])\n",
      "            >>> torch.logical_not(torch.tensor([0., 1.5, -10.], dtype=torch.double))\n",
      "            tensor([ True, False, False])\n",
      "            >>> torch.logical_not(torch.tensor([0., 1., -10.], dtype=torch.double), out=torch.empty(3, dtype=torch.int16))\n",
      "            tensor([1, 0, 0], dtype=torch.int16)\n",
      "    \n",
      "    logical_or(...)\n",
      "        logical_or(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise logical OR of the given input tensors. Zeros are treated as ``False`` and nonzeros are\n",
      "        treated as ``True``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the tensor to compute OR with\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.logical_or(torch.tensor([True, False, True]), torch.tensor([True, False, False]))\n",
      "            tensor([ True, False,  True])\n",
      "            >>> a = torch.tensor([0, 1, 10, 0], dtype=torch.int8)\n",
      "            >>> b = torch.tensor([4, 0, 1, 0], dtype=torch.int8)\n",
      "            >>> torch.logical_or(a, b)\n",
      "            tensor([ True,  True,  True, False])\n",
      "            >>> torch.logical_or(a.double(), b.double())\n",
      "            tensor([ True,  True,  True, False])\n",
      "            >>> torch.logical_or(a.double(), b)\n",
      "            tensor([ True,  True,  True, False])\n",
      "            >>> torch.logical_or(a, b, out=torch.empty(4, dtype=torch.bool))\n",
      "            tensor([ True,  True,  True, False])\n",
      "    \n",
      "    logical_xor(...)\n",
      "        logical_xor(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise logical XOR of the given input tensors. Zeros are treated as ``False`` and nonzeros are\n",
      "        treated as ``True``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the tensor to compute XOR with\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.logical_xor(torch.tensor([True, False, True]), torch.tensor([True, False, False]))\n",
      "            tensor([False, False,  True])\n",
      "            >>> a = torch.tensor([0, 1, 10, 0], dtype=torch.int8)\n",
      "            >>> b = torch.tensor([4, 0, 1, 0], dtype=torch.int8)\n",
      "            >>> torch.logical_xor(a, b)\n",
      "            tensor([ True,  True, False, False])\n",
      "            >>> torch.logical_xor(a.double(), b.double())\n",
      "            tensor([ True,  True, False, False])\n",
      "            >>> torch.logical_xor(a.double(), b)\n",
      "            tensor([ True,  True, False, False])\n",
      "            >>> torch.logical_xor(a, b, out=torch.empty(4, dtype=torch.bool))\n",
      "            tensor([ True,  True, False, False])\n",
      "    \n",
      "    logit(...)\n",
      "        logit(input, eps=None, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the logit of the elements of :attr:`input`.\n",
      "        :attr:`input` is clamped to [eps, 1 - eps] when eps is not None.\n",
      "        When eps is None and :attr:`input` < 0 or :attr:`input` > 1, the function will yields NaN.\n",
      "        \n",
      "        .. math::\n",
      "            y_{i} = \\ln(\\frac{z_{i}}{1 - z_{i}}) \\\\\n",
      "            z_{i} = \\begin{cases}\n",
      "                x_{i} & \\text{if eps is None} \\\\\n",
      "                \\text{eps} & \\text{if } x_{i} < \\text{eps} \\\\\n",
      "                x_{i} & \\text{if } \\text{eps} \\leq x_{i} \\leq 1 - \\text{eps} \\\\\n",
      "                1 - \\text{eps} & \\text{if } x_{i} > 1 - \\text{eps}\n",
      "            \\end{cases}\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            eps (float, optional): the epsilon for input clamp bound. Default: ``None``\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.rand(5)\n",
      "            >>> a\n",
      "            tensor([0.2796, 0.9331, 0.6486, 0.1523, 0.6516])\n",
      "            >>> torch.logit(a, eps=1e-6)\n",
      "            tensor([-0.9466,  2.6352,  0.6131, -1.7169,  0.6261])\n",
      "    \n",
      "    logit_(...)\n",
      "    \n",
      "    logspace(...)\n",
      "        logspace(start, end, steps, base=10.0, *,          out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        \n",
      "        Creates a one-dimensional tensor of size :attr:`steps` whose values are evenly\n",
      "        spaced from :math:`{{\\text{{base}}}}^{{\\text{{start}}}}` to\n",
      "        :math:`{{\\text{{base}}}}^{{\\text{{end}}}}`, inclusive, on a logarithmic scale\n",
      "        with base :attr:`base`. That is, the values are:\n",
      "        \n",
      "        .. math::\n",
      "            (\\text{base}^{\\text{start}},\n",
      "            \\text{base}^{(\\text{start} + \\frac{\\text{end} - \\text{start}}{ \\text{steps} - 1})},\n",
      "            \\ldots,\n",
      "            \\text{base}^{(\\text{start} + (\\text{steps} - 2) * \\frac{\\text{end} - \\text{start}}{ \\text{steps} - 1})},\n",
      "            \\text{base}^{\\text{end}})\n",
      "        \n",
      "        \n",
      "        .. warning::\n",
      "            Not providing a value for :attr:`steps` is deprecated. For backwards\n",
      "            compatibility, not providing a value for :attr:`steps` will create a tensor\n",
      "            with 100 elements. Note that this behavior is not reflected in the\n",
      "            documented function signature and should not be relied on. In a future\n",
      "            PyTorch release, failing to provide a value for :attr:`steps` will throw a\n",
      "            runtime error.\n",
      "        \n",
      "        Args:\n",
      "            start (float): the starting value for the set of points\n",
      "            end (float): the ending value for the set of points\n",
      "            steps (int): size of the constructed tensor\n",
      "            base (float, optional): base of the logarithm function. Default: ``10.0``.\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.logspace(start=-10, end=10, steps=5)\n",
      "            tensor([ 1.0000e-10,  1.0000e-05,  1.0000e+00,  1.0000e+05,  1.0000e+10])\n",
      "            >>> torch.logspace(start=0.1, end=1.0, steps=5)\n",
      "            tensor([  1.2589,   2.1135,   3.5481,   5.9566,  10.0000])\n",
      "            >>> torch.logspace(start=0.1, end=1.0, steps=1)\n",
      "            tensor([1.2589])\n",
      "            >>> torch.logspace(start=2, end=2, steps=1, base=2)\n",
      "            tensor([4.0])\n",
      "    \n",
      "    logsumexp(...)\n",
      "        logsumexp(input, dim, keepdim=False, *, out=None)\n",
      "        \n",
      "        Returns the log of summed exponentials of each row of the :attr:`input`\n",
      "        tensor in the given dimension :attr:`dim`. The computation is numerically\n",
      "        stabilized.\n",
      "        \n",
      "        For summation index :math:`j` given by `dim` and other indices :math:`i`, the result is\n",
      "        \n",
      "            .. math::\n",
      "                \\text{logsumexp}(x)_{i} = \\log \\sum_j \\exp(x_{ij})\n",
      "        \n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "        as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "        output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        \n",
      "        Example::\n",
      "            >>> a = torch.randn(3, 3)\n",
      "            >>> torch.logsumexp(a, 1)\n",
      "            tensor([ 0.8442,  1.4322,  0.8711])\n",
      "    \n",
      "    lstm(...)\n",
      "    \n",
      "    lstm_cell(...)\n",
      "    \n",
      "    lstsq(...)\n",
      "        lstsq(input, A, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the solution to the least squares and least norm problems for a full\n",
      "        rank matrix :math:`A` of size :math:`(m \\times n)` and a matrix :math:`B` of\n",
      "        size :math:`(m \\times k)`.\n",
      "        \n",
      "        If :math:`m \\geq n`, :func:`lstsq` solves the least-squares problem:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           \\begin{array}{ll}\n",
      "           \\min_X & \\|AX-B\\|_2.\n",
      "           \\end{array}\n",
      "        \n",
      "        If :math:`m < n`, :func:`lstsq` solves the least-norm problem:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           \\begin{array}{llll}\n",
      "           \\min_X & \\|X\\|_2 & \\text{subject to} & AX = B.\n",
      "           \\end{array}\n",
      "        \n",
      "        Returned tensor :math:`X` has shape :math:`(\\max(m, n) \\times k)`. The first :math:`n`\n",
      "        rows of :math:`X` contains the solution. If :math:`m \\geq n`, the residual sum of squares\n",
      "        for the solution in each column is given by the sum of squares of elements in the\n",
      "        remaining :math:`m - n` rows of that column.\n",
      "        \n",
      "        .. note::\n",
      "            The case when :math:`m < n` is not supported on the GPU.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the matrix :math:`B`\n",
      "            A (Tensor): the :math:`m` by :math:`n` matrix :math:`A`\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the optional destination tensor\n",
      "        \n",
      "        Returns:\n",
      "            (Tensor, Tensor): A namedtuple (solution, QR) containing:\n",
      "        \n",
      "                - **solution** (*Tensor*): the least squares solution\n",
      "                - **QR** (*Tensor*): the details of the QR factorization\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            The returned matrices will always be transposed, irrespective of the strides\n",
      "            of the input matrices. That is, they will have stride `(1, m)` instead of\n",
      "            `(m, 1)`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> A = torch.tensor([[1., 1, 1],\n",
      "            ...                   [2, 3, 4],\n",
      "            ...                   [3, 5, 2],\n",
      "            ...                   [4, 2, 5],\n",
      "            ...                   [5, 4, 3]])\n",
      "            >>> B = torch.tensor([[-10., -3],\n",
      "            ...                   [ 12, 14],\n",
      "            ...                   [ 14, 12],\n",
      "            ...                   [ 16, 16],\n",
      "            ...                   [ 18, 16]])\n",
      "            >>> X, _ = torch.lstsq(B, A)\n",
      "            >>> X\n",
      "            tensor([[  2.0000,   1.0000],\n",
      "                    [  1.0000,   1.0000],\n",
      "                    [  1.0000,   2.0000],\n",
      "                    [ 10.9635,   4.8501],\n",
      "                    [  8.9332,   5.2418]])\n",
      "    \n",
      "    lt(...)\n",
      "        lt(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes :math:`\\text{input} < \\text{other}` element-wise.\n",
      "        \n",
      "        \n",
      "        The second argument can be a number or a tensor whose shape is\n",
      "        :ref:`broadcastable <broadcasting-semantics>` with the first argument.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to compare\n",
      "            other (Tensor or float): the tensor or value to compare\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Returns:\n",
      "            A boolean tensor that is True where :attr:`input` is less than :attr:`other` and False elsewhere\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.lt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\n",
      "            tensor([[False, False], [True, False]])\n",
      "    \n",
      "    lu_solve(...)\n",
      "        lu_solve(b, LU_data, LU_pivots, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns the LU solve of the linear system :math:`Ax = b` using the partially pivoted\n",
      "        LU factorization of A from :meth:`torch.lu`.\n",
      "        \n",
      "        This function supports ``float``, ``double``, ``cfloat`` and ``cdouble`` dtypes for :attr:`input`.\n",
      "        \n",
      "        Arguments:\n",
      "            b (Tensor): the RHS tensor of size :math:`(*, m, k)`, where :math:`*`\n",
      "                        is zero or more batch dimensions.\n",
      "            LU_data (Tensor): the pivoted LU factorization of A from :meth:`torch.lu` of size :math:`(*, m, m)`,\n",
      "                               where :math:`*` is zero or more batch dimensions.\n",
      "            LU_pivots (IntTensor): the pivots of the LU factorization from :meth:`torch.lu` of size :math:`(*, m)`,\n",
      "                                   where :math:`*` is zero or more batch dimensions.\n",
      "                                   The batch dimensions of :attr:`LU_pivots` must be equal to the batch dimensions of\n",
      "                                   :attr:`LU_data`.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> A = torch.randn(2, 3, 3)\n",
      "            >>> b = torch.randn(2, 3, 1)\n",
      "            >>> A_LU = torch.lu(A)\n",
      "            >>> x = torch.lu_solve(b, *A_LU)\n",
      "            >>> torch.norm(torch.bmm(A, x) - b)\n",
      "            tensor(1.00000e-07 *\n",
      "                   2.8312)\n",
      "    \n",
      "    manual_seed(seed) -> torch._C.Generator\n",
      "        Sets the seed for generating random numbers. Returns a\n",
      "        `torch.Generator` object.\n",
      "        \n",
      "        Args:\n",
      "            seed (int): The desired seed. Value must be within the inclusive range\n",
      "                `[-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]`. Otherwise, a RuntimeError\n",
      "                is raised. Negative inputs are remapped to positive values with the formula\n",
      "                `0xffff_ffff_ffff_ffff + seed`.\n",
      "    \n",
      "    margin_ranking_loss(...)\n",
      "    \n",
      "    masked_fill(...)\n",
      "    \n",
      "    masked_scatter(...)\n",
      "    \n",
      "    masked_select(...)\n",
      "        masked_select(input, mask, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new 1-D tensor which indexes the :attr:`input` tensor according to\n",
      "        the boolean mask :attr:`mask` which is a `BoolTensor`.\n",
      "        \n",
      "        The shapes of the :attr:`mask` tensor and the :attr:`input` tensor don't need\n",
      "        to match, but they must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        .. note:: The returned tensor does **not** use the same storage\n",
      "                  as the original tensor\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            mask  (BoolTensor): the tensor containing the binary mask to index with\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.randn(3, 4)\n",
      "            >>> x\n",
      "            tensor([[ 0.3552, -2.3825, -0.8297,  0.3477],\n",
      "                    [-1.2035,  1.2252,  0.5002,  0.6248],\n",
      "                    [ 0.1307, -2.0608,  0.1244,  2.0139]])\n",
      "            >>> mask = x.ge(0.5)\n",
      "            >>> mask\n",
      "            tensor([[False, False, False, False],\n",
      "                    [False, True, True, True],\n",
      "                    [False, False, False, True]])\n",
      "            >>> torch.masked_select(x, mask)\n",
      "            tensor([ 1.2252,  0.5002,  0.6248,  2.0139])\n",
      "    \n",
      "    matmul(...)\n",
      "        matmul(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Matrix product of two tensors.\n",
      "        \n",
      "        The behavior depends on the dimensionality of the tensors as follows:\n",
      "        \n",
      "        - If both tensors are 1-dimensional, the dot product (scalar) is returned.\n",
      "        - If both arguments are 2-dimensional, the matrix-matrix product is returned.\n",
      "        - If the first argument is 1-dimensional and the second argument is 2-dimensional,\n",
      "          a 1 is prepended to its dimension for the purpose of the matrix multiply.\n",
      "          After the matrix multiply, the prepended dimension is removed.\n",
      "        - If the first argument is 2-dimensional and the second argument is 1-dimensional,\n",
      "          the matrix-vector product is returned.\n",
      "        - If both arguments are at least 1-dimensional and at least one argument is\n",
      "          N-dimensional (where N > 2), then a batched matrix multiply is returned.  If the first\n",
      "          argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the\n",
      "          batched matrix multiply and removed after.  If the second argument is 1-dimensional, a\n",
      "          1 is appended to its dimension for the purpose of the batched matrix multiple and removed after.\n",
      "          The non-matrix (i.e. batch) dimensions are :ref:`broadcasted <broadcasting-semantics>` (and thus\n",
      "          must be broadcastable).  For example, if :attr:`input` is a\n",
      "          :math:`(j \\times 1 \\times n \\times n)` tensor and :attr:`other` is a :math:`(k \\times n \\times n)`\n",
      "          tensor, :attr:`out` will be a :math:`(j \\times k \\times n \\times n)` tensor.\n",
      "        \n",
      "          Note that the broadcasting logic only looks at the batch dimensions when determining if the inputs\n",
      "          are broadcastable, and not the matrix dimensions. For example, if :attr:`input` is a\n",
      "          :math:`(j \\times 1 \\times n \\times m)` tensor and :attr:`other` is a :math:`(k \\times m \\times p)`\n",
      "          tensor, these inputs are valid for broadcasting even though the final two dimensions (i.e. the\n",
      "          matrix dimensions) are different. :attr:`out` will be a :math:`(j \\times k \\times n \\times p)` tensor.\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            The 1-dimensional dot product version of this function does not support an :attr:`out` parameter.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): the first tensor to be multiplied\n",
      "            other (Tensor): the second tensor to be multiplied\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> # vector x vector\n",
      "            >>> tensor1 = torch.randn(3)\n",
      "            >>> tensor2 = torch.randn(3)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([])\n",
      "            >>> # matrix x vector\n",
      "            >>> tensor1 = torch.randn(3, 4)\n",
      "            >>> tensor2 = torch.randn(4)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([3])\n",
      "            >>> # batched matrix x broadcasted vector\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(4)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3])\n",
      "            >>> # batched matrix x batched matrix\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(10, 4, 5)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3, 5])\n",
      "            >>> # batched matrix x broadcasted matrix\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(4, 5)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3, 5])\n",
      "    \n",
      "    matrix_exp(...)\n",
      "        Returns the matrix exponential. Supports batched input.\n",
      "        For a matrix ``A``, the matrix exponential is defined as\n",
      "        \n",
      "        .. math::\n",
      "            \\mathrm{e}^A = \\sum_{k=0}^\\infty A^k / k!\n",
      "        \n",
      "        \n",
      "        The implementation is based on:\n",
      "        \n",
      "        Bader, P.; Blanes, S.; Casas, F.\n",
      "        Computing the Matrix Exponential with an Optimized Taylor Polynomial Approximation.\n",
      "        Mathematics 2019, 7, 1174.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(2, 2, 2)\n",
      "            >>> a[0, :, :] = torch.eye(2, 2)\n",
      "            >>> a[1, :, :] = 2 * torch.eye(2, 2)\n",
      "            >>> a\n",
      "            tensor([[[1., 0.],\n",
      "                     [0., 1.]],\n",
      "        \n",
      "                    [[2., 0.],\n",
      "                     [0., 2.]]])\n",
      "            >>> torch.matrix_exp(a)\n",
      "            tensor([[[2.7183, 0.0000],\n",
      "                     [0.0000, 2.7183]],\n",
      "        \n",
      "                     [[7.3891, 0.0000],\n",
      "                      [0.0000, 7.3891]]])\n",
      "        \n",
      "            >>> import math\n",
      "            >>> x = torch.tensor([[0, math.pi/3], [-math.pi/3, 0]])\n",
      "            >>> x.matrix_exp() # should be [[cos(pi/3), sin(pi/3)], [-sin(pi/3), cos(pi/3)]]\n",
      "            tensor([[ 0.5000,  0.8660],\n",
      "                    [-0.8660,  0.5000]])\n",
      "    \n",
      "    matrix_power(...)\n",
      "        matrix_power(input, n) -> Tensor\n",
      "        \n",
      "        Returns the matrix raised to the power :attr:`n` for square matrices.\n",
      "        For batch of matrices, each individual matrix is raised to the power :attr:`n`.\n",
      "        \n",
      "        If :attr:`n` is negative, then the inverse of the matrix (if invertible) is\n",
      "        raised to the power :attr:`n`.  For a batch of matrices, the batched inverse\n",
      "        (if invertible) is raised to the power :attr:`n`. If :attr:`n` is 0, then an identity matrix\n",
      "        is returned.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            n (int): the power to raise the matrix to\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(2, 2, 2)\n",
      "            >>> a\n",
      "            tensor([[[-1.9975, -1.9610],\n",
      "                     [ 0.9592, -2.3364]],\n",
      "        \n",
      "                    [[-1.2534, -1.3429],\n",
      "                     [ 0.4153, -1.4664]]])\n",
      "            >>> torch.matrix_power(a, 3)\n",
      "            tensor([[[  3.9392, -23.9916],\n",
      "                     [ 11.7357,  -0.2070]],\n",
      "        \n",
      "                    [[  0.2468,  -6.7168],\n",
      "                     [  2.0774,  -0.8187]]])\n",
      "    \n",
      "    matrix_rank(...)\n",
      "        matrix_rank(input, tol=None, symmetric=False, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns the numerical rank of a 2-D tensor. The method to compute the\n",
      "        matrix rank is done using SVD by default. If :attr:`symmetric` is ``True``,\n",
      "        then :attr:`input` is assumed to be symmetric, and the computation of the\n",
      "        rank is done by obtaining the eigenvalues.\n",
      "        \n",
      "        :attr:`tol` is the threshold below which the singular values (or the eigenvalues\n",
      "        when :attr:`symmetric` is ``True``) are considered to be 0. If :attr:`tol` is not\n",
      "        specified, :attr:`tol` is set to ``S.max() * max(S.size()) * eps`` where `S` is the\n",
      "        singular values (or the eigenvalues when :attr:`symmetric` is ``True``), and ``eps``\n",
      "        is the epsilon value for the datatype of :attr:`input`.\n",
      "        \n",
      "        .. note:: :func:`torch.matrix_rank` is deprecated. Please use :func:`torch.linalg.matrix_rank` instead.\n",
      "                  The parameter :attr:`symmetric` was renamed in :func:`torch.linalg.matrix_rank` to ``hermitian``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input 2-D tensor\n",
      "            tol (float, optional): the tolerance value. Default: ``None``\n",
      "            symmetric(bool, optional): indicates whether :attr:`input` is symmetric.\n",
      "                                       Default: ``False``\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.eye(10)\n",
      "            >>> torch.matrix_rank(a)\n",
      "            tensor(10)\n",
      "            >>> b = torch.eye(10)\n",
      "            >>> b[0, 0] = 0\n",
      "            >>> torch.matrix_rank(b)\n",
      "            tensor(9)\n",
      "    \n",
      "    max(...)\n",
      "        max(input) -> Tensor\n",
      "        \n",
      "        Returns the maximum value of all elements in the ``input`` tensor.\n",
      "        \n",
      "        .. warning::\n",
      "            This function produces deterministic (sub)gradients unlike ``max(dim=0)``\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 3)\n",
      "            >>> a\n",
      "            tensor([[ 0.6763,  0.7445, -2.2369]])\n",
      "            >>> torch.max(a)\n",
      "            tensor(0.7445)\n",
      "        \n",
      "        .. function:: max(input, dim, keepdim=False, *, out=None) -> (Tensor, LongTensor)\n",
      "        \n",
      "        Returns a namedtuple ``(values, indices)`` where ``values`` is the maximum\n",
      "        value of each row of the :attr:`input` tensor in the given dimension\n",
      "        :attr:`dim`. And ``indices`` is the index location of each maximum value found\n",
      "        (argmax).\n",
      "        \n",
      "        If ``keepdim`` is ``True``, the output tensors are of the same size\n",
      "        as ``input`` except in the dimension ``dim`` where they are of size 1.\n",
      "        Otherwise, ``dim`` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "        in the output tensors having 1 fewer dimension than ``input``.\n",
      "        \n",
      "        .. note:: If there are multiple maximal values in a reduced row then\n",
      "                  the indices of the first maximal value are returned.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the dimension to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not. Default: ``False``.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the result tuple of two output tensors (max, max_indices)\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[-1.2360, -0.2942, -0.1222,  0.8475],\n",
      "                    [ 1.1949, -1.1127, -2.2379, -0.6702],\n",
      "                    [ 1.5717, -0.9207,  0.1297, -1.8768],\n",
      "                    [-0.6172,  1.0036, -0.6060, -0.2432]])\n",
      "            >>> torch.max(a, 1)\n",
      "            torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1]))\n",
      "        \n",
      "        .. function:: max(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        See :func:`torch.maximum`.\n",
      "    \n",
      "    max_pool1d(...)\n",
      "    \n",
      "    max_pool1d_with_indices(...)\n",
      "    \n",
      "    max_pool2d(...)\n",
      "    \n",
      "    max_pool3d(...)\n",
      "    \n",
      "    maximum(...)\n",
      "        maximum(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise maximum of :attr:`input` and :attr:`other`.\n",
      "        \n",
      "        .. note::\n",
      "            If one of the elements being compared is a NaN, then that element is returned.\n",
      "            :func:`maximum` is not supported for tensors with complex dtypes.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor((1, 2, -1))\n",
      "            >>> b = torch.tensor((3, 0, 4))\n",
      "            >>> torch.maximum(a, b)\n",
      "            tensor([3, 2, 4])\n",
      "    \n",
      "    mean(...)\n",
      "        mean(input) -> Tensor\n",
      "        \n",
      "        Returns the mean value of all elements in the :attr:`input` tensor.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 3)\n",
      "            >>> a\n",
      "            tensor([[ 0.2294, -0.5481,  1.3288]])\n",
      "            >>> torch.mean(a)\n",
      "            tensor(0.3367)\n",
      "        \n",
      "        .. function:: mean(input, dim, keepdim=False, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns the mean value of each row of the :attr:`input` tensor in the given\n",
      "        dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
      "        reduce over all of them.\n",
      "        \n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "        as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "        output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[-0.3841,  0.6320,  0.4254, -0.7384],\n",
      "                    [-0.9644,  1.0131, -0.6549, -1.4279],\n",
      "                    [-0.2951, -1.3350, -0.7694,  0.5600],\n",
      "                    [ 1.0842, -0.9580,  0.3623,  0.2343]])\n",
      "            >>> torch.mean(a, 1)\n",
      "            tensor([-0.0163, -0.5085, -0.4599,  0.1807])\n",
      "            >>> torch.mean(a, 1, True)\n",
      "            tensor([[-0.0163],\n",
      "                    [-0.5085],\n",
      "                    [-0.4599],\n",
      "                    [ 0.1807]])\n",
      "    \n",
      "    median(...)\n",
      "        median(input) -> Tensor\n",
      "        \n",
      "        Returns the median of the values in :attr:`input`.\n",
      "        \n",
      "        .. note::\n",
      "            The median is not unique for :attr:`input` tensors with an even number\n",
      "            of elements. In this case the lower of the two medians is returned. To\n",
      "            compute the mean of both medians, use :func:`torch.quantile` with ``q=0.5`` instead.\n",
      "        \n",
      "        .. warning::\n",
      "            This function produces deterministic (sub)gradients unlike ``median(dim=0)``\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 3)\n",
      "            >>> a\n",
      "            tensor([[ 1.5219, -1.5212,  0.2202]])\n",
      "            >>> torch.median(a)\n",
      "            tensor(0.2202)\n",
      "        \n",
      "        .. function:: median(input, dim=-1, keepdim=False, *, out=None) -> (Tensor, LongTensor)\n",
      "        \n",
      "        Returns a namedtuple ``(values, indices)`` where ``values`` contains the median of each row of :attr:`input`\n",
      "        in the dimension :attr:`dim`, and ``indices`` contains the index of the median values found in the dimension :attr:`dim`.\n",
      "        \n",
      "        By default, :attr:`dim` is the last dimension of the :attr:`input` tensor.\n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensors are of the same size\n",
      "        as :attr:`input` except in the dimension :attr:`dim` where they are of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
      "        the outputs tensor having 1 fewer dimension than :attr:`input`.\n",
      "        \n",
      "        .. note::\n",
      "            The median is not unique for :attr:`input` tensors with an even number\n",
      "            of elements in the dimension :attr:`dim`. In this case the lower of the\n",
      "            two medians is returned. To compute the mean of both medians in\n",
      "            :attr:`input`, use :func:`torch.quantile` with ``q=0.5`` instead.\n",
      "        \n",
      "        .. warning::\n",
      "            ``indices`` does not necessarily contain the first occurrence of each\n",
      "            median value found, unless it is unique.\n",
      "            The exact implementation details are device-specific.\n",
      "            Do not expect the same result when run on CPU and GPU in general.\n",
      "            For the same reason do not expect the gradients to be deterministic.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the dimension to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            out ((Tensor, Tensor), optional): The first tensor will be populated with the median values and the second\n",
      "                                              tensor, which must have dtype long, with their indices in the dimension\n",
      "                                              :attr:`dim` of :attr:`input`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 5)\n",
      "            >>> a\n",
      "            tensor([[ 0.2505, -0.3982, -0.9948,  0.3518, -1.3131],\n",
      "                    [ 0.3180, -0.6993,  1.0436,  0.0438,  0.2270],\n",
      "                    [-0.2751,  0.7303,  0.2192,  0.3321,  0.2488],\n",
      "                    [ 1.0778, -1.9510,  0.7048,  0.4742, -0.7125]])\n",
      "            >>> torch.median(a, 1)\n",
      "            torch.return_types.median(values=tensor([-0.3982,  0.2270,  0.2488,  0.4742]), indices=tensor([1, 4, 4, 3]))\n",
      "    \n",
      "    merge_type_from_type_comment(...) method of builtins.PyCapsule instance\n",
      "        merge_type_from_type_comment(arg0: torch._C._jit_tree_views.Decl, arg1: torch._C._jit_tree_views.Decl, arg2: bool) -> torch._C._jit_tree_views.Decl\n",
      "    \n",
      "    meshgrid(*tensors)\n",
      "        Take :math:`N` tensors, each of which can be either scalar or 1-dimensional\n",
      "        vector, and create :math:`N` N-dimensional grids, where the :math:`i` :sup:`th` grid is defined by\n",
      "        expanding the :math:`i` :sup:`th` input over dimensions defined by other inputs.\n",
      "        \n",
      "        Args:\n",
      "            tensors (list of Tensor): list of scalars or 1 dimensional tensors. Scalars will be\n",
      "                treated as tensors of size :math:`(1,)` automatically\n",
      "        \n",
      "        Returns:\n",
      "            seq (sequence of Tensors): If the input has :math:`k` tensors of size\n",
      "            :math:`(N_1,), (N_2,), \\ldots , (N_k,)`, then the output would also have :math:`k` tensors,\n",
      "            where all tensors are of size :math:`(N_1, N_2, \\ldots , N_k)`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.tensor([1, 2, 3])\n",
      "            >>> y = torch.tensor([4, 5, 6])\n",
      "            >>> grid_x, grid_y = torch.meshgrid(x, y)\n",
      "            >>> grid_x\n",
      "            tensor([[1, 1, 1],\n",
      "                    [2, 2, 2],\n",
      "                    [3, 3, 3]])\n",
      "            >>> grid_y\n",
      "            tensor([[4, 5, 6],\n",
      "                    [4, 5, 6],\n",
      "                    [4, 5, 6]])\n",
      "    \n",
      "    min(...)\n",
      "        min(input) -> Tensor\n",
      "        \n",
      "        Returns the minimum value of all elements in the :attr:`input` tensor.\n",
      "        \n",
      "        .. warning::\n",
      "            This function produces deterministic (sub)gradients unlike ``min(dim=0)``\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 3)\n",
      "            >>> a\n",
      "            tensor([[ 0.6750,  1.0857,  1.7197]])\n",
      "            >>> torch.min(a)\n",
      "            tensor(0.6750)\n",
      "        \n",
      "        .. function:: min(input, dim, keepdim=False, *, out=None) -> (Tensor, LongTensor)\n",
      "        \n",
      "        Returns a namedtuple ``(values, indices)`` where ``values`` is the minimum\n",
      "        value of each row of the :attr:`input` tensor in the given dimension\n",
      "        :attr:`dim`. And ``indices`` is the index location of each minimum value found\n",
      "        (argmin).\n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensors are of the same size as\n",
      "        :attr:`input` except in the dimension :attr:`dim` where they are of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
      "        the output tensors having 1 fewer dimension than :attr:`input`.\n",
      "        \n",
      "        .. note:: If there are multiple minimal values in a reduced row then\n",
      "                  the indices of the first minimal value are returned.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the dimension to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the tuple of two output tensors (min, min_indices)\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[-0.6248,  1.1334, -1.1899, -0.2803],\n",
      "                    [-1.4644, -0.2635, -0.3651,  0.6134],\n",
      "                    [ 0.2457,  0.0384,  1.0128,  0.7015],\n",
      "                    [-0.1153,  2.9849,  2.1458,  0.5788]])\n",
      "            >>> torch.min(a, 1)\n",
      "            torch.return_types.min(values=tensor([-1.1899, -1.4644,  0.0384, -0.1153]), indices=tensor([2, 0, 1, 0]))\n",
      "        \n",
      "        .. function:: min(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        See :func:`torch.minimum`.\n",
      "    \n",
      "    minimum(...)\n",
      "        minimum(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise minimum of :attr:`input` and :attr:`other`.\n",
      "        \n",
      "        .. note::\n",
      "            If one of the elements being compared is a NaN, then that element is returned.\n",
      "            :func:`minimum` is not supported for tensors with complex dtypes.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor((1, 2, -1))\n",
      "            >>> b = torch.tensor((3, 0, 4))\n",
      "            >>> torch.minimum(a, b)\n",
      "            tensor([1, 0, -1])\n",
      "    \n",
      "    miopen_batch_norm(...)\n",
      "    \n",
      "    miopen_convolution(...)\n",
      "    \n",
      "    miopen_convolution_transpose(...)\n",
      "    \n",
      "    miopen_depthwise_convolution(...)\n",
      "    \n",
      "    miopen_rnn(...)\n",
      "    \n",
      "    mkldnn_adaptive_avg_pool2d(...)\n",
      "    \n",
      "    mkldnn_convolution(...)\n",
      "    \n",
      "    mkldnn_convolution_backward_weights(...)\n",
      "    \n",
      "    mkldnn_linear_backward_weights(...)\n",
      "    \n",
      "    mkldnn_max_pool2d(...)\n",
      "    \n",
      "    mkldnn_max_pool3d(...)\n",
      "    \n",
      "    mm(...)\n",
      "        mm(input, mat2, *, out=None) -> Tensor\n",
      "        \n",
      "        Performs a matrix multiplication of the matrices :attr:`input` and :attr:`mat2`.\n",
      "        \n",
      "        If :attr:`input` is a :math:`(n \\times m)` tensor, :attr:`mat2` is a\n",
      "        :math:`(m \\times p)` tensor, :attr:`out` will be a :math:`(n \\times p)` tensor.\n",
      "        \n",
      "        .. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
      "                  For broadcasting matrix products, see :func:`torch.matmul`.\n",
      "        \n",
      "        Supports strided and sparse 2-D tensors as inputs, autograd with\n",
      "        respect to strided inputs.\n",
      "        \n",
      "        This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the first matrix to be matrix multiplied\n",
      "            mat2 (Tensor): the second matrix to be matrix multiplied\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> mat1 = torch.randn(2, 3)\n",
      "            >>> mat2 = torch.randn(3, 3)\n",
      "            >>> torch.mm(mat1, mat2)\n",
      "            tensor([[ 0.4851,  0.5037, -0.3633],\n",
      "                    [-0.0760, -3.6705,  2.4784]])\n",
      "    \n",
      "    mode(...)\n",
      "        mode(input, dim=-1, keepdim=False, *, out=None) -> (Tensor, LongTensor)\n",
      "        \n",
      "        Returns a namedtuple ``(values, indices)`` where ``values`` is the mode\n",
      "        value of each row of the :attr:`input` tensor in the given dimension\n",
      "        :attr:`dim`, i.e. a value which appears most often\n",
      "        in that row, and ``indices`` is the index location of each mode value found.\n",
      "        \n",
      "        By default, :attr:`dim` is the last dimension of the :attr:`input` tensor.\n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensors are of the same size as\n",
      "        :attr:`input` except in the dimension :attr:`dim` where they are of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "        in the output tensors having 1 fewer dimension than :attr:`input`.\n",
      "        \n",
      "        .. note:: This function is not defined for ``torch.cuda.Tensor`` yet.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the dimension to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the result tuple of two output tensors (values, indices)\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randint(10, (5,))\n",
      "            >>> a\n",
      "            tensor([6, 5, 1, 0, 2])\n",
      "            >>> b = a + (torch.randn(50, 1) * 5).long()\n",
      "            >>> torch.mode(b, 0)\n",
      "            torch.return_types.mode(values=tensor([6, 5, 1, 0, 2]), indices=tensor([2, 2, 2, 2, 2]))\n",
      "    \n",
      "    moveaxis(...)\n",
      "        moveaxis(input, source, destination) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.movedim`.\n",
      "        \n",
      "        This function is equivalent to NumPy's moveaxis function.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> t = torch.randn(3,2,1)\n",
      "            >>> t\n",
      "            tensor([[[-0.3362],\n",
      "                    [-0.8437]],\n",
      "        \n",
      "                    [[-0.9627],\n",
      "                    [ 0.1727]],\n",
      "        \n",
      "                    [[ 0.5173],\n",
      "                    [-0.1398]]])\n",
      "            >>> torch.moveaxis(t, 1, 0).shape\n",
      "            torch.Size([2, 3, 1])\n",
      "            >>> torch.moveaxis(t, 1, 0)\n",
      "            tensor([[[-0.3362],\n",
      "                    [-0.9627],\n",
      "                    [ 0.5173]],\n",
      "        \n",
      "                    [[-0.8437],\n",
      "                    [ 0.1727],\n",
      "                    [-0.1398]]])\n",
      "            >>> torch.moveaxis(t, (1, 2), (0, 1)).shape\n",
      "            torch.Size([2, 1, 3])\n",
      "            >>> torch.moveaxis(t, (1, 2), (0, 1))\n",
      "            tensor([[[-0.3362, -0.9627,  0.5173]],\n",
      "        \n",
      "                    [[-0.8437,  0.1727, -0.1398]]])\n",
      "    \n",
      "    movedim(...)\n",
      "        movedim(input, source, destination) -> Tensor\n",
      "        \n",
      "        Moves the dimension(s) of :attr:`input` at the position(s) in :attr:`source`\n",
      "        to the position(s) in :attr:`destination`.\n",
      "        \n",
      "        Other dimensions of :attr:`input` that are not explicitly moved remain in\n",
      "        their original order and appear at the positions not specified in :attr:`destination`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            source (int or tuple of ints): Original positions of the dims to move. These must be unique.\n",
      "            destination (int or tuple of ints): Destination positions for each of the original dims. These must also be unique.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> t = torch.randn(3,2,1)\n",
      "            >>> t\n",
      "            tensor([[[-0.3362],\n",
      "                    [-0.8437]],\n",
      "        \n",
      "                    [[-0.9627],\n",
      "                    [ 0.1727]],\n",
      "        \n",
      "                    [[ 0.5173],\n",
      "                    [-0.1398]]])\n",
      "            >>> torch.movedim(t, 1, 0).shape\n",
      "            torch.Size([2, 3, 1])\n",
      "            >>> torch.movedim(t, 1, 0)\n",
      "            tensor([[[-0.3362],\n",
      "                    [-0.9627],\n",
      "                    [ 0.5173]],\n",
      "        \n",
      "                    [[-0.8437],\n",
      "                    [ 0.1727],\n",
      "                    [-0.1398]]])\n",
      "            >>> torch.movedim(t, (1, 2), (0, 1)).shape\n",
      "            torch.Size([2, 1, 3])\n",
      "            >>> torch.movedim(t, (1, 2), (0, 1))\n",
      "            tensor([[[-0.3362, -0.9627,  0.5173]],\n",
      "        \n",
      "                    [[-0.8437,  0.1727, -0.1398]]])\n",
      "    \n",
      "    msort(...)\n",
      "        msort(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Sorts the elements of the :attr:`input` tensor along its first dimension\n",
      "        in ascending order by value.\n",
      "        \n",
      "        .. note:: `torch.msort(t)` is equivalent to `torch.sort(t, dim=0)[0]`.\n",
      "                  See also :func:`torch.sort`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> t = torch.randn(3, 4)\n",
      "            >>> t\n",
      "            tensor([[-0.1321,  0.4370, -1.2631, -1.1289],\n",
      "                    [-2.0527, -1.1250,  0.2275,  0.3077],\n",
      "                    [-0.0881, -0.1259, -0.5495,  1.0284]])\n",
      "            >>> torch.msort(t)\n",
      "            tensor([[-2.0527, -1.1250, -1.2631, -1.1289],\n",
      "                    [-0.1321, -0.1259, -0.5495,  0.3077],\n",
      "                    [-0.0881,  0.4370,  0.2275,  1.0284]])\n",
      "    \n",
      "    mul(...)\n",
      "        mul(input, other, *, out=None)\n",
      "        \n",
      "        Multiplies each element of the input :attr:`input` with the scalar\n",
      "        :attr:`other` and returns a new resulting tensor.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = \\text{other} \\times \\text{input}_i\n",
      "        \n",
      "        If :attr:`input` is of type `FloatTensor` or `DoubleTensor`, :attr:`other`\n",
      "        should be a real number, otherwise it should be an integer\n",
      "        \n",
      "        Args:\n",
      "            {input}\n",
      "            other (Number): the number to be multiplied to each element of :attr:`input`\n",
      "        \n",
      "        Keyword args:\n",
      "            {out}\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(3)\n",
      "            >>> a\n",
      "            tensor([ 0.2015, -0.4255,  2.6087])\n",
      "            >>> torch.mul(a, 100)\n",
      "            tensor([  20.1494,  -42.5491,  260.8663])\n",
      "        \n",
      "        .. function:: mul(input, other, *, out=None)\n",
      "        \n",
      "        Each element of the tensor :attr:`input` is multiplied by the corresponding\n",
      "        element of the Tensor :attr:`other`. The resulting tensor is returned.\n",
      "        \n",
      "        The shapes of :attr:`input` and :attr:`other` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = \\text{input}_i \\times \\text{other}_i\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the first multiplicand tensor\n",
      "            other (Tensor): the second multiplicand tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 1)\n",
      "            >>> a\n",
      "            tensor([[ 1.1207],\n",
      "                    [-0.3137],\n",
      "                    [ 0.0700],\n",
      "                    [ 0.8378]])\n",
      "            >>> b = torch.randn(1, 4)\n",
      "            >>> b\n",
      "            tensor([[ 0.5146,  0.1216, -0.5244,  2.2382]])\n",
      "            >>> torch.mul(a, b)\n",
      "            tensor([[ 0.5767,  0.1363, -0.5877,  2.5083],\n",
      "                    [-0.1614, -0.0382,  0.1645, -0.7021],\n",
      "                    [ 0.0360,  0.0085, -0.0367,  0.1567],\n",
      "                    [ 0.4312,  0.1019, -0.4394,  1.8753]])\n",
      "    \n",
      "    multinomial(...)\n",
      "        multinomial(input, num_samples, replacement=False, *, generator=None, out=None) -> LongTensor\n",
      "        \n",
      "        Returns a tensor where each row contains :attr:`num_samples` indices sampled\n",
      "        from the multinomial probability distribution located in the corresponding row\n",
      "        of tensor :attr:`input`.\n",
      "        \n",
      "        .. note::\n",
      "            The rows of :attr:`input` do not need to sum to one (in which case we use\n",
      "            the values as weights), but must be non-negative, finite and have\n",
      "            a non-zero sum.\n",
      "        \n",
      "        Indices are ordered from left to right according to when each was sampled\n",
      "        (first samples are placed in first column).\n",
      "        \n",
      "        If :attr:`input` is a vector, :attr:`out` is a vector of size :attr:`num_samples`.\n",
      "        \n",
      "        If :attr:`input` is a matrix with `m` rows, :attr:`out` is an matrix of shape\n",
      "        :math:`(m \\times \\text{num\\_samples})`.\n",
      "        \n",
      "        If replacement is ``True``, samples are drawn with replacement.\n",
      "        \n",
      "        If not, they are drawn without replacement, which means that when a\n",
      "        sample index is drawn for a row, it cannot be drawn again for that row.\n",
      "        \n",
      "        .. note::\n",
      "            When drawn without replacement, :attr:`num_samples` must be lower than\n",
      "            number of non-zero elements in :attr:`input` (or the min number of non-zero\n",
      "            elements in each row of :attr:`input` if it is a matrix).\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor containing probabilities\n",
      "            num_samples (int): number of samples to draw\n",
      "            replacement (bool, optional): whether to draw with replacement or not\n",
      "        \n",
      "        Keyword args:\n",
      "            generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> weights = torch.tensor([0, 10, 3, 0], dtype=torch.float) # create a tensor of weights\n",
      "            >>> torch.multinomial(weights, 2)\n",
      "            tensor([1, 2])\n",
      "            >>> torch.multinomial(weights, 4) # ERROR!\n",
      "            RuntimeError: invalid argument 2: invalid multinomial distribution (with replacement=False,\n",
      "            not enough non-negative category to sample) at ../aten/src/TH/generic/THTensorRandom.cpp:320\n",
      "            >>> torch.multinomial(weights, 4, replacement=True)\n",
      "            tensor([ 2,  1,  1,  1])\n",
      "    \n",
      "    multiply(...)\n",
      "        multiply(input, other, *, out=None)\n",
      "        \n",
      "        Alias for :func:`torch.mul`.\n",
      "    \n",
      "    mv(...)\n",
      "        mv(input, vec, *, out=None) -> Tensor\n",
      "        \n",
      "        Performs a matrix-vector product of the matrix :attr:`input` and the vector\n",
      "        :attr:`vec`.\n",
      "        \n",
      "        If :attr:`input` is a :math:`(n \\times m)` tensor, :attr:`vec` is a 1-D tensor of\n",
      "        size :math:`m`, :attr:`out` will be 1-D of size :math:`n`.\n",
      "        \n",
      "        .. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): matrix to be multiplied\n",
      "            vec (Tensor): vector to be multiplied\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> mat = torch.randn(2, 3)\n",
      "            >>> vec = torch.randn(3)\n",
      "            >>> torch.mv(mat, vec)\n",
      "            tensor([ 1.0404, -0.6361])\n",
      "    \n",
      "    mvlgamma(...)\n",
      "        mvlgamma(input, p) -> Tensor\n",
      "        \n",
      "        Computes the `multivariate log-gamma function\n",
      "        <https://en.wikipedia.org/wiki/Multivariate_gamma_function>`_) with dimension\n",
      "        :math:`p` element-wise, given by\n",
      "        \n",
      "        .. math::\n",
      "            \\log(\\Gamma_{p}(a)) = C + \\displaystyle \\sum_{i=1}^{p} \\log\\left(\\Gamma\\left(a - \\frac{i - 1}{2}\\right)\\right)\n",
      "        \n",
      "        where :math:`C = \\log(\\pi) \\times \\frac{p (p - 1)}{4}` and :math:`\\Gamma(\\cdot)` is the Gamma function.\n",
      "        \n",
      "        All elements must be greater than :math:`\\frac{p - 1}{2}`, otherwise an error would be thrown.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to compute the multivariate log-gamma function\n",
      "            p (int): the number of dimensions\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.empty(2, 3).uniform_(1, 2)\n",
      "            >>> a\n",
      "            tensor([[1.6835, 1.8474, 1.1929],\n",
      "                    [1.0475, 1.7162, 1.4180]])\n",
      "            >>> torch.mvlgamma(a, 2)\n",
      "            tensor([[0.3928, 0.4007, 0.7586],\n",
      "                    [1.0311, 0.3901, 0.5049]])\n",
      "    \n",
      "    nan_to_num(...)\n",
      "        nan_to_num(input, nan=0.0, posinf=None, neginf=None, *, out=None) -> Tensor\n",
      "        \n",
      "        Replaces :literal:`NaN`, positive infinity, and negative infinity values in :attr:`input`\n",
      "        with the values specified by :attr:`nan`, :attr:`posinf`, and :attr:`neginf`, respectively.\n",
      "        By default, :literal:`NaN`s are replaced with zero, positive infinity is replaced with the\n",
      "        greatest finite value representable by :attr:`input`'s dtype, and negative infinity\n",
      "        is replaced with the least finite value representable by :attr:`input`'s dtype.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            nan (Number, optional): the value to replace :literal:`NaN`\\s with. Default is zero.\n",
      "            posinf (Number, optional): if a Number, the value to replace positive infinity values with.\n",
      "                If None, positive infinity values are replaced with the greatest finite value representable by :attr:`input`'s dtype.\n",
      "                Default is None.\n",
      "            neginf (Number, optional): if a Number, the value to replace negative infinity values with.\n",
      "                If None, negative infinity values are replaced with the lowest finite value representable by :attr:`input`'s dtype.\n",
      "                Default is None.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.tensor([float('nan'), float('inf'), -float('inf'), 3.14])\n",
      "            >>> torch.nan_to_num(x)\n",
      "            tensor([ 0.0000e+00,  3.4028e+38, -3.4028e+38,  3.1400e+00])\n",
      "            >>> torch.nan_to_num(x, nan=2.0)\n",
      "            tensor([ 2.0000e+00,  3.4028e+38, -3.4028e+38,  3.1400e+00])\n",
      "            >>> torch.nan_to_num(x, nan=2.0, posinf=1.0)\n",
      "            tensor([ 2.0000e+00,  1.0000e+00, -3.4028e+38,  3.1400e+00])\n",
      "    \n",
      "    nan_to_num_(...)\n",
      "    \n",
      "    nanmedian(...)\n",
      "        nanmedian(input) -> Tensor\n",
      "        \n",
      "        Returns the median of the values in :attr:`input`, ignoring ``NaN`` values.\n",
      "        \n",
      "        This function is identical to :func:`torch.median` when there are no ``NaN`` values in :attr:`input`.\n",
      "        When :attr:`input` has one or more ``NaN`` values, :func:`torch.median` will always return ``NaN``,\n",
      "        while this function will return the median of the non-``NaN`` elements in :attr:`input`.\n",
      "        If all the elements in :attr:`input` are ``NaN`` it will also return ``NaN``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([1, float('nan'), 3, 2])\n",
      "            >>> a.median()\n",
      "            tensor(nan)\n",
      "            >>> a.nanmedian()\n",
      "            tensor(2.)\n",
      "        \n",
      "        .. function:: nanmedian(input, dim=-1, keepdim=False, *, out=None) -> (Tensor, LongTensor)\n",
      "        \n",
      "        Returns a namedtuple ``(values, indices)`` where ``values`` contains the median of each row of :attr:`input`\n",
      "        in the dimension :attr:`dim`, ignoring ``NaN`` values, and ``indices`` contains the index of the median values\n",
      "        found in the dimension :attr:`dim`.\n",
      "        \n",
      "        This function is identical to :func:`torch.median` when there are no ``NaN`` values in a reduced row. When a reduced row has\n",
      "        one or more ``NaN`` values, :func:`torch.median` will always reduce it to ``NaN``, while this function will reduce it to the\n",
      "        median of the non-``NaN`` elements. If all the elements in a reduced row are ``NaN`` then it will be reduced to ``NaN``, too.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the dimension to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            out ((Tensor, Tensor), optional): The first tensor will be populated with the median values and the second\n",
      "                                              tensor, which must have dtype long, with their indices in the dimension\n",
      "                                              :attr:`dim` of :attr:`input`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([[2, 3, 1], [float('nan'), 1, float('nan')]])\n",
      "            >>> a\n",
      "            tensor([[2., 3., 1.],\n",
      "                    [nan, 1., nan]])\n",
      "            >>> a.median(0)\n",
      "            torch.return_types.median(values=tensor([nan, 1., nan]), indices=tensor([1, 1, 1]))\n",
      "            >>> a.nanmedian(0)\n",
      "            torch.return_types.nanmedian(values=tensor([2., 1., 1.]), indices=tensor([0, 1, 0]))\n",
      "    \n",
      "    nanquantile(...)\n",
      "        nanquantile(input, q, dim=None, keepdim=False, *, out=None) -> Tensor\n",
      "        \n",
      "        This is a variant of :func:`torch.quantile` that \"ignores\" ``NaN`` values,\n",
      "        computing the quantiles :attr:`q` as if ``NaN`` values in :attr:`input` did\n",
      "        not exist. If all values in a reduced row are ``NaN`` then the quantiles for\n",
      "        that reduction will be ``NaN``. See the documentation for :func:`torch.quantile`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            q (float or Tensor): a scalar or 1D tensor of quantile values in the range [0, 1]\n",
      "            dim (int): the dimension to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> t = torch.tensor([float('nan'), 1, 2])\n",
      "            >>> t.quantile(0.5)\n",
      "            tensor(nan)\n",
      "            >>> t.nanquantile(0.5)\n",
      "            tensor(1.5000)\n",
      "        \n",
      "            >>> t = torch.tensor([[float('nan'), float('nan')], [1, 2]])\n",
      "            >>> t\n",
      "            tensor([[nan, nan],\n",
      "                    [1., 2.]])\n",
      "            >>> t.nanquantile(0.5, dim=0)\n",
      "            tensor([1., 2.])\n",
      "            >>> t.nanquantile(0.5, dim=1)\n",
      "            tensor([   nan, 1.5000])\n",
      "    \n",
      "    nansum(...)\n",
      "        nansum(input, *, dtype=None) -> Tensor\n",
      "        \n",
      "        Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "                is performed. This is useful for preventing data type overflows. Default: None.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([1., 2., float('nan'), 4.])\n",
      "            >>> torch.nansum(a)\n",
      "            tensor(7.)\n",
      "        \n",
      "        .. function:: nansum(input, dim, keepdim=False, *, dtype=None) -> Tensor\n",
      "        \n",
      "        Returns the sum of each row of the :attr:`input` tensor in the given\n",
      "        dimension :attr:`dim`, treating Not a Numbers (NaNs) as zero.\n",
      "        If :attr:`dim` is a list of dimensions, reduce over all of them.\n",
      "        \n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "        as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "        output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "                is performed. This is useful for preventing data type overflows. Default: None.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.nansum(torch.tensor([1., float(\"nan\")]))\n",
      "            1.0\n",
      "            >>> a = torch.tensor([[1, 2], [3., float(\"nan\")]])\n",
      "            >>> torch.nansum(a)\n",
      "            tensor(6.)\n",
      "            >>> torch.nansum(a, dim=0)\n",
      "            tensor([4., 2.])\n",
      "            >>> torch.nansum(a, dim=1)\n",
      "            tensor([3., 3.])\n",
      "    \n",
      "    narrow(...)\n",
      "        narrow(input, dim, start, length) -> Tensor\n",
      "        \n",
      "        Returns a new tensor that is a narrowed version of :attr:`input` tensor. The\n",
      "        dimension :attr:`dim` is input from :attr:`start` to :attr:`start + length`. The\n",
      "        returned tensor and :attr:`input` tensor share the same underlying storage.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to narrow\n",
      "            dim (int): the dimension along which to narrow\n",
      "            start (int): the starting dimension\n",
      "            length (int): the distance to the ending dimension\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "            >>> torch.narrow(x, 0, 0, 2)\n",
      "            tensor([[ 1,  2,  3],\n",
      "                    [ 4,  5,  6]])\n",
      "            >>> torch.narrow(x, 1, 1, 2)\n",
      "            tensor([[ 2,  3],\n",
      "                    [ 5,  6],\n",
      "                    [ 8,  9]])\n",
      "    \n",
      "    narrow_copy(...)\n",
      "    \n",
      "    native_batch_norm(...)\n",
      "    \n",
      "    native_group_norm(...)\n",
      "    \n",
      "    native_layer_norm(...)\n",
      "    \n",
      "    native_norm(...)\n",
      "    \n",
      "    ne(...)\n",
      "        ne(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes :math:`\\text{input} \\neq \\text{other}` element-wise.\n",
      "        \n",
      "        \n",
      "        The second argument can be a number or a tensor whose shape is\n",
      "        :ref:`broadcastable <broadcasting-semantics>` with the first argument.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to compare\n",
      "            other (Tensor or float): the tensor or value to compare\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Returns:\n",
      "            A boolean tensor that is True where :attr:`input` is not equal to :attr:`other` and False elsewhere\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.ne(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\n",
      "            tensor([[False, True], [True, False]])\n",
      "    \n",
      "    neg(...)\n",
      "        neg(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the negative of the elements of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out} = -1 \\times \\text{input}\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(5)\n",
      "            >>> a\n",
      "            tensor([ 0.0090, -0.2262, -0.0682, -0.2866,  0.3940])\n",
      "            >>> torch.neg(a)\n",
      "            tensor([-0.0090,  0.2262,  0.0682,  0.2866, -0.3940])\n",
      "    \n",
      "    neg_(...)\n",
      "    \n",
      "    negative(...)\n",
      "        negative(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.neg`\n",
      "    \n",
      "    negative_(...)\n",
      "    \n",
      "    nextafter(...)\n",
      "        nextafter(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Return the next floating-point value after :attr:`input` towards :attr:`other`, elementwise.\n",
      "        \n",
      "        The shapes of ``input`` and ``other`` must be\n",
      "        :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the first input tensor\n",
      "            other (Tensor): the second input tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> eps = torch.finfo(torch.float32).eps\n",
      "            >>> torch.nextafter(torch.Tensor([1, 2]), torch.Tensor([2, 1])) == torch.Tensor([eps + 1, 2 - eps])\n",
      "            tensor([True, True])\n",
      "    \n",
      "    nonzero(...)\n",
      "        nonzero(input, *, out=None, as_tuple=False) -> LongTensor or tuple of LongTensors\n",
      "        \n",
      "        .. note::\n",
      "            :func:`torch.nonzero(..., as_tuple=False) <torch.nonzero>` (default) returns a\n",
      "            2-D tensor where each row is the index for a nonzero value.\n",
      "        \n",
      "            :func:`torch.nonzero(..., as_tuple=True) <torch.nonzero>` returns a tuple of 1-D\n",
      "            index tensors, allowing for advanced indexing, so ``x[x.nonzero(as_tuple=True)]``\n",
      "            gives all nonzero values of tensor ``x``. Of the returned tuple, each index tensor\n",
      "            contains nonzero indices for a certain dimension.\n",
      "        \n",
      "            See below for more details on the two behaviors.\n",
      "        \n",
      "            When :attr:`input` is on CUDA, :func:`torch.nonzero() <torch.nonzero>` causes\n",
      "            host-device synchronization.\n",
      "        \n",
      "        **When** :attr:`as_tuple` **is ``False`` (default)**:\n",
      "        \n",
      "        Returns a tensor containing the indices of all non-zero elements of\n",
      "        :attr:`input`.  Each row in the result contains the indices of a non-zero\n",
      "        element in :attr:`input`. The result is sorted lexicographically, with\n",
      "        the last index changing the fastest (C-style).\n",
      "        \n",
      "        If :attr:`input` has :math:`n` dimensions, then the resulting indices tensor\n",
      "        :attr:`out` is of size :math:`(z \\times n)`, where :math:`z` is the total number of\n",
      "        non-zero elements in the :attr:`input` tensor.\n",
      "        \n",
      "        **When** :attr:`as_tuple` **is ``True``**:\n",
      "        \n",
      "        Returns a tuple of 1-D tensors, one for each dimension in :attr:`input`,\n",
      "        each containing the indices (in that dimension) of all non-zero elements of\n",
      "        :attr:`input` .\n",
      "        \n",
      "        If :attr:`input` has :math:`n` dimensions, then the resulting tuple contains :math:`n`\n",
      "        tensors of size :math:`z`, where :math:`z` is the total number of\n",
      "        non-zero elements in the :attr:`input` tensor.\n",
      "        \n",
      "        As a special case, when :attr:`input` has zero dimensions and a nonzero scalar\n",
      "        value, it is treated as a one-dimensional tensor with one element.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (LongTensor, optional): the output tensor containing indices\n",
      "        \n",
      "        Returns:\n",
      "            LongTensor or tuple of LongTensor: If :attr:`as_tuple` is ``False``, the output\n",
      "            tensor containing indices. If :attr:`as_tuple` is ``True``, one 1-D tensor for\n",
      "            each dimension, containing the indices of each nonzero element along that\n",
      "            dimension.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.nonzero(torch.tensor([1, 1, 1, 0, 1]))\n",
      "            tensor([[ 0],\n",
      "                    [ 1],\n",
      "                    [ 2],\n",
      "                    [ 4]])\n",
      "            >>> torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],\n",
      "            ...                             [0.0, 0.4, 0.0, 0.0],\n",
      "            ...                             [0.0, 0.0, 1.2, 0.0],\n",
      "            ...                             [0.0, 0.0, 0.0,-0.4]]))\n",
      "            tensor([[ 0,  0],\n",
      "                    [ 1,  1],\n",
      "                    [ 2,  2],\n",
      "                    [ 3,  3]])\n",
      "            >>> torch.nonzero(torch.tensor([1, 1, 1, 0, 1]), as_tuple=True)\n",
      "            (tensor([0, 1, 2, 4]),)\n",
      "            >>> torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],\n",
      "            ...                             [0.0, 0.4, 0.0, 0.0],\n",
      "            ...                             [0.0, 0.0, 1.2, 0.0],\n",
      "            ...                             [0.0, 0.0, 0.0,-0.4]]), as_tuple=True)\n",
      "            (tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3]))\n",
      "            >>> torch.nonzero(torch.tensor(5), as_tuple=True)\n",
      "            (tensor([0]),)\n",
      "    \n",
      "    norm(input, p='fro', dim=None, keepdim=False, out=None, dtype=None)\n",
      "        Returns the matrix norm or vector norm of a given tensor.\n",
      "        \n",
      "        .. warning::\n",
      "        \n",
      "            torch.norm is deprecated and may be removed in a future PyTorch release.\n",
      "            Use :func:`torch.linalg.norm` instead, but note that :func:`torch.linalg.norm`\n",
      "            has a different signature and slightly different behavior that is\n",
      "            more consistent with NumPy's numpy.linalg.norm.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): The input tensor. Its data type must be either a floating\n",
      "                point or complex type. For complex inputs, the norm is calculated using the\n",
      "                absolute value of each element. If the input is complex and neither\n",
      "                :attr:`dtype` nor :attr:`out` is specified, the result's data type will\n",
      "                be the corresponding floating point type (e.g. float if :attr:`input` is\n",
      "                complexfloat).\n",
      "        \n",
      "            p (int, float, inf, -inf, 'fro', 'nuc', optional): the order of norm. Default: ``'fro'``\n",
      "                The following norms can be calculated:\n",
      "        \n",
      "                ======  ==============  ==========================\n",
      "                ord     matrix norm     vector norm\n",
      "                ======  ==============  ==========================\n",
      "                'fro'   Frobenius norm  --\n",
      "                'nuc'   nuclear norm    --\n",
      "                Number  --              sum(abs(x)**ord)**(1./ord)\n",
      "                ======  ==============  ==========================\n",
      "        \n",
      "                The vector norm can be calculated across any number of dimensions.\n",
      "                The corresponding dimensions of :attr:`input` are flattened into\n",
      "                one dimension, and the norm is calculated on the flattened\n",
      "                dimension.\n",
      "        \n",
      "                Frobenius norm produces the same result as ``p=2`` in all cases\n",
      "                except when :attr:`dim` is a list of three or more dims, in which\n",
      "                case Frobenius norm throws an error.\n",
      "        \n",
      "                Nuclear norm can only be calculated across exactly two dimensions.\n",
      "        \n",
      "            dim (int, tuple of ints, list of ints, optional):\n",
      "                Specifies which dimension or dimensions of :attr:`input` to\n",
      "                calculate the norm across. If :attr:`dim` is ``None``, the norm will\n",
      "                be calculated across all dimensions of :attr:`input`. If the norm\n",
      "                type indicated by :attr:`p` does not support the specified number of\n",
      "                dimensions, an error will occur.\n",
      "            keepdim (bool, optional): whether the output tensors have :attr:`dim`\n",
      "                retained or not. Ignored if :attr:`dim` = ``None`` and\n",
      "                :attr:`out` = ``None``. Default: ``False``\n",
      "            out (Tensor, optional): the output tensor. Ignored if\n",
      "                :attr:`dim` = ``None`` and :attr:`out` = ``None``.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of\n",
      "                returned tensor. If specified, the input tensor is casted to\n",
      "                :attr:'dtype' while performing the operation. Default: None.\n",
      "        \n",
      "        .. note::\n",
      "            Even though ``p='fro'`` supports any number of dimensions, the true\n",
      "            mathematical definition of Frobenius norm only applies to tensors with\n",
      "            exactly two dimensions. :func:`torch.linalg.norm` with ``ord='fro'`` aligns\n",
      "            with the mathematical definition, since it can only be applied across\n",
      "            exactly two dimensions.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> import torch\n",
      "            >>> a = torch.arange(9, dtype= torch.float) - 4\n",
      "            >>> b = a.reshape((3, 3))\n",
      "            >>> torch.norm(a)\n",
      "            tensor(7.7460)\n",
      "            >>> torch.norm(b)\n",
      "            tensor(7.7460)\n",
      "            >>> torch.norm(a, float('inf'))\n",
      "            tensor(4.)\n",
      "            >>> torch.norm(b, float('inf'))\n",
      "            tensor(4.)\n",
      "            >>> c = torch.tensor([[ 1, 2, 3],[-1, 1, 4]] , dtype= torch.float)\n",
      "            >>> torch.norm(c, dim=0)\n",
      "            tensor([1.4142, 2.2361, 5.0000])\n",
      "            >>> torch.norm(c, dim=1)\n",
      "            tensor([3.7417, 4.2426])\n",
      "            >>> torch.norm(c, p=1, dim=1)\n",
      "            tensor([6., 6.])\n",
      "            >>> d = torch.arange(8, dtype= torch.float).reshape(2,2,2)\n",
      "            >>> torch.norm(d, dim=(1,2))\n",
      "            tensor([ 3.7417, 11.2250])\n",
      "            >>> torch.norm(d[0, :, :]), torch.norm(d[1, :, :])\n",
      "            (tensor(3.7417), tensor(11.2250))\n",
      "    \n",
      "    norm_except_dim(...)\n",
      "    \n",
      "    normal(...)\n",
      "        normal(mean, std, *, generator=None, out=None) -> Tensor\n",
      "        \n",
      "        Returns a tensor of random numbers drawn from separate normal distributions\n",
      "        whose mean and standard deviation are given.\n",
      "        \n",
      "        The :attr:`mean` is a tensor with the mean of\n",
      "        each output element's normal distribution\n",
      "        \n",
      "        The :attr:`std` is a tensor with the standard deviation of\n",
      "        each output element's normal distribution\n",
      "        \n",
      "        The shapes of :attr:`mean` and :attr:`std` don't need to match, but the\n",
      "        total number of elements in each tensor need to be the same.\n",
      "        \n",
      "        .. note:: When the shapes do not match, the shape of :attr:`mean`\n",
      "                  is used as the shape for the returned output tensor\n",
      "        \n",
      "        Args:\n",
      "            mean (Tensor): the tensor of per-element means\n",
      "            std (Tensor): the tensor of per-element standard deviations\n",
      "        \n",
      "        Keyword args:\n",
      "            generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\n",
      "            tensor([  1.0425,   3.5672,   2.7969,   4.2925,   4.7229,   6.2134,\n",
      "                      8.0505,   8.1408,   9.0563,  10.0566])\n",
      "        \n",
      "        .. function:: normal(mean=0.0, std, *, out=None) -> Tensor\n",
      "        \n",
      "        Similar to the function above, but the means are shared among all drawn\n",
      "        elements.\n",
      "        \n",
      "        Args:\n",
      "            mean (float, optional): the mean for all distributions\n",
      "            std (Tensor): the tensor of per-element standard deviations\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.normal(mean=0.5, std=torch.arange(1., 6.))\n",
      "            tensor([-1.2793, -1.0732, -2.0687,  5.1177, -1.2303])\n",
      "        \n",
      "        .. function:: normal(mean, std=1.0, *, out=None) -> Tensor\n",
      "        \n",
      "        Similar to the function above, but the standard-deviations are shared among\n",
      "        all drawn elements.\n",
      "        \n",
      "        Args:\n",
      "            mean (Tensor): the tensor of per-element means\n",
      "            std (float, optional): the standard deviation for all distributions\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.normal(mean=torch.arange(1., 6.))\n",
      "            tensor([ 1.1552,  2.6148,  2.6535,  5.8318,  4.2361])\n",
      "        \n",
      "        .. function:: normal(mean, std, size, *, out=None) -> Tensor\n",
      "        \n",
      "        Similar to the function above, but the means and standard deviations are shared\n",
      "        among all drawn elements. The resulting tensor has size given by :attr:`size`.\n",
      "        \n",
      "        Args:\n",
      "            mean (float): the mean for all distributions\n",
      "            std (float): the standard deviation for all distributions\n",
      "            size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.normal(2, 3, size=(1, 4))\n",
      "            tensor([[-1.3987, -1.9544,  3.6048,  0.7909]])\n",
      "    \n",
      "    not_equal(...)\n",
      "        not_equal(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.ne`.\n",
      "    \n",
      "    nuclear_norm(...)\n",
      "    \n",
      "    numel(...)\n",
      "        numel(input) -> int\n",
      "        \n",
      "        Returns the total number of elements in the :attr:`input` tensor.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 2, 3, 4, 5)\n",
      "            >>> torch.numel(a)\n",
      "            120\n",
      "            >>> a = torch.zeros(4,4)\n",
      "            >>> torch.numel(a)\n",
      "            16\n",
      "    \n",
      "    ones(...)\n",
      "        ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with the scalar value `1`, with the shape defined\n",
      "        by the variable argument :attr:`size`.\n",
      "        \n",
      "        Args:\n",
      "            size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "                Can be a variable number of arguments or a collection like a list or tuple.\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.ones(2, 3)\n",
      "            tensor([[ 1.,  1.,  1.],\n",
      "                    [ 1.,  1.,  1.]])\n",
      "        \n",
      "            >>> torch.ones(5)\n",
      "            tensor([ 1.,  1.,  1.,  1.,  1.])\n",
      "    \n",
      "    ones_like(...)\n",
      "        ones_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with the scalar value `1`, with the same size as\n",
      "        :attr:`input`. ``torch.ones_like(input)`` is equivalent to\n",
      "        ``torch.ones(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)``.\n",
      "        \n",
      "        .. warning::\n",
      "            As of 0.4, this function does not support an :attr:`out` keyword. As an alternative,\n",
      "            the old ``torch.ones_like(input, out=output)`` is equivalent to\n",
      "            ``torch.ones(input.size(), out=output)``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the size of :attr:`input` will determine size of the output tensor.\n",
      "        \n",
      "        Keyword arguments:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned Tensor.\n",
      "                Default: if ``None``, defaults to the dtype of :attr:`input`.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned tensor.\n",
      "                Default: if ``None``, defaults to the layout of :attr:`input`.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, defaults to the device of :attr:`input`.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "            memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "                returned Tensor. Default: ``torch.preserve_format``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> input = torch.empty(2, 3)\n",
      "            >>> torch.ones_like(input)\n",
      "            tensor([[ 1.,  1.,  1.],\n",
      "                    [ 1.,  1.,  1.]])\n",
      "    \n",
      "    orgqr(...)\n",
      "        orgqr(input, input2) -> Tensor\n",
      "        \n",
      "        Computes the orthogonal matrix `Q` of a QR factorization, from the `(input, input2)`\n",
      "        tuple returned by :func:`torch.geqrf`.\n",
      "        \n",
      "        This directly calls the underlying LAPACK function `?orgqr`.\n",
      "        See `LAPACK documentation for orgqr`_ for further details.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the `a` from :func:`torch.geqrf`.\n",
      "            input2 (Tensor): the `tau` from :func:`torch.geqrf`.\n",
      "        \n",
      "        .. _LAPACK documentation for orgqr:\n",
      "            https://software.intel.com/en-us/mkl-developer-reference-c-orgqr\n",
      "    \n",
      "    ormqr(...)\n",
      "        ormqr(input, input2, input3, left=True, transpose=False) -> Tensor\n",
      "        \n",
      "        Multiplies `mat` (given by :attr:`input3`) by the orthogonal `Q` matrix of the QR factorization\n",
      "        formed by :func:`torch.geqrf` that is represented by `(a, tau)` (given by (:attr:`input`, :attr:`input2`)).\n",
      "        \n",
      "        This directly calls the underlying LAPACK function `?ormqr`.\n",
      "        See `LAPACK documentation for ormqr`_ for further details.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the `a` from :func:`torch.geqrf`.\n",
      "            input2 (Tensor): the `tau` from :func:`torch.geqrf`.\n",
      "            input3 (Tensor): the matrix to be multiplied.\n",
      "        \n",
      "        .. _LAPACK documentation for ormqr:\n",
      "            https://software.intel.com/en-us/mkl-developer-reference-c-ormqr\n",
      "    \n",
      "    outer(...)\n",
      "        outer(input, vec2, *, out=None) -> Tensor\n",
      "        \n",
      "        Outer product of :attr:`input` and :attr:`vec2`.\n",
      "        If :attr:`input` is a vector of size :math:`n` and :attr:`vec2` is a vector of\n",
      "        size :math:`m`, then :attr:`out` must be a matrix of size :math:`(n \\times m)`.\n",
      "        \n",
      "        .. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): 1-D input vector\n",
      "            vec2 (Tensor): 1-D input vector\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): optional output matrix\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> v1 = torch.arange(1., 5.)\n",
      "            >>> v2 = torch.arange(1., 4.)\n",
      "            >>> torch.outer(v1, v2)\n",
      "            tensor([[  1.,   2.,   3.],\n",
      "                    [  2.,   4.,   6.],\n",
      "                    [  3.,   6.,   9.],\n",
      "                    [  4.,   8.,  12.]])\n",
      "    \n",
      "    pairwise_distance(...)\n",
      "    \n",
      "    parse_ir(...) method of builtins.PyCapsule instance\n",
      "        parse_ir(arg0: str) -> torch::jit::Graph\n",
      "    \n",
      "    parse_schema(...) method of builtins.PyCapsule instance\n",
      "        parse_schema(arg0: str) -> c10::FunctionSchema\n",
      "    \n",
      "    parse_type_comment(...) method of builtins.PyCapsule instance\n",
      "        parse_type_comment(arg0: str) -> torch._C._jit_tree_views.Decl\n",
      "    \n",
      "    pdist(...)\n",
      "        pdist(input, p=2) -> Tensor\n",
      "        \n",
      "        Computes the p-norm distance between every pair of row vectors in the input.\n",
      "        This is identical to the upper triangular portion, excluding the diagonal, of\n",
      "        `torch.norm(input[:, None] - input, dim=2, p=p)`. This function will be faster\n",
      "        if the rows are contiguous.\n",
      "        \n",
      "        If input has shape :math:`N \\times M` then the output will have shape\n",
      "        :math:`\\frac{1}{2} N (N - 1)`.\n",
      "        \n",
      "        This function is equivalent to `scipy.spatial.distance.pdist(input,\n",
      "        'minkowski', p=p)` if :math:`p \\in (0, \\infty)`. When :math:`p = 0` it is\n",
      "        equivalent to `scipy.spatial.distance.pdist(input, 'hamming') * M`.\n",
      "        When :math:`p = \\infty`, the closest scipy function is\n",
      "        `scipy.spatial.distance.pdist(xn, lambda x, y: np.abs(x - y).max())`.\n",
      "        \n",
      "        Args:\n",
      "            input: input tensor of shape :math:`N \\times M`.\n",
      "            p: p value for the p-norm distance to calculate between each vector pair\n",
      "                :math:`\\in [0, \\infty]`.\n",
      "    \n",
      "    pinverse(...)\n",
      "        pinverse(input, rcond=1e-15) -> Tensor\n",
      "        \n",
      "        Calculates the pseudo-inverse (also known as the Moore-Penrose inverse) of a 2D tensor.\n",
      "        Please look at `Moore-Penrose inverse`_ for more details\n",
      "        \n",
      "        .. note:: :func:`torch.pinverse` is deprecated. Please use :func:`torch.linalg.pinv` instead\n",
      "                  which includes new parameters :attr:`hermitian` and :attr:`out`.\n",
      "        \n",
      "        .. note::\n",
      "            This method is implemented using the Singular Value Decomposition.\n",
      "        \n",
      "        .. note::\n",
      "            The pseudo-inverse is not necessarily a continuous function in the elements of the matrix `[1]`_.\n",
      "            Therefore, derivatives are not always existent, and exist for a constant rank only `[2]`_.\n",
      "            However, this method is backprop-able due to the implementation by using SVD results, and\n",
      "            could be unstable. Double-backward will also be unstable due to the usage of SVD internally.\n",
      "            See :meth:`~torch.svd` for more details.\n",
      "        \n",
      "        .. note::\n",
      "            Supports real and complex inputs.\n",
      "            Batched version for complex inputs is only supported on the CPU.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): The input tensor of size :math:`(*, m, n)` where :math:`*` is\n",
      "                zero or more batch dimensions.\n",
      "            rcond (float, optional): A floating point value to determine the cutoff for\n",
      "                small singular values. Default: ``1e-15``.\n",
      "        \n",
      "        Returns:\n",
      "            The pseudo-inverse of :attr:`input` of dimensions :math:`(*, n, m)`\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> input = torch.randn(3, 5)\n",
      "            >>> input\n",
      "            tensor([[ 0.5495,  0.0979, -1.4092, -0.1128,  0.4132],\n",
      "                    [-1.1143, -0.3662,  0.3042,  1.6374, -0.9294],\n",
      "                    [-0.3269, -0.5745, -0.0382, -0.5922, -0.6759]])\n",
      "            >>> torch.pinverse(input)\n",
      "            tensor([[ 0.0600, -0.1933, -0.2090],\n",
      "                    [-0.0903, -0.0817, -0.4752],\n",
      "                    [-0.7124, -0.1631, -0.2272],\n",
      "                    [ 0.1356,  0.3933, -0.5023],\n",
      "                    [-0.0308, -0.1725, -0.5216]])\n",
      "            >>> # Batched pinverse example\n",
      "            >>> a = torch.randn(2,6,3)\n",
      "            >>> b = torch.pinverse(a)\n",
      "            >>> torch.matmul(b, a)\n",
      "            tensor([[[ 1.0000e+00,  1.6391e-07, -1.1548e-07],\n",
      "                    [ 8.3121e-08,  1.0000e+00, -2.7567e-07],\n",
      "                    [ 3.5390e-08,  1.4901e-08,  1.0000e+00]],\n",
      "        \n",
      "                    [[ 1.0000e+00, -8.9407e-08,  2.9802e-08],\n",
      "                    [-2.2352e-07,  1.0000e+00,  1.1921e-07],\n",
      "                    [ 0.0000e+00,  8.9407e-08,  1.0000e+00]]])\n",
      "        \n",
      "        .. _Moore-Penrose inverse: https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse\n",
      "        \n",
      "        .. _[1]: https://epubs.siam.org/doi/10.1137/0117004\n",
      "        \n",
      "        .. _[2]: https://www.jstor.org/stable/2156365\n",
      "    \n",
      "    pixel_shuffle(...)\n",
      "        pixel_shuffle(input, upscale_factor) -> Tensor\n",
      "        \n",
      "        Rearranges elements in a tensor of shape :math:`(*, C \\times r^2, H, W)` to a\n",
      "        tensor of shape :math:`(*, C, H \\times r, W \\times r)`, where r is the :attr:`upscale_factor`.\n",
      "        \n",
      "        See :class:`~torch.nn.PixelShuffle` for details.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor\n",
      "            upscale_factor (int): factor to increase spatial resolution by\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> input = torch.randn(1, 9, 4, 4)\n",
      "            >>> output = torch.nn.functional.pixel_shuffle(input, 3)\n",
      "            >>> print(output.size())\n",
      "            torch.Size([1, 1, 12, 12])\n",
      "    \n",
      "    pixel_unshuffle(...)\n",
      "        pixel_unshuffle(input, downscale_factor) -> Tensor\n",
      "        \n",
      "        Reverses the :class:`~torch.nn.PixelShuffle` operation by rearranging elements in a\n",
      "        tensor of shape :math:`(*, C, H \\times r, W \\times r)` to a tensor of shape\n",
      "        :math:`(*, C \\times r^2, H, W)`, where r is the :attr:`downscale_factor`.\n",
      "        \n",
      "        See :class:`~torch.nn.PixelUnshuffle` for details.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor\n",
      "            downscale_factor (int): factor to increase spatial resolution by\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> input = torch.randn(1, 1, 12, 12)\n",
      "            >>> output = torch.nn.functional.pixel_unshuffle(input, 3)\n",
      "            >>> print(output.size())\n",
      "            torch.Size([1, 9, 4, 4])\n",
      "    \n",
      "    poisson(...)\n",
      "        poisson(input, generator=None) -> Tensor\n",
      "        \n",
      "        Returns a tensor of the same size as :attr:`input` with each element\n",
      "        sampled from a Poisson distribution with rate parameter given by the corresponding\n",
      "        element in :attr:`input` i.e.,\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i \\sim \\text{Poisson}(\\text{input}_i)\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor containing the rates of the Poisson distribution\n",
      "        \n",
      "        Keyword args:\n",
      "            generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> rates = torch.rand(4, 4) * 5  # rate parameter between 0 and 5\n",
      "            >>> torch.poisson(rates)\n",
      "            tensor([[9., 1., 3., 5.],\n",
      "                    [8., 6., 6., 0.],\n",
      "                    [0., 4., 5., 3.],\n",
      "                    [2., 1., 4., 2.]])\n",
      "    \n",
      "    poisson_nll_loss(...)\n",
      "    \n",
      "    polar(...)\n",
      "        polar(abs, angle, *, out=None) -> Tensor\n",
      "        \n",
      "        Constructs a complex tensor whose elements are Cartesian coordinates\n",
      "        corresponding to the polar coordinates with absolute value :attr:`abs` and angle\n",
      "        :attr:`angle`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out} = \\text{abs} \\cdot \\cos(\\text{angle}) + \\text{abs} \\cdot \\sin(\\text{angle}) \\cdot j\n",
      "        \n",
      "        Args:\n",
      "            abs (Tensor): The absolute value the complex tensor. Must be float or\n",
      "                double.\n",
      "            angle (Tensor): The angle of the complex tensor. Must be same dtype as\n",
      "                :attr:`abs`.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor): If the inputs are ``torch.float32``, must be\n",
      "                ``torch.complex64``. If the inputs are ``torch.float64``, must be\n",
      "                ``torch.complex128``.\n",
      "        \n",
      "        Example::\n",
      "            >>> import numpy as np\n",
      "            >>> abs = torch.tensor([1, 2], dtype=torch.float64)\n",
      "            >>> angle = torch.tensor([np.pi / 2, 5 * np.pi / 4], dtype=torch.float64)\n",
      "            >>> z = torch.polar(abs, angle)\n",
      "            >>> z\n",
      "            tensor([(0.0000+1.0000j), (-1.4142-1.4142j)], dtype=torch.complex128)\n",
      "    \n",
      "    polygamma(...)\n",
      "        polygamma(n, input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the :math:`n^{th}` derivative of the digamma function on :attr:`input`.\n",
      "        :math:`n \\geq 0` is called the order of the polygamma function.\n",
      "        \n",
      "        .. math::\n",
      "            \\psi^{(n)}(x) = \\frac{d^{(n)}}{dx^{(n)}} \\psi(x)\n",
      "        \n",
      "        .. note::\n",
      "            This function is implemented only for nonnegative integers :math:`n \\geq 0`.\n",
      "        \n",
      "        Args:\n",
      "            n (int): the order of the polygamma function\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> a = torch.tensor([1, 0.5])\n",
      "            >>> torch.polygamma(1, a)\n",
      "            tensor([1.64493, 4.9348])\n",
      "            >>> torch.polygamma(2, a)\n",
      "            tensor([ -2.4041, -16.8288])\n",
      "            >>> torch.polygamma(3, a)\n",
      "            tensor([ 6.4939, 97.4091])\n",
      "            >>> torch.polygamma(4, a)\n",
      "            tensor([ -24.8863, -771.4742])\n",
      "    \n",
      "    pow(...)\n",
      "        pow(input, exponent, *, out=None) -> Tensor\n",
      "        \n",
      "        Takes the power of each element in :attr:`input` with :attr:`exponent` and\n",
      "        returns a tensor with the result.\n",
      "        \n",
      "        :attr:`exponent` can be either a single ``float`` number or a `Tensor`\n",
      "        with the same number of elements as :attr:`input`.\n",
      "        \n",
      "        When :attr:`exponent` is a scalar value, the operation applied is:\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = x_i ^ \\text{exponent}\n",
      "        \n",
      "        When :attr:`exponent` is a tensor, the operation applied is:\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = x_i ^ {\\text{exponent}_i}\n",
      "        \n",
      "        When :attr:`exponent` is a tensor, the shapes of :attr:`input`\n",
      "        and :attr:`exponent` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            exponent (float or tensor): the exponent value\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.4331,  1.2475,  0.6834, -0.2791])\n",
      "            >>> torch.pow(a, 2)\n",
      "            tensor([ 0.1875,  1.5561,  0.4670,  0.0779])\n",
      "            >>> exp = torch.arange(1., 5.)\n",
      "        \n",
      "            >>> a = torch.arange(1., 5.)\n",
      "            >>> a\n",
      "            tensor([ 1.,  2.,  3.,  4.])\n",
      "            >>> exp\n",
      "            tensor([ 1.,  2.,  3.,  4.])\n",
      "            >>> torch.pow(a, exp)\n",
      "            tensor([   1.,    4.,   27.,  256.])\n",
      "        \n",
      "        .. function:: pow(self, exponent, *, out=None) -> Tensor\n",
      "        \n",
      "        :attr:`self` is a scalar ``float`` value, and :attr:`exponent` is a tensor.\n",
      "        The returned tensor :attr:`out` is of the same shape as :attr:`exponent`\n",
      "        \n",
      "        The operation applied is:\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = \\text{self} ^ {\\text{exponent}_i}\n",
      "        \n",
      "        Args:\n",
      "            self (float): the scalar base value for the power operation\n",
      "            exponent (Tensor): the exponent tensor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> exp = torch.arange(1., 5.)\n",
      "            >>> base = 2\n",
      "            >>> torch.pow(base, exp)\n",
      "            tensor([  2.,   4.,   8.,  16.])\n",
      "    \n",
      "    prelu(...)\n",
      "    \n",
      "    prod(...)\n",
      "        prod(input, *, dtype=None) -> Tensor\n",
      "        \n",
      "        Returns the product of all elements in the :attr:`input` tensor.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "                is performed. This is useful for preventing data type overflows. Default: None.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 3)\n",
      "            >>> a\n",
      "            tensor([[-0.8020,  0.5428, -1.5854]])\n",
      "            >>> torch.prod(a)\n",
      "            tensor(0.6902)\n",
      "        \n",
      "        .. function:: prod(input, dim, keepdim=False, *, dtype=None) -> Tensor\n",
      "        \n",
      "        Returns the product of each row of the :attr:`input` tensor in the given\n",
      "        dimension :attr:`dim`.\n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "        as :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
      "        the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the dimension to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "                is performed. This is useful for preventing data type overflows. Default: None.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 2)\n",
      "            >>> a\n",
      "            tensor([[ 0.5261, -0.3837],\n",
      "                    [ 1.1857, -0.2498],\n",
      "                    [-1.1646,  0.0705],\n",
      "                    [ 1.1131, -1.0629]])\n",
      "            >>> torch.prod(a, 1)\n",
      "            tensor([-0.2018, -0.2962, -0.0821, -1.1831])\n",
      "    \n",
      "    promote_types(...)\n",
      "        promote_types(type1, type2) -> dtype\n",
      "        \n",
      "        Returns the :class:`torch.dtype` with the smallest size and scalar kind that is\n",
      "        not smaller nor of lower kind than either `type1` or `type2`. See type promotion\n",
      "        :ref:`documentation <type-promotion-doc>` for more information on the type\n",
      "        promotion logic.\n",
      "        \n",
      "        Args:\n",
      "            type1 (:class:`torch.dtype`)\n",
      "            type2 (:class:`torch.dtype`)\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.promote_types(torch.int32, torch.float32)\n",
      "            torch.float32\n",
      "            >>> torch.promote_types(torch.uint8, torch.long)\n",
      "            torch.long\n",
      "    \n",
      "    q_per_channel_axis(...)\n",
      "    \n",
      "    q_per_channel_scales(...)\n",
      "    \n",
      "    q_per_channel_zero_points(...)\n",
      "    \n",
      "    q_scale(...)\n",
      "    \n",
      "    q_zero_point(...)\n",
      "    \n",
      "    qr(...)\n",
      "        qr(input, some=True, *, out=None) -> (Tensor, Tensor)\n",
      "        \n",
      "        Computes the QR decomposition of a matrix or a batch of matrices :attr:`input`,\n",
      "        and returns a namedtuple (Q, R) of tensors such that :math:`\\text{input} = Q R`\n",
      "        with :math:`Q` being an orthogonal matrix or batch of orthogonal matrices and\n",
      "        :math:`R` being an upper triangular matrix or batch of upper triangular matrices.\n",
      "        \n",
      "        If :attr:`some` is ``True``, then this function returns the thin (reduced) QR factorization.\n",
      "        Otherwise, if :attr:`some` is ``False``, this function returns the complete QR factorization.\n",
      "        \n",
      "        .. warning:: ``torch.qr`` is deprecated. Please use :func:`torch.linalg.qr`\n",
      "                     instead.\n",
      "        \n",
      "                     **Differences with** ``torch.linalg.qr``:\n",
      "        \n",
      "                     * ``torch.linalg.qr`` takes a string parameter ``mode`` instead of ``some``:\n",
      "        \n",
      "                       - ``some=True`` is equivalent of ``mode='reduced'``: both are the\n",
      "                         default\n",
      "        \n",
      "                       - ``some=False`` is equivalent of ``mode='complete'``.\n",
      "        \n",
      "        \n",
      "        .. warning::\n",
      "                  If you plan to backpropagate through QR, note that the current backward implementation\n",
      "                  is only well-defined when the first :math:`\\min(input.size(-1), input.size(-2))`\n",
      "                  columns of :attr:`input` are linearly independent.\n",
      "                  This behavior will propably change once QR supports pivoting.\n",
      "        \n",
      "        .. note:: This function uses LAPACK for CPU inputs and MAGMA for CUDA inputs,\n",
      "                  and may produce different (valid) decompositions on different device types\n",
      "                  or different platforms.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor of size :math:`(*, m, n)` where `*` is zero or more\n",
      "                        batch dimensions consisting of matrices of dimension :math:`m \\times n`.\n",
      "            some (bool, optional): Set to ``True`` for reduced QR decomposition and ``False`` for\n",
      "                        complete QR decomposition. If `k = min(m, n)` then:\n",
      "        \n",
      "                          * ``some=True`` : returns `(Q, R)` with dimensions (m, k), (k, n) (default)\n",
      "        \n",
      "                          * ``'some=False'``: returns `(Q, R)` with dimensions (m, m), (m, n)\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): tuple of `Q` and `R` tensors.\n",
      "                        The dimensions of `Q` and `R` are detailed in the description of :attr:`some` above.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([[12., -51, 4], [6, 167, -68], [-4, 24, -41]])\n",
      "            >>> q, r = torch.qr(a)\n",
      "            >>> q\n",
      "            tensor([[-0.8571,  0.3943,  0.3314],\n",
      "                    [-0.4286, -0.9029, -0.0343],\n",
      "                    [ 0.2857, -0.1714,  0.9429]])\n",
      "            >>> r\n",
      "            tensor([[ -14.0000,  -21.0000,   14.0000],\n",
      "                    [   0.0000, -175.0000,   70.0000],\n",
      "                    [   0.0000,    0.0000,  -35.0000]])\n",
      "            >>> torch.mm(q, r).round()\n",
      "            tensor([[  12.,  -51.,    4.],\n",
      "                    [   6.,  167.,  -68.],\n",
      "                    [  -4.,   24.,  -41.]])\n",
      "            >>> torch.mm(q.t(), q).round()\n",
      "            tensor([[ 1.,  0.,  0.],\n",
      "                    [ 0.,  1., -0.],\n",
      "                    [ 0., -0.,  1.]])\n",
      "            >>> a = torch.randn(3, 4, 5)\n",
      "            >>> q, r = torch.qr(a, some=False)\n",
      "            >>> torch.allclose(torch.matmul(q, r), a)\n",
      "            True\n",
      "            >>> torch.allclose(torch.matmul(q.transpose(-2, -1), q), torch.eye(5))\n",
      "            True\n",
      "    \n",
      "    quantile(...)\n",
      "        quantile(input, q) -> Tensor\n",
      "        \n",
      "        Returns the q-th quantiles of all elements in the :attr:`input` tensor, doing a linear\n",
      "        interpolation when the q-th quantile lies between two data points.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            q (float or Tensor): a scalar or 1D tensor of quantile values in the range [0, 1]\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 3)\n",
      "            >>> a\n",
      "            tensor([[ 0.0700, -0.5446,  0.9214]])\n",
      "            >>> q = torch.tensor([0, 0.5, 1])\n",
      "            >>> torch.quantile(a, q)\n",
      "            tensor([-0.5446,  0.0700,  0.9214])\n",
      "        \n",
      "        .. function:: quantile(input, q, dim=None, keepdim=False, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns the q-th quantiles of each row of the :attr:`input` tensor along the dimension\n",
      "        :attr:`dim`, doing a linear interpolation when the q-th quantile lies between two\n",
      "        data points. By default, :attr:`dim` is ``None`` resulting in the :attr:`input` tensor\n",
      "        being flattened before computation.\n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output dimensions are of the same size as :attr:`input`\n",
      "        except in the dimensions being reduced (:attr:`dim` or all if :attr:`dim` is ``None``) where they\n",
      "        have size 1. Otherwise, the dimensions being reduced are squeezed (see :func:`torch.squeeze`).\n",
      "        If :attr:`q` is a 1D tensor, an extra dimension is prepended to the output tensor with the same\n",
      "        size as :attr:`q` which represents the quantiles.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            q (float or Tensor): a scalar or 1D tensor of quantile values in the range [0, 1]\n",
      "            dim (int): the dimension to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(2, 3)\n",
      "            >>> a\n",
      "            tensor([[ 0.0795, -1.2117,  0.9765],\n",
      "                    [ 1.1707,  0.6706,  0.4884]])\n",
      "            >>> q = torch.tensor([0.25, 0.5, 0.75])\n",
      "            >>> torch.quantile(a, q, dim=1, keepdim=True)\n",
      "            tensor([[[-0.5661],\n",
      "                    [ 0.5795]],\n",
      "        \n",
      "                    [[ 0.0795],\n",
      "                    [ 0.6706]],\n",
      "        \n",
      "                    [[ 0.5280],\n",
      "                    [ 0.9206]]])\n",
      "            >>> torch.quantile(a, q, dim=1, keepdim=True).shape\n",
      "            torch.Size([3, 2, 1])\n",
      "    \n",
      "    quantize_per_channel(...)\n",
      "        quantize_per_channel(input, scales, zero_points, axis, dtype) -> Tensor\n",
      "        \n",
      "        Converts a float tensor to a per-channel quantized tensor with given scales and zero points.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): float tensor to quantize\n",
      "            scales (Tensor): float 1D tensor of scales to use, size should match ``input.size(axis)``\n",
      "            zero_points (int): integer 1D tensor of offset to use, size should match ``input.size(axis)``\n",
      "            axis (int): dimension on which apply per-channel quantization\n",
      "            dtype (:class:`torch.dtype`): the desired data type of returned tensor.\n",
      "                Has to be one of the quantized dtypes: ``torch.quint8``, ``torch.qint8``, ``torch.qint32``\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A newly quantized tensor\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.tensor([[-1.0, 0.0], [1.0, 2.0]])\n",
      "            >>> torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8)\n",
      "            tensor([[-1.,  0.],\n",
      "                    [ 1.,  2.]], size=(2, 2), dtype=torch.quint8,\n",
      "                   quantization_scheme=torch.per_channel_affine,\n",
      "                   scale=tensor([0.1000, 0.0100], dtype=torch.float64),\n",
      "                   zero_point=tensor([10,  0]), axis=0)\n",
      "            >>> torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8).int_repr()\n",
      "            tensor([[  0,  10],\n",
      "                    [100, 200]], dtype=torch.uint8)\n",
      "    \n",
      "    quantize_per_tensor(...)\n",
      "        quantize_per_tensor(input, scale, zero_point, dtype) -> Tensor\n",
      "        \n",
      "        Converts a float tensor to a quantized tensor with given scale and zero point.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): float tensor to quantize\n",
      "            scale (float): scale to apply in quantization formula\n",
      "            zero_point (int): offset in integer value that maps to float zero\n",
      "            dtype (:class:`torch.dtype`): the desired data type of returned tensor.\n",
      "                Has to be one of the quantized dtypes: ``torch.quint8``, ``torch.qint8``, ``torch.qint32``\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A newly quantized tensor\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8)\n",
      "            tensor([-1.,  0.,  1.,  2.], size=(4,), dtype=torch.quint8,\n",
      "                   quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10)\n",
      "            >>> torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8).int_repr()\n",
      "            tensor([ 0, 10, 20, 30], dtype=torch.uint8)\n",
      "    \n",
      "    quantized_batch_norm(...)\n",
      "    \n",
      "    quantized_gru_cell(...)\n",
      "    \n",
      "    quantized_lstm_cell(...)\n",
      "    \n",
      "    quantized_max_pool1d(...)\n",
      "    \n",
      "    quantized_max_pool2d(...)\n",
      "    \n",
      "    quantized_rnn_relu_cell(...)\n",
      "    \n",
      "    quantized_rnn_tanh_cell(...)\n",
      "    \n",
      "    rad2deg(...)\n",
      "        rad2deg(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with each of the elements of :attr:`input`\n",
      "        converted from angles in radians to degrees.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword arguments:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([[3.142, -3.142], [6.283, -6.283], [1.570, -1.570]])\n",
      "            >>> torch.rad2deg(a)\n",
      "            tensor([[ 180.0233, -180.0233],\n",
      "                    [ 359.9894, -359.9894],\n",
      "                    [  89.9544,  -89.9544]])\n",
      "    \n",
      "    rad2deg_(...)\n",
      "    \n",
      "    rand(...)\n",
      "        rand(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with random numbers from a uniform distribution\n",
      "        on the interval :math:`[0, 1)`\n",
      "        \n",
      "        The shape of the tensor is defined by the variable argument :attr:`size`.\n",
      "        \n",
      "        Args:\n",
      "            size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "                Can be a variable number of arguments or a collection like a list or tuple.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.rand(4)\n",
      "            tensor([ 0.5204,  0.2503,  0.3525,  0.5673])\n",
      "            >>> torch.rand(2, 3)\n",
      "            tensor([[ 0.8237,  0.5781,  0.6879],\n",
      "                    [ 0.3816,  0.7249,  0.0998]])\n",
      "    \n",
      "    rand_like(...)\n",
      "        rand_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) -> Tensor\n",
      "        \n",
      "        Returns a tensor with the same size as :attr:`input` that is filled with\n",
      "        random numbers from a uniform distribution on the interval :math:`[0, 1)`.\n",
      "        ``torch.rand_like(input)`` is equivalent to\n",
      "        ``torch.rand(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the size of :attr:`input` will determine size of the output tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned Tensor.\n",
      "                Default: if ``None``, defaults to the dtype of :attr:`input`.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned tensor.\n",
      "                Default: if ``None``, defaults to the layout of :attr:`input`.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, defaults to the device of :attr:`input`.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "            memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "                returned Tensor. Default: ``torch.preserve_format``.\n",
      "    \n",
      "    randint(...)\n",
      "        randint(low=0, high, size, \\*, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with random integers generated uniformly\n",
      "        between :attr:`low` (inclusive) and :attr:`high` (exclusive).\n",
      "        \n",
      "        The shape of the tensor is defined by the variable argument :attr:`size`.\n",
      "        \n",
      "        .. note::\n",
      "            With the global dtype default (``torch.float32``), this function returns\n",
      "            a tensor with dtype ``torch.int64``.\n",
      "        \n",
      "        Args:\n",
      "            low (int, optional): Lowest integer to be drawn from the distribution. Default: 0.\n",
      "            high (int): One above the highest integer to be drawn from the distribution.\n",
      "            size (tuple): a tuple defining the shape of the output tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.randint(3, 5, (3,))\n",
      "            tensor([4, 3, 4])\n",
      "        \n",
      "        \n",
      "            >>> torch.randint(10, (2, 2))\n",
      "            tensor([[0, 2],\n",
      "                    [5, 5]])\n",
      "        \n",
      "        \n",
      "            >>> torch.randint(3, 10, (2, 2))\n",
      "            tensor([[4, 5],\n",
      "                    [6, 7]])\n",
      "    \n",
      "    randint_like(...)\n",
      "        randint_like(input, low=0, high, \\*, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format) -> Tensor\n",
      "        \n",
      "        Returns a tensor with the same shape as Tensor :attr:`input` filled with\n",
      "        random integers generated uniformly between :attr:`low` (inclusive) and\n",
      "        :attr:`high` (exclusive).\n",
      "        \n",
      "        .. note:\n",
      "            With the global dtype default (``torch.float32``), this function returns\n",
      "            a tensor with dtype ``torch.int64``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the size of :attr:`input` will determine size of the output tensor.\n",
      "            low (int, optional): Lowest integer to be drawn from the distribution. Default: 0.\n",
      "            high (int): One above the highest integer to be drawn from the distribution.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned Tensor.\n",
      "                Default: if ``None``, defaults to the dtype of :attr:`input`.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned tensor.\n",
      "                Default: if ``None``, defaults to the layout of :attr:`input`.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, defaults to the device of :attr:`input`.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "            memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "                returned Tensor. Default: ``torch.preserve_format``.\n",
      "    \n",
      "    randn(...)\n",
      "        randn(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with random numbers from a normal distribution\n",
      "        with mean `0` and variance `1` (also called the standard normal\n",
      "        distribution).\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} \\sim \\mathcal{N}(0, 1)\n",
      "        \n",
      "        The shape of the tensor is defined by the variable argument :attr:`size`.\n",
      "        \n",
      "        Args:\n",
      "            size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "                Can be a variable number of arguments or a collection like a list or tuple.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.randn(4)\n",
      "            tensor([-2.1436,  0.9966,  2.3426, -0.6366])\n",
      "            >>> torch.randn(2, 3)\n",
      "            tensor([[ 1.5954,  2.8929, -1.0923],\n",
      "                    [ 1.1719, -0.4709, -0.1996]])\n",
      "    \n",
      "    randn_like(...)\n",
      "        randn_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) -> Tensor\n",
      "        \n",
      "        Returns a tensor with the same size as :attr:`input` that is filled with\n",
      "        random numbers from a normal distribution with mean 0 and variance 1.\n",
      "        ``torch.randn_like(input)`` is equivalent to\n",
      "        ``torch.randn(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the size of :attr:`input` will determine size of the output tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned Tensor.\n",
      "                Default: if ``None``, defaults to the dtype of :attr:`input`.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned tensor.\n",
      "                Default: if ``None``, defaults to the layout of :attr:`input`.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, defaults to the device of :attr:`input`.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "            memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "                returned Tensor. Default: ``torch.preserve_format``.\n",
      "    \n",
      "    randperm(...)\n",
      "        randperm(n, *, generator=None, out=None, dtype=torch.int64,layout=torch.strided, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
      "        \n",
      "        Returns a random permutation of integers from ``0`` to ``n - 1``.\n",
      "        \n",
      "        Args:\n",
      "            n (int): the upper bound (exclusive)\n",
      "        \n",
      "        Keyword args:\n",
      "            generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: ``torch.int64``.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "            pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
      "                the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.randperm(4)\n",
      "            tensor([2, 1, 0, 3])\n",
      "    \n",
      "    range(...)\n",
      "        range(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a 1-D tensor of size :math:`\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1`\n",
      "        with values from :attr:`start` to :attr:`end` with step :attr:`step`. Step is\n",
      "        the gap between two values in the tensor.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i+1} = \\text{out}_i + \\text{step}.\n",
      "        \n",
      "        .. warning::\n",
      "            This function is deprecated and will be removed in a future release because its behavior is inconsistent with\n",
      "            Python's range builtin. Instead, use :func:`torch.arange`, which produces values in [start, end).\n",
      "        \n",
      "        Args:\n",
      "            start (float): the starting value for the set of points. Default: ``0``.\n",
      "            end (float): the ending value for the set of points\n",
      "            step (float): the gap between each pair of adjacent points. Default: ``1``.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`). If `dtype` is not given, infer the data type from the other input\n",
      "                arguments. If any of `start`, `end`, or `stop` are floating-point, the\n",
      "                `dtype` is inferred to be the default dtype, see\n",
      "                :meth:`~torch.get_default_dtype`. Otherwise, the `dtype` is inferred to\n",
      "                be `torch.int64`.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.range(1, 4)\n",
      "            tensor([ 1.,  2.,  3.,  4.])\n",
      "            >>> torch.range(1, 4, 0.5)\n",
      "            tensor([ 1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000])\n",
      "    \n",
      "    ravel(...)\n",
      "        ravel(input) -> Tensor\n",
      "        \n",
      "        Return a contiguous flattened tensor. A copy is made only if needed.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> t = torch.tensor([[[1, 2],\n",
      "            ...                    [3, 4]],\n",
      "            ...                   [[5, 6],\n",
      "            ...                    [7, 8]]])\n",
      "            >>> torch.ravel(t)\n",
      "            tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "    \n",
      "    real(...)\n",
      "        real(input) -> Tensor\n",
      "        \n",
      "        Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "        The returned tensor and :attr:`self` share the same underlying storage.\n",
      "        \n",
      "        .. warning::\n",
      "            :func:`real` is only supported for tensors with complex dtypes.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "            >>> x\n",
      "            tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "            >>> x.real\n",
      "            tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "    \n",
      "    reciprocal(...)\n",
      "        reciprocal(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the reciprocal of the elements of :attr:`input`\n",
      "        \n",
      "        .. note::\n",
      "            Unlike NumPy's reciprocal, torch.reciprocal supports integral inputs. Integral\n",
      "            inputs to reciprocal are automatically :ref:`promoted <type-promotion-doc>` to\n",
      "            the default scalar type.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\frac{1}{\\text{input}_{i}}\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-0.4595, -2.1219, -1.4314,  0.7298])\n",
      "            >>> torch.reciprocal(a)\n",
      "            tensor([-2.1763, -0.4713, -0.6986,  1.3702])\n",
      "    \n",
      "    reciprocal_(...)\n",
      "    \n",
      "    relu(...)\n",
      "    \n",
      "    relu_(...)\n",
      "        relu_(input) -> Tensor\n",
      "        \n",
      "        In-place version of :func:`~relu`.\n",
      "    \n",
      "    remainder(...)\n",
      "        remainder(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the element-wise remainder of division.\n",
      "        \n",
      "        The dividend and divisor may contain both for integer and floating point\n",
      "        numbers. The remainder has the same sign as the divisor :attr:`other`.\n",
      "        \n",
      "        Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`,\n",
      "        :ref:`type promotion <type-promotion-doc>`, and integer and float inputs.\n",
      "        \n",
      "        .. note::\n",
      "            Complex inputs are not supported. In some cases, it is not mathematically\n",
      "            possible to satisfy the definition of a modulo operation with complex numbers.\n",
      "            See :func:`torch.fmod` for how division by zero is handled.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the dividend\n",
      "            other (Tensor or Scalar): the divisor\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.remainder(torch.tensor([-3., -2, -1, 1, 2, 3]), 2)\n",
      "            tensor([ 1.,  0.,  1.,  1.,  0.,  1.])\n",
      "            >>> torch.remainder(torch.tensor([1, 2, 3, 4, 5]), 1.5)\n",
      "            tensor([ 1.0000,  0.5000,  0.0000,  1.0000,  0.5000])\n",
      "        \n",
      "        .. seealso::\n",
      "        \n",
      "                :func:`torch.fmod`, which computes the element-wise remainder of\n",
      "                division equivalently to the C library function ``fmod()``.\n",
      "    \n",
      "    renorm(...)\n",
      "        renorm(input, p, dim, maxnorm, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a tensor where each sub-tensor of :attr:`input` along dimension\n",
      "        :attr:`dim` is normalized such that the `p`-norm of the sub-tensor is lower\n",
      "        than the value :attr:`maxnorm`\n",
      "        \n",
      "        .. note:: If the norm of a row is lower than `maxnorm`, the row is unchanged\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            p (float): the power for the norm computation\n",
      "            dim (int): the dimension to slice over to get the sub-tensors\n",
      "            maxnorm (float): the maximum norm to keep each sub-tensor under\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.ones(3, 3)\n",
      "            >>> x[1].fill_(2)\n",
      "            tensor([ 2.,  2.,  2.])\n",
      "            >>> x[2].fill_(3)\n",
      "            tensor([ 3.,  3.,  3.])\n",
      "            >>> x\n",
      "            tensor([[ 1.,  1.,  1.],\n",
      "                    [ 2.,  2.,  2.],\n",
      "                    [ 3.,  3.,  3.]])\n",
      "            >>> torch.renorm(x, 1, 0, 5)\n",
      "            tensor([[ 1.0000,  1.0000,  1.0000],\n",
      "                    [ 1.6667,  1.6667,  1.6667],\n",
      "                    [ 1.6667,  1.6667,  1.6667]])\n",
      "    \n",
      "    repeat_interleave(...)\n",
      "        repeat_interleave(input, repeats, dim=None) -> Tensor\n",
      "        \n",
      "        Repeat elements of a tensor.\n",
      "        \n",
      "        .. warning::\n",
      "        \n",
      "            This is different from :meth:`torch.Tensor.repeat` but similar to ``numpy.repeat``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            repeats (Tensor or int): The number of repetitions for each element.\n",
      "                repeats is broadcasted to fit the shape of the given axis.\n",
      "            dim (int, optional): The dimension along which to repeat values.\n",
      "                By default, use the flattened input array, and return a flat output\n",
      "                array.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: Repeated tensor which has the same shape as input, except along the given axis.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.tensor([1, 2, 3])\n",
      "            >>> x.repeat_interleave(2)\n",
      "            tensor([1, 1, 2, 2, 3, 3])\n",
      "            >>> y = torch.tensor([[1, 2], [3, 4]])\n",
      "            >>> torch.repeat_interleave(y, 2)\n",
      "            tensor([1, 1, 2, 2, 3, 3, 4, 4])\n",
      "            >>> torch.repeat_interleave(y, 3, dim=1)\n",
      "            tensor([[1, 1, 1, 2, 2, 2],\n",
      "                    [3, 3, 3, 4, 4, 4]])\n",
      "            >>> torch.repeat_interleave(y, torch.tensor([1, 2]), dim=0)\n",
      "            tensor([[1, 2],\n",
      "                    [3, 4],\n",
      "                    [3, 4]])\n",
      "        \n",
      "        .. function:: repeat_interleave(repeats) -> Tensor\n",
      "        \n",
      "        If the `repeats` is `tensor([n1, n2, n3, ...])`, then the output will be\n",
      "        `tensor([0, 0, ..., 1, 1, ..., 2, 2, ..., ...])` where `0` appears `n1` times,\n",
      "        `1` appears `n2` times, `2` appears `n3` times, etc.\n",
      "    \n",
      "    reshape(...)\n",
      "        reshape(input, shape) -> Tensor\n",
      "        \n",
      "        Returns a tensor with the same data and number of elements as :attr:`input`,\n",
      "        but with the specified shape. When possible, the returned tensor will be a view\n",
      "        of :attr:`input`. Otherwise, it will be a copy. Contiguous inputs and inputs\n",
      "        with compatible strides can be reshaped without copying, but you should not\n",
      "        depend on the copying vs. viewing behavior.\n",
      "        \n",
      "        See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "        \n",
      "        A single dimension may be -1, in which case it's inferred from the remaining\n",
      "        dimensions and the number of elements in :attr:`input`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to be reshaped\n",
      "            shape (tuple of ints): the new shape\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.arange(4.)\n",
      "            >>> torch.reshape(a, (2, 2))\n",
      "            tensor([[ 0.,  1.],\n",
      "                    [ 2.,  3.]])\n",
      "            >>> b = torch.tensor([[0, 1], [2, 3]])\n",
      "            >>> torch.reshape(b, (-1,))\n",
      "            tensor([ 0,  1,  2,  3])\n",
      "    \n",
      "    resize_as_(...)\n",
      "    \n",
      "    result_type(...)\n",
      "        result_type(tensor1, tensor2) -> dtype\n",
      "        \n",
      "        Returns the :class:`torch.dtype` that would result from performing an arithmetic\n",
      "        operation on the provided input tensors. See type promotion :ref:`documentation <type-promotion-doc>`\n",
      "        for more information on the type promotion logic.\n",
      "        \n",
      "        Args:\n",
      "            tensor1 (Tensor or Number): an input tensor or number\n",
      "            tensor2 (Tensor or Number): an input tensor or number\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.result_type(torch.tensor([1, 2], dtype=torch.int), 1.0)\n",
      "            torch.float32\n",
      "            >>> torch.result_type(torch.tensor([1, 2], dtype=torch.uint8), torch.tensor(1))\n",
      "            torch.uint8\n",
      "    \n",
      "    rnn_relu(...)\n",
      "    \n",
      "    rnn_relu_cell(...)\n",
      "    \n",
      "    rnn_tanh(...)\n",
      "    \n",
      "    rnn_tanh_cell(...)\n",
      "    \n",
      "    roll(...)\n",
      "        roll(input, shifts, dims=None) -> Tensor\n",
      "        \n",
      "        Roll the tensor along the given dimension(s). Elements that are shifted beyond the\n",
      "        last position are re-introduced at the first position. If a dimension is not\n",
      "        specified, the tensor will be flattened before rolling and then restored\n",
      "        to the original shape.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            shifts (int or tuple of ints): The number of places by which the elements\n",
      "                of the tensor are shifted. If shifts is a tuple, dims must be a tuple of\n",
      "                the same size, and each dimension will be rolled by the corresponding\n",
      "                value\n",
      "            dims (int or tuple of ints): Axis along which to roll\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8]).view(4, 2)\n",
      "            >>> x\n",
      "            tensor([[1, 2],\n",
      "                    [3, 4],\n",
      "                    [5, 6],\n",
      "                    [7, 8]])\n",
      "            >>> torch.roll(x, 1, 0)\n",
      "            tensor([[7, 8],\n",
      "                    [1, 2],\n",
      "                    [3, 4],\n",
      "                    [5, 6]])\n",
      "            >>> torch.roll(x, -1, 0)\n",
      "            tensor([[3, 4],\n",
      "                    [5, 6],\n",
      "                    [7, 8],\n",
      "                    [1, 2]])\n",
      "            >>> torch.roll(x, shifts=(2, 1), dims=(0, 1))\n",
      "            tensor([[6, 5],\n",
      "                    [8, 7],\n",
      "                    [2, 1],\n",
      "                    [4, 3]])\n",
      "    \n",
      "    rot90(...)\n",
      "        rot90(input, k, dims) -> Tensor\n",
      "        \n",
      "        Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.\n",
      "        Rotation direction is from the first towards the second axis if k > 0, and from the second towards the first for k < 0.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            k (int): number of times to rotate\n",
      "            dims (a list or tuple): axis to rotate\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.arange(4).view(2, 2)\n",
      "            >>> x\n",
      "            tensor([[0, 1],\n",
      "                    [2, 3]])\n",
      "            >>> torch.rot90(x, 1, [0, 1])\n",
      "            tensor([[1, 3],\n",
      "                    [0, 2]])\n",
      "        \n",
      "            >>> x = torch.arange(8).view(2, 2, 2)\n",
      "            >>> x\n",
      "            tensor([[[0, 1],\n",
      "                     [2, 3]],\n",
      "        \n",
      "                    [[4, 5],\n",
      "                     [6, 7]]])\n",
      "            >>> torch.rot90(x, 1, [1, 2])\n",
      "            tensor([[[1, 3],\n",
      "                     [0, 2]],\n",
      "        \n",
      "                    [[5, 7],\n",
      "                     [4, 6]]])\n",
      "    \n",
      "    round(...)\n",
      "        round(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with each of the elements of :attr:`input` rounded\n",
      "        to the closest integer.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.9920,  0.6077,  0.9734, -1.0362])\n",
      "            >>> torch.round(a)\n",
      "            tensor([ 1.,  1.,  1., -1.])\n",
      "    \n",
      "    round_(...)\n",
      "    \n",
      "    row_stack(...)\n",
      "        row_stack(tensors, *, out=None) -> Tensor\n",
      "        \n",
      "        Alias of :func:`torch.vstack`.\n",
      "    \n",
      "    rrelu(...)\n",
      "    \n",
      "    rrelu_(...)\n",
      "        rrelu_(input, lower=1./8, upper=1./3, training=False) -> Tensor\n",
      "        \n",
      "        In-place version of :func:`~rrelu`.\n",
      "    \n",
      "    rsqrt(...)\n",
      "        rsqrt(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the reciprocal of the square-root of each of\n",
      "        the elements of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\frac{1}{\\sqrt{\\text{input}_{i}}}\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-0.0370,  0.2970,  1.5420, -0.9105])\n",
      "            >>> torch.rsqrt(a)\n",
      "            tensor([    nan,  1.8351,  0.8053,     nan])\n",
      "    \n",
      "    rsqrt_(...)\n",
      "    \n",
      "    rsub(...)\n",
      "    \n",
      "    saddmm(...)\n",
      "    \n",
      "    save(obj, f: Union[str, os.PathLike, BinaryIO, IO[bytes]], pickle_module=<module 'pickle' from 'd:\\\\anaconda\\\\envs\\\\pytorch\\\\lib\\\\pickle.py'>, pickle_protocol=2, _use_new_zipfile_serialization=True) -> None\n",
      "        Saves an object to a disk file.\n",
      "        \n",
      "        See also: `saving-loading-tensors`\n",
      "        \n",
      "        Args:\n",
      "            obj: saved object\n",
      "            f: a file-like object (has to implement write and flush) or a string or\n",
      "               os.PathLike object containing a file name\n",
      "            pickle_module: module used for pickling metadata and objects\n",
      "            pickle_protocol: can be specified to override the default protocol\n",
      "        \n",
      "        .. note::\n",
      "            A common PyTorch convention is to save tensors using .pt file extension.\n",
      "        \n",
      "        .. note::\n",
      "            PyTorch preserves storage sharing across serialization. See\n",
      "            `preserve-storage-sharing` for more details.\n",
      "        \n",
      "        .. note::\n",
      "            The 1.6 release of PyTorch switched ``torch.save`` to use a new\n",
      "            zipfile-based file format. ``torch.load`` still retains the ability to\n",
      "            load files in the old format. If for any reason you want ``torch.save``\n",
      "            to use the old format, pass the kwarg ``_use_new_zipfile_serialization=False``.\n",
      "        \n",
      "        Example:\n",
      "            >>> # Save to file\n",
      "            >>> x = torch.tensor([0, 1, 2, 3, 4])\n",
      "            >>> torch.save(x, 'tensor.pt')\n",
      "            >>> # Save to io.BytesIO buffer\n",
      "            >>> buffer = io.BytesIO()\n",
      "            >>> torch.save(x, buffer)\n",
      "    \n",
      "    scalar_tensor(...)\n",
      "    \n",
      "    scatter(...)\n",
      "        scatter(input, dim, index, src) -> Tensor\n",
      "        \n",
      "        Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "    \n",
      "    scatter_add(...)\n",
      "        scatter_add(input, dim, index, src) -> Tensor\n",
      "        \n",
      "        Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "    \n",
      "    searchsorted(...)\n",
      "        searchsorted(sorted_sequence, values, *, out_int32=False, right=False, out=None) -> Tensor\n",
      "        \n",
      "        Find the indices from the *innermost* dimension of :attr:`sorted_sequence` such that, if the\n",
      "        corresponding values in :attr:`values` were inserted before the indices, the order of the\n",
      "        corresponding *innermost* dimension within :attr:`sorted_sequence` would be preserved.\n",
      "        Return a new tensor with the same size as :attr:`values`. If :attr:`right` is False (default),\n",
      "        then the left boundary of :attr:`sorted_sequence` is closed. More formally, the returned index\n",
      "        satisfies the following rules:\n",
      "        \n",
      "        .. list-table::\n",
      "           :widths: 12 10 78\n",
      "           :header-rows: 1\n",
      "        \n",
      "           * - :attr:`sorted_sequence`\n",
      "             - :attr:`right`\n",
      "             - *returned index satisfies*\n",
      "           * - 1-D\n",
      "             - False\n",
      "             - ``sorted_sequence[i-1] < values[m][n]...[l][x] <= sorted_sequence[i]``\n",
      "           * - 1-D\n",
      "             - True\n",
      "             - ``sorted_sequence[i-1] <= values[m][n]...[l][x] < sorted_sequence[i]``\n",
      "           * - N-D\n",
      "             - False\n",
      "             - ``sorted_sequence[m][n]...[l][i-1] < values[m][n]...[l][x] <= sorted_sequence[m][n]...[l][i]``\n",
      "           * - N-D\n",
      "             - True\n",
      "             - ``sorted_sequence[m][n]...[l][i-1] <= values[m][n]...[l][x] < sorted_sequence[m][n]...[l][i]``\n",
      "        \n",
      "        Args:\n",
      "            sorted_sequence (Tensor): N-D or 1-D tensor, containing monotonically increasing sequence on the *innermost*\n",
      "                                      dimension.\n",
      "            values (Tensor or Scalar): N-D tensor or a Scalar containing the search value(s).\n",
      "        \n",
      "        Keyword args:\n",
      "            out_int32 (bool, optional): indicate the output data type. torch.int32 if True, torch.int64 otherwise.\n",
      "                                        Default value is False, i.e. default output data type is torch.int64.\n",
      "            right (bool, optional): if False, return the first suitable location that is found. If True, return the\n",
      "                                    last such index. If no suitable index found, return 0 for non-numerical value\n",
      "                                    (eg. nan, inf) or the size of *innermost* dimension within :attr:`sorted_sequence`\n",
      "                                    (one pass the last index of the *innermost* dimension). In other words, if False,\n",
      "                                    gets the lower bound index for each value in :attr:`values` on the corresponding\n",
      "                                    *innermost* dimension of the :attr:`sorted_sequence`. If True, gets the upper\n",
      "                                    bound index instead. Default value is False.\n",
      "            out (Tensor, optional): the output tensor, must be the same size as :attr:`values` if provided.\n",
      "        \n",
      "        .. note:: If your use case is always 1-D sorted sequence, :func:`torch.bucketize` is preferred,\n",
      "                  because it has fewer dimension checks resulting in slightly better performance.\n",
      "        \n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> sorted_sequence = torch.tensor([[1, 3, 5, 7, 9], [2, 4, 6, 8, 10]])\n",
      "            >>> sorted_sequence\n",
      "            tensor([[ 1,  3,  5,  7,  9],\n",
      "                    [ 2,  4,  6,  8, 10]])\n",
      "            >>> values = torch.tensor([[3, 6, 9], [3, 6, 9]])\n",
      "            >>> values\n",
      "            tensor([[3, 6, 9],\n",
      "                    [3, 6, 9]])\n",
      "            >>> torch.searchsorted(sorted_sequence, values)\n",
      "            tensor([[1, 3, 4],\n",
      "                    [1, 2, 4]])\n",
      "            >>> torch.searchsorted(sorted_sequence, values, right=True)\n",
      "            tensor([[2, 3, 5],\n",
      "                    [1, 3, 4]])\n",
      "        \n",
      "            >>> sorted_sequence_1d = torch.tensor([1, 3, 5, 7, 9])\n",
      "            >>> sorted_sequence_1d\n",
      "            tensor([1, 3, 5, 7, 9])\n",
      "            >>> torch.searchsorted(sorted_sequence_1d, values)\n",
      "            tensor([[1, 3, 4],\n",
      "                    [1, 3, 4]])\n",
      "    \n",
      "    seed() -> int\n",
      "        Sets the seed for generating random numbers to a non-deterministic\n",
      "        random number. Returns a 64 bit number used to seed the RNG.\n",
      "    \n",
      "    select(...)\n",
      "    \n",
      "    selu(...)\n",
      "    \n",
      "    selu_(...)\n",
      "        selu_(input) -> Tensor\n",
      "        \n",
      "        In-place version of :func:`~selu`.\n",
      "    \n",
      "    set_anomaly_enabled(...)\n",
      "    \n",
      "    set_autocast_enabled(...)\n",
      "    \n",
      "    set_default_tensor_type(t)\n",
      "        Sets the default ``torch.Tensor`` type to floating point tensor type\n",
      "        ``t``. This type will also be used as default floating point type for\n",
      "        type inference in :func:`torch.tensor`.\n",
      "        \n",
      "        The default floating point tensor type is initially ``torch.FloatTensor``.\n",
      "        \n",
      "        Args:\n",
      "            t (type or string): the floating point tensor type or its name\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.tensor([1.2, 3]).dtype    # initial default for floating point is torch.float32\n",
      "            torch.float32\n",
      "            >>> torch.set_default_tensor_type(torch.DoubleTensor)\n",
      "            >>> torch.tensor([1.2, 3]).dtype    # a new floating point tensor\n",
      "            torch.float64\n",
      "    \n",
      "    set_deterministic(d)\n",
      "        This function is deprecated and will be removed in a future release.\n",
      "        Please use :func:`torch.use_deterministic_algorithms` instead.\n",
      "    \n",
      "    set_flush_denormal(...)\n",
      "        set_flush_denormal(mode) -> bool\n",
      "        \n",
      "        Disables denormal floating numbers on CPU.\n",
      "        \n",
      "        Returns ``True`` if your system supports flushing denormal numbers and it\n",
      "        successfully configures flush denormal mode.  :meth:`~torch.set_flush_denormal`\n",
      "        is only supported on x86 architectures supporting SSE3.\n",
      "        \n",
      "        Args:\n",
      "            mode (bool): Controls whether to enable flush denormal mode or not\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.set_flush_denormal(True)\n",
      "            True\n",
      "            >>> torch.tensor([1e-323], dtype=torch.float64)\n",
      "            tensor([ 0.], dtype=torch.float64)\n",
      "            >>> torch.set_flush_denormal(False)\n",
      "            True\n",
      "            >>> torch.tensor([1e-323], dtype=torch.float64)\n",
      "            tensor(9.88131e-324 *\n",
      "                   [ 1.0000], dtype=torch.float64)\n",
      "    \n",
      "    set_num_interop_threads(...)\n",
      "        set_num_interop_threads(int)\n",
      "        \n",
      "        Sets the number of threads used for interop parallelism\n",
      "        (e.g. in JIT interpreter) on CPU.\n",
      "        \n",
      "        .. warning::\n",
      "            Can only be called once and before any inter-op parallel work\n",
      "            is started (e.g. JIT execution).\n",
      "    \n",
      "    set_num_threads(...)\n",
      "        set_num_threads(int)\n",
      "        \n",
      "        Sets the number of threads used for intraop parallelism on CPU.\n",
      "        \n",
      "        .. warning::\n",
      "            To ensure that the correct number of threads is used, set_num_threads\n",
      "            must be called before running eager, JIT or autograd code.\n",
      "    \n",
      "    set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
      "        Set options for printing. Items shamelessly taken from NumPy\n",
      "        \n",
      "        Args:\n",
      "            precision: Number of digits of precision for floating point output\n",
      "                (default = 4).\n",
      "            threshold: Total number of array elements which trigger summarization\n",
      "                rather than full `repr` (default = 1000).\n",
      "            edgeitems: Number of array items in summary at beginning and end of\n",
      "                each dimension (default = 3).\n",
      "            linewidth: The number of characters per line for the purpose of\n",
      "                inserting line breaks (default = 80). Thresholded matrices will\n",
      "                ignore this parameter.\n",
      "            profile: Sane defaults for pretty printing. Can override with any of\n",
      "                the above options. (any one of `default`, `short`, `full`)\n",
      "            sci_mode: Enable (True) or disable (False) scientific notation. If\n",
      "                None (default) is specified, the value is defined by\n",
      "                `torch._tensor_str._Formatter`. This value is automatically chosen\n",
      "                by the framework.\n",
      "    \n",
      "    set_rng_state(new_state) -> None\n",
      "        Sets the random number generator state.\n",
      "        \n",
      "        Args:\n",
      "            new_state (torch.ByteTensor): The desired state\n",
      "    \n",
      "    sgn(...)\n",
      "        sgn(input, *, out=None) -> Tensor\n",
      "        \n",
      "        For complex tensors, this function returns a new tensor whose elemants have the same angle as that of the\n",
      "        elements of :attr:`input` and absolute value 1. For a non-complex tensor, this function\n",
      "        returns the signs of the elements of :attr:`input` (see :func:`torch.sign`).\n",
      "        \n",
      "        :math:`\\text{out}_{i} = 0`, if :math:`|{\\text{{input}}_i}| == 0`\n",
      "        :math:`\\text{out}_{i} = \\frac{{\\text{{input}}_i}}{|{\\text{{input}}_i}|}`, otherwise\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "          out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x=torch.tensor([3+4j, 7-24j, 0, 1+2j])\n",
      "            >>> x.sgn()\n",
      "            tensor([0.6000+0.8000j, 0.2800-0.9600j, 0.0000+0.0000j, 0.4472+0.8944j])\n",
      "    \n",
      "    sigmoid(...)\n",
      "        sigmoid(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the sigmoid of the elements of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\frac{1}{1 + e^{-\\text{input}_{i}}}\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.9213,  1.0887, -0.8858, -1.7683])\n",
      "            >>> torch.sigmoid(a)\n",
      "            tensor([ 0.7153,  0.7481,  0.2920,  0.1458])\n",
      "    \n",
      "    sigmoid_(...)\n",
      "    \n",
      "    sign(...)\n",
      "        sign(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the signs of the elements of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\operatorname{sgn}(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([0.7, -1.2, 0., 2.3])\n",
      "            >>> a\n",
      "            tensor([ 0.7000, -1.2000,  0.0000,  2.3000])\n",
      "            >>> torch.sign(a)\n",
      "            tensor([ 1., -1.,  0.,  1.])\n",
      "    \n",
      "    signbit(...)\n",
      "        signbit(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Tests if each element of :attr:`input` has its sign bit set (is less than zero) or not.\n",
      "        \n",
      "        Args:\n",
      "          input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "          out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([0.7, -1.2, 0., 2.3])\n",
      "            >>> torch.signbit(a)\n",
      "            tensor([ False, True,  False,  False])\n",
      "    \n",
      "    sin(...)\n",
      "        sin(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the sine of the elements of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\sin(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-0.5461,  0.1347, -2.7266, -0.2746])\n",
      "            >>> torch.sin(a)\n",
      "            tensor([-0.5194,  0.1343, -0.4032, -0.2711])\n",
      "    \n",
      "    sin_(...)\n",
      "    \n",
      "    sinc(...)\n",
      "        sinc(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the normalized sinc of :attr:`input.`\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} =\n",
      "            \\begin{cases}\n",
      "              1, & \\text{if}\\ \\text{input}_{i}=0 \\\\\n",
      "              \\sin(\\pi \\text{input}_{i}) / (\\pi \\text{input}_{i}), & \\text{otherwise}\n",
      "            \\end{cases}\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.2252, -0.2948,  1.0267, -1.1566])\n",
      "            >>> torch.sinc(a)\n",
      "            tensor([ 0.9186,  0.8631, -0.0259, -0.1300])\n",
      "    \n",
      "    sinc_(...)\n",
      "    \n",
      "    sinh(...)\n",
      "        sinh(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the hyperbolic sine of the elements of\n",
      "        :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\sinh(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.5380, -0.8632, -0.1265,  0.9399])\n",
      "            >>> torch.sinh(a)\n",
      "            tensor([ 0.5644, -0.9744, -0.1268,  1.0845])\n",
      "        \n",
      "        .. note::\n",
      "           When :attr:`input` is on the CPU, the implementation of torch.sinh may use\n",
      "           the Sleef library, which rounds very large results to infinity or negative\n",
      "           infinity. See `here <https://sleef.org/purec.xhtml>`_ for details.\n",
      "    \n",
      "    sinh_(...)\n",
      "    \n",
      "    slogdet(...)\n",
      "        slogdet(input) -> (Tensor, Tensor)\n",
      "        \n",
      "        Calculates the sign and log absolute value of the determinant(s) of a square matrix or batches of square matrices.\n",
      "        \n",
      "        .. note:: :func:`torch.slogdet` is deprecated. Please use :func:`torch.linalg.slogdet` instead.\n",
      "        \n",
      "        .. note::\n",
      "            If ``input`` has zero determinant, this returns ``(0, -inf)``.\n",
      "        \n",
      "        .. note::\n",
      "            Backward through :meth:`slogdet` internally uses SVD results when :attr:`input`\n",
      "            is not invertible. In this case, double backward through :meth:`slogdet`\n",
      "            will be unstable in when :attr:`input` doesn't have distinct singular values.\n",
      "            See :meth:`~torch.svd` for details.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): the input tensor of size ``(*, n, n)`` where ``*`` is zero or more\n",
      "                        batch dimensions.\n",
      "        \n",
      "        Returns:\n",
      "            A namedtuple (sign, logabsdet) containing the sign of the determinant, and the log\n",
      "            value of the absolute determinant.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> A = torch.randn(3, 3)\n",
      "            >>> A\n",
      "            tensor([[ 0.0032, -0.2239, -1.1219],\n",
      "                    [-0.6690,  0.1161,  0.4053],\n",
      "                    [-1.6218, -0.9273, -0.0082]])\n",
      "            >>> torch.det(A)\n",
      "            tensor(-0.7576)\n",
      "            >>> torch.logdet(A)\n",
      "            tensor(nan)\n",
      "            >>> torch.slogdet(A)\n",
      "            torch.return_types.slogdet(sign=tensor(-1.), logabsdet=tensor(-0.2776))\n",
      "    \n",
      "    smm(...)\n",
      "        smm(input, mat) -> Tensor\n",
      "        \n",
      "        Performs a matrix multiplication of the sparse matrix :attr:`input`\n",
      "        with the dense matrix :attr:`mat`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): a sparse matrix to be matrix multiplied\n",
      "            mat (Tensor): a dense matrix to be matrix multiplied\n",
      "    \n",
      "    softmax(...)\n",
      "    \n",
      "    solve(...)\n",
      "        torch.solve(input, A, *, out=None) -> (Tensor, Tensor)\n",
      "        \n",
      "        This function returns the solution to the system of linear\n",
      "        equations represented by :math:`AX = B` and the LU factorization of\n",
      "        A, in order as a namedtuple `solution, LU`.\n",
      "        \n",
      "        `LU` contains `L` and `U` factors for LU factorization of `A`.\n",
      "        \n",
      "        `torch.solve(B, A)` can take in 2D inputs `B, A` or inputs that are\n",
      "        batches of 2D matrices. If the inputs are batches, then returns\n",
      "        batched outputs `solution, LU`.\n",
      "        \n",
      "        Supports real-valued and complex-valued inputs.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            Irrespective of the original strides, the returned matrices\n",
      "            `solution` and `LU` will be transposed, i.e. with strides like\n",
      "            `B.contiguous().transpose(-1, -2).stride()` and\n",
      "            `A.contiguous().transpose(-1, -2).stride()` respectively.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): input matrix :math:`B` of size :math:`(*, m, k)` , where :math:`*`\n",
      "                        is zero or more batch dimensions.\n",
      "            A (Tensor): input square matrix of size :math:`(*, m, m)`, where\n",
      "                        :math:`*` is zero or more batch dimensions.\n",
      "        \n",
      "        Keyword args:\n",
      "            out ((Tensor, Tensor), optional): optional output tuple.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> A = torch.tensor([[6.80, -2.11,  5.66,  5.97,  8.23],\n",
      "            ...                   [-6.05, -3.30,  5.36, -4.44,  1.08],\n",
      "            ...                   [-0.45,  2.58, -2.70,  0.27,  9.04],\n",
      "            ...                   [8.32,  2.71,  4.35,  -7.17,  2.14],\n",
      "            ...                   [-9.67, -5.14, -7.26,  6.08, -6.87]]).t()\n",
      "            >>> B = torch.tensor([[4.02,  6.19, -8.22, -7.57, -3.03],\n",
      "            ...                   [-1.56,  4.00, -8.67,  1.75,  2.86],\n",
      "            ...                   [9.81, -4.09, -4.57, -8.61,  8.99]]).t()\n",
      "            >>> X, LU = torch.solve(B, A)\n",
      "            >>> torch.dist(B, torch.mm(A, X))\n",
      "            tensor(1.00000e-06 *\n",
      "                   7.0977)\n",
      "        \n",
      "            >>> # Batched solver example\n",
      "            >>> A = torch.randn(2, 3, 1, 4, 4)\n",
      "            >>> B = torch.randn(2, 3, 1, 4, 6)\n",
      "            >>> X, LU = torch.solve(B, A)\n",
      "            >>> torch.dist(B, A.matmul(X))\n",
      "            tensor(1.00000e-06 *\n",
      "               3.6386)\n",
      "    \n",
      "    sort(...)\n",
      "        sort(input, dim=-1, descending=False, *, out=None) -> (Tensor, LongTensor)\n",
      "        \n",
      "        Sorts the elements of the :attr:`input` tensor along a given dimension\n",
      "        in ascending order by value.\n",
      "        \n",
      "        If :attr:`dim` is not given, the last dimension of the `input` is chosen.\n",
      "        \n",
      "        If :attr:`descending` is ``True`` then the elements are sorted in descending\n",
      "        order by value.\n",
      "        \n",
      "        A namedtuple of (values, indices) is returned, where the `values` are the\n",
      "        sorted values and `indices` are the indices of the elements in the original\n",
      "        `input` tensor.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int, optional): the dimension to sort along\n",
      "            descending (bool, optional): controls the sorting order (ascending or descending)\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the output tuple of (`Tensor`, `LongTensor`) that can\n",
      "                be optionally given to be used as output buffers\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.randn(3, 4)\n",
      "            >>> sorted, indices = torch.sort(x)\n",
      "            >>> sorted\n",
      "            tensor([[-0.2162,  0.0608,  0.6719,  2.3332],\n",
      "                    [-0.5793,  0.0061,  0.6058,  0.9497],\n",
      "                    [-0.5071,  0.3343,  0.9553,  1.0960]])\n",
      "            >>> indices\n",
      "            tensor([[ 1,  0,  2,  3],\n",
      "                    [ 3,  1,  0,  2],\n",
      "                    [ 0,  3,  1,  2]])\n",
      "        \n",
      "            >>> sorted, indices = torch.sort(x, 0)\n",
      "            >>> sorted\n",
      "            tensor([[-0.5071, -0.2162,  0.6719, -0.5793],\n",
      "                    [ 0.0608,  0.0061,  0.9497,  0.3343],\n",
      "                    [ 0.6058,  0.9553,  1.0960,  2.3332]])\n",
      "            >>> indices\n",
      "            tensor([[ 2,  0,  0,  1],\n",
      "                    [ 0,  1,  1,  2],\n",
      "                    [ 1,  2,  2,  0]])\n",
      "    \n",
      "    sparse_coo_tensor(...)\n",
      "        sparse_coo_tensor(indices, values, size=None, *, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Constructs a :ref:`sparse tensor in COO(rdinate) format\n",
      "        <sparse-coo-docs>` with specified values at the given\n",
      "        :attr:`indices`.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "           This function returns an :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "        \n",
      "        Args:\n",
      "            indices (array_like): Initial data for the tensor. Can be a list, tuple,\n",
      "                NumPy ``ndarray``, scalar, and other types. Will be cast to a :class:`torch.LongTensor`\n",
      "                internally. The indices are the coordinates of the non-zero values in the matrix, and thus\n",
      "                should be two-dimensional where the first dimension is the number of tensor dimensions and\n",
      "                the second dimension is the number of non-zero values.\n",
      "            values (array_like): Initial values for the tensor. Can be a list, tuple,\n",
      "                NumPy ``ndarray``, scalar, and other types.\n",
      "            size (list, tuple, or :class:`torch.Size`, optional): Size of the sparse tensor. If not\n",
      "                provided the size will be inferred as the minimum size big enough to hold all non-zero\n",
      "                elements.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if None, infers data type from :attr:`values`.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if None, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> i = torch.tensor([[0, 1, 1],\n",
      "            ...                   [2, 0, 2]])\n",
      "            >>> v = torch.tensor([3, 4, 5], dtype=torch.float32)\n",
      "            >>> torch.sparse_coo_tensor(i, v, [2, 4])\n",
      "            tensor(indices=tensor([[0, 1, 1],\n",
      "                                   [2, 0, 2]]),\n",
      "                   values=tensor([3., 4., 5.]),\n",
      "                   size=(2, 4), nnz=3, layout=torch.sparse_coo)\n",
      "        \n",
      "            >>> torch.sparse_coo_tensor(i, v)  # Shape inference\n",
      "            tensor(indices=tensor([[0, 1, 1],\n",
      "                                   [2, 0, 2]]),\n",
      "                   values=tensor([3., 4., 5.]),\n",
      "                   size=(2, 3), nnz=3, layout=torch.sparse_coo)\n",
      "        \n",
      "            >>> torch.sparse_coo_tensor(i, v, [2, 4],\n",
      "            ...                         dtype=torch.float64,\n",
      "            ...                         device=torch.device('cuda:0'))\n",
      "            tensor(indices=tensor([[0, 1, 1],\n",
      "                                   [2, 0, 2]]),\n",
      "                   values=tensor([3., 4., 5.]),\n",
      "                   device='cuda:0', size=(2, 4), nnz=3, dtype=torch.float64,\n",
      "                   layout=torch.sparse_coo)\n",
      "        \n",
      "            # Create an empty sparse tensor with the following invariants:\n",
      "            #   1. sparse_dim + dense_dim = len(SparseTensor.shape)\n",
      "            #   2. SparseTensor._indices().shape = (sparse_dim, nnz)\n",
      "            #   3. SparseTensor._values().shape = (nnz, SparseTensor.shape[sparse_dim:])\n",
      "            #\n",
      "            # For instance, to create an empty sparse tensor with nnz = 0, dense_dim = 0 and\n",
      "            # sparse_dim = 1 (hence indices is a 2D tensor of shape = (1, 0))\n",
      "            >>> S = torch.sparse_coo_tensor(torch.empty([1, 0]), [], [1])\n",
      "            tensor(indices=tensor([], size=(1, 0)),\n",
      "                   values=tensor([], size=(0,)),\n",
      "                   size=(1,), nnz=0, layout=torch.sparse_coo)\n",
      "        \n",
      "            # and to create an empty sparse tensor with nnz = 0, dense_dim = 1 and\n",
      "            # sparse_dim = 1\n",
      "            >>> S = torch.sparse_coo_tensor(torch.empty([1, 0]), torch.empty([0, 2]), [1, 2])\n",
      "            tensor(indices=tensor([], size=(1, 0)),\n",
      "                   values=tensor([], size=(0, 2)),\n",
      "                   size=(1, 2), nnz=0, layout=torch.sparse_coo)\n",
      "        \n",
      "        .. _torch.sparse: https://pytorch.org/docs/stable/sparse.html\n",
      "    \n",
      "    split(tensor, split_size_or_sections, dim=0)\n",
      "        Splits the tensor into chunks. Each chunk is a view of the original tensor.\n",
      "        \n",
      "        If :attr:`split_size_or_sections` is an integer type, then :attr:`tensor` will\n",
      "        be split into equally sized chunks (if possible). Last chunk will be smaller if\n",
      "        the tensor size along the given dimension :attr:`dim` is not divisible by\n",
      "        :attr:`split_size`.\n",
      "        \n",
      "        If :attr:`split_size_or_sections` is a list, then :attr:`tensor` will be split\n",
      "        into ``len(split_size_or_sections)`` chunks with sizes in :attr:`dim` according\n",
      "        to :attr:`split_size_or_sections`.\n",
      "        \n",
      "        Args:\n",
      "            tensor (Tensor): tensor to split.\n",
      "            split_size_or_sections (int) or (list(int)): size of a single chunk or\n",
      "                list of sizes for each chunk\n",
      "            dim (int): dimension along which to split the tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> a = torch.arange(10).reshape(5,2)\n",
      "            >>> a\n",
      "            tensor([[0, 1],\n",
      "                    [2, 3],\n",
      "                    [4, 5],\n",
      "                    [6, 7],\n",
      "                    [8, 9]])\n",
      "            >>> torch.split(a, 2)\n",
      "            (tensor([[0, 1],\n",
      "                     [2, 3]]),\n",
      "             tensor([[4, 5],\n",
      "                     [6, 7]]),\n",
      "             tensor([[8, 9]]))\n",
      "            >>> torch.split(a, [1,4])\n",
      "            (tensor([[0, 1]]),\n",
      "             tensor([[2, 3],\n",
      "                     [4, 5],\n",
      "                     [6, 7],\n",
      "                     [8, 9]]))\n",
      "    \n",
      "    split_with_sizes(...)\n",
      "    \n",
      "    spmm(...)\n",
      "    \n",
      "    sqrt(...)\n",
      "        sqrt(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the square-root of the elements of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\sqrt{\\text{input}_{i}}\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-2.0755,  1.0226,  0.0831,  0.4806])\n",
      "            >>> torch.sqrt(a)\n",
      "            tensor([    nan,  1.0112,  0.2883,  0.6933])\n",
      "    \n",
      "    sqrt_(...)\n",
      "    \n",
      "    square(...)\n",
      "        square(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the square of the elements of :attr:`input`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-2.0755,  1.0226,  0.0831,  0.4806])\n",
      "            >>> torch.square(a)\n",
      "            tensor([ 4.3077,  1.0457,  0.0069,  0.2310])\n",
      "    \n",
      "    square_(...)\n",
      "    \n",
      "    squeeze(...)\n",
      "        squeeze(input, dim=None, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a tensor with all the dimensions of :attr:`input` of size `1` removed.\n",
      "        \n",
      "        For example, if `input` is of shape:\n",
      "        :math:`(A \\times 1 \\times B \\times C \\times 1 \\times D)` then the `out` tensor\n",
      "        will be of shape: :math:`(A \\times B \\times C \\times D)`.\n",
      "        \n",
      "        When :attr:`dim` is given, a squeeze operation is done only in the given\n",
      "        dimension. If `input` is of shape: :math:`(A \\times 1 \\times B)`,\n",
      "        ``squeeze(input, 0)`` leaves the tensor unchanged, but ``squeeze(input, 1)``\n",
      "        will squeeze the tensor to the shape :math:`(A \\times B)`.\n",
      "        \n",
      "        .. note:: The returned tensor shares the storage with the input tensor,\n",
      "                  so changing the contents of one will change the contents of the other.\n",
      "        \n",
      "        .. warning:: If the tensor has a batch dimension of size 1, then `squeeze(input)`\n",
      "                  will also remove the batch dimension, which can lead to unexpected\n",
      "                  errors.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int, optional): if given, the input will be squeezed only in\n",
      "                   this dimension\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.zeros(2, 1, 2, 1, 2)\n",
      "            >>> x.size()\n",
      "            torch.Size([2, 1, 2, 1, 2])\n",
      "            >>> y = torch.squeeze(x)\n",
      "            >>> y.size()\n",
      "            torch.Size([2, 2, 2])\n",
      "            >>> y = torch.squeeze(x, 0)\n",
      "            >>> y.size()\n",
      "            torch.Size([2, 1, 2, 1, 2])\n",
      "            >>> y = torch.squeeze(x, 1)\n",
      "            >>> y.size()\n",
      "            torch.Size([2, 2, 1, 2])\n",
      "    \n",
      "    sspaddmm(...)\n",
      "        sspaddmm(input, mat1, mat2, *, beta=1, alpha=1, out=None) -> Tensor\n",
      "        \n",
      "        Matrix multiplies a sparse tensor :attr:`mat1` with a dense tensor\n",
      "        :attr:`mat2`, then adds the sparse tensor :attr:`input` to the result.\n",
      "        \n",
      "        Note: This function is equivalent to :func:`torch.addmm`, except\n",
      "        :attr:`input` and :attr:`mat1` are sparse.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): a sparse matrix to be added\n",
      "            mat1 (Tensor): a sparse matrix to be matrix multiplied\n",
      "            mat2 (Tensor): a dense matrix to be matrix multiplied\n",
      "        \n",
      "        Keyword args:\n",
      "            beta (Number, optional): multiplier for :attr:`mat` (:math:`\\beta`)\n",
      "            alpha (Number, optional): multiplier for :math:`mat1 @ mat2` (:math:`\\alpha`)\n",
      "            out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    stack(...)\n",
      "        stack(tensors, dim=0, *, out=None) -> Tensor\n",
      "        \n",
      "        Concatenates a sequence of tensors along a new dimension.\n",
      "        \n",
      "        All tensors need to be of the same size.\n",
      "        \n",
      "        Arguments:\n",
      "            tensors (sequence of Tensors): sequence of tensors to concatenate\n",
      "            dim (int): dimension to insert. Has to be between 0 and the number\n",
      "                of dimensions of concatenated tensors (inclusive)\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    std(...)\n",
      "        std(input, unbiased=True) -> Tensor\n",
      "        \n",
      "        Returns the standard-deviation of all elements in the :attr:`input` tensor.\n",
      "        \n",
      "        If :attr:`unbiased` is ``False``, then the standard-deviation will be calculated\n",
      "        via the biased estimator. Otherwise, Bessel's correction will be used.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            unbiased (bool): whether to use the unbiased estimation or not\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 3)\n",
      "            >>> a\n",
      "            tensor([[-0.8166, -1.3802, -0.3560]])\n",
      "            >>> torch.std(a)\n",
      "            tensor(0.5130)\n",
      "        \n",
      "        .. function:: std(input, dim, unbiased=True, keepdim=False, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns the standard-deviation of each row of the :attr:`input` tensor in the\n",
      "        dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
      "        reduce over all of them.\n",
      "        \n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "        as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "        output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
      "        \n",
      "        \n",
      "        If :attr:`unbiased` is ``False``, then the standard-deviation will be calculated\n",
      "        via the biased estimator. Otherwise, Bessel's correction will be used.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "            unbiased (bool): whether to use the unbiased estimation or not\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[ 0.2035,  1.2959,  1.8101, -0.4644],\n",
      "                    [ 1.5027, -0.3270,  0.5905,  0.6538],\n",
      "                    [-1.5745,  1.3330, -0.5596, -0.6548],\n",
      "                    [ 0.1264, -0.5080,  1.6420,  0.1992]])\n",
      "            >>> torch.std(a, dim=1)\n",
      "            tensor([ 1.0311,  0.7477,  1.2204,  0.9087])\n",
      "    \n",
      "    std_mean(...)\n",
      "        std_mean(input, unbiased=True) -> (Tensor, Tensor)\n",
      "        \n",
      "        Returns the standard-deviation and mean of all elements in the :attr:`input` tensor.\n",
      "        \n",
      "        If :attr:`unbiased` is ``False``, then the standard-deviation will be calculated\n",
      "        via the biased estimator. Otherwise, Bessel's correction will be used.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            unbiased (bool): whether to use the unbiased estimation or not\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 3)\n",
      "            >>> a\n",
      "            tensor([[0.3364, 0.3591, 0.9462]])\n",
      "            >>> torch.std_mean(a)\n",
      "            (tensor(0.3457), tensor(0.5472))\n",
      "        \n",
      "        .. function:: std_mean(input, dim, unbiased=True, keepdim=False) -> (Tensor, Tensor)\n",
      "        \n",
      "        Returns the standard-deviation and mean of each row of the :attr:`input` tensor in the\n",
      "        dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
      "        reduce over all of them.\n",
      "        \n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "        as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "        output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
      "        \n",
      "        \n",
      "        If :attr:`unbiased` is ``False``, then the standard-deviation will be calculated\n",
      "        via the biased estimator. Otherwise, Bessel's correction will be used.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "            unbiased (bool): whether to use the unbiased estimation or not\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[ 0.5648, -0.5984, -1.2676, -1.4471],\n",
      "                    [ 0.9267,  1.0612,  1.1050, -0.6014],\n",
      "                    [ 0.0154,  1.9301,  0.0125, -1.0904],\n",
      "                    [-1.9711, -0.7748, -1.3840,  0.5067]])\n",
      "            >>> torch.std_mean(a, 1)\n",
      "            (tensor([0.9110, 0.8197, 1.2552, 1.0608]), tensor([-0.6871,  0.6229,  0.2169, -0.9058]))\n",
      "    \n",
      "    stft(input: torch.Tensor, n_fft: int, hop_length: Union[int, NoneType] = None, win_length: Union[int, NoneType] = None, window: Union[torch.Tensor, NoneType] = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Union[bool, NoneType] = None, return_complex: Union[bool, NoneType] = None) -> torch.Tensor\n",
      "        Short-time Fourier transform (STFT).\n",
      "        \n",
      "        .. warning::\n",
      "            From version 1.8.0, :attr:`return_complex` must always be given\n",
      "            explicitly for real inputs and `return_complex=False` has been\n",
      "            deprecated. Strongly prefer `return_complex=True` as in a future\n",
      "            pytorch release, this function will only return complex tensors.\n",
      "        \n",
      "            Note that :func:`torch.view_as_real` can be used to recover a real\n",
      "            tensor with an extra last dimension for real and imaginary components.\n",
      "        \n",
      "        The STFT computes the Fourier transform of short overlapping windows of the\n",
      "        input. This giving frequency components of the signal as they change over\n",
      "        time. The interface of this function is modeled after the librosa_ stft function.\n",
      "        \n",
      "        .. _librosa: https://librosa.org/doc/latest/generated/librosa.stft.html\n",
      "        \n",
      "        Ignoring the optional batch dimension, this method computes the following\n",
      "        expression:\n",
      "        \n",
      "        .. math::\n",
      "            X[m, \\omega] = \\sum_{k = 0}^{\\text{win\\_length-1}}%\n",
      "                                \\text{window}[k]\\ \\text{input}[m \\times \\text{hop\\_length} + k]\\ %\n",
      "                                \\exp\\left(- j \\frac{2 \\pi \\cdot \\omega k}{\\text{win\\_length}}\\right),\n",
      "        \n",
      "        where :math:`m` is the index of the sliding window, and :math:`\\omega` is\n",
      "        the frequency that :math:`0 \\leq \\omega < \\text{n\\_fft}`. When\n",
      "        :attr:`onesided` is the default value ``True``,\n",
      "        \n",
      "        * :attr:`input` must be either a 1-D time sequence or a 2-D batch of time\n",
      "          sequences.\n",
      "        \n",
      "        * If :attr:`hop_length` is ``None`` (default), it is treated as equal to\n",
      "          ``floor(n_fft / 4)``.\n",
      "        \n",
      "        * If :attr:`win_length` is ``None`` (default), it is treated as equal to\n",
      "          :attr:`n_fft`.\n",
      "        \n",
      "        * :attr:`window` can be a 1-D tensor of size :attr:`win_length`, e.g., from\n",
      "          :meth:`torch.hann_window`. If :attr:`window` is ``None`` (default), it is\n",
      "          treated as if having :math:`1` everywhere in the window. If\n",
      "          :math:`\\text{win\\_length} < \\text{n\\_fft}`, :attr:`window` will be padded on\n",
      "          both sides to length :attr:`n_fft` before being applied.\n",
      "        \n",
      "        * If :attr:`center` is ``True`` (default), :attr:`input` will be padded on\n",
      "          both sides so that the :math:`t`-th frame is centered at time\n",
      "          :math:`t \\times \\text{hop\\_length}`. Otherwise, the :math:`t`-th frame\n",
      "          begins at time  :math:`t \\times \\text{hop\\_length}`.\n",
      "        \n",
      "        * :attr:`pad_mode` determines the padding method used on :attr:`input` when\n",
      "          :attr:`center` is ``True``. See :meth:`torch.nn.functional.pad` for\n",
      "          all available options. Default is ``\"reflect\"``.\n",
      "        \n",
      "        * If :attr:`onesided` is ``True`` (default for real input), only values for\n",
      "          :math:`\\omega` in :math:`\\left[0, 1, 2, \\dots, \\left\\lfloor\n",
      "          \\frac{\\text{n\\_fft}}{2} \\right\\rfloor + 1\\right]` are returned because\n",
      "          the real-to-complex Fourier transform satisfies the conjugate symmetry,\n",
      "          i.e., :math:`X[m, \\omega] = X[m, \\text{n\\_fft} - \\omega]^*`.\n",
      "          Note if the input or window tensors are complex, then :attr:`onesided`\n",
      "          output is not possible.\n",
      "        \n",
      "        * If :attr:`normalized` is ``True`` (default is ``False``), the function\n",
      "          returns the normalized STFT results, i.e., multiplied by :math:`(\\text{frame\\_length})^{-0.5}`.\n",
      "        \n",
      "        * If :attr:`return_complex` is ``True`` (default if input is complex), the\n",
      "          return is a ``input.dim() + 1`` dimensional complex tensor. If ``False``,\n",
      "          the output is a ``input.dim() + 2`` dimensional real tensor where the last\n",
      "          dimension represents the real and imaginary components.\n",
      "        \n",
      "        Returns either a complex tensor of size :math:`(* \\times N \\times T)` if\n",
      "        :attr:`return_complex` is true, or a real tensor of size :math:`(* \\times N\n",
      "        \\times T \\times 2)`. Where :math:`*` is the optional batch size of\n",
      "        :attr:`input`, :math:`N` is the number of frequencies where STFT is applied\n",
      "        and :math:`T` is the total number of frames used.\n",
      "        \n",
      "        .. warning::\n",
      "          This function changed signature at version 0.4.1. Calling with the\n",
      "          previous signature may cause error or return incorrect result.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor\n",
      "            n_fft (int): size of Fourier transform\n",
      "            hop_length (int, optional): the distance between neighboring sliding window\n",
      "                frames. Default: ``None`` (treated as equal to ``floor(n_fft / 4)``)\n",
      "            win_length (int, optional): the size of window frame and STFT filter.\n",
      "                Default: ``None``  (treated as equal to :attr:`n_fft`)\n",
      "            window (Tensor, optional): the optional window function.\n",
      "                Default: ``None`` (treated as window of all :math:`1` s)\n",
      "            center (bool, optional): whether to pad :attr:`input` on both sides so\n",
      "                that the :math:`t`-th frame is centered at time :math:`t \\times \\text{hop\\_length}`.\n",
      "                Default: ``True``\n",
      "            pad_mode (string, optional): controls the padding method used when\n",
      "                :attr:`center` is ``True``. Default: ``\"reflect\"``\n",
      "            normalized (bool, optional): controls whether to return the normalized STFT results\n",
      "                 Default: ``False``\n",
      "            onesided (bool, optional): controls whether to return half of results to\n",
      "                avoid redundancy for real inputs.\n",
      "                Default: ``True`` for real :attr:`input` and :attr:`window`, ``False`` otherwise.\n",
      "            return_complex (bool, optional): whether to return a complex tensor, or\n",
      "                a real tensor with an extra last dimension for the real and\n",
      "                imaginary components.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A tensor containing the STFT result with shape described above\n",
      "    \n",
      "    sub(...)\n",
      "        sub(input, other, *, alpha=1, out=None) -> Tensor\n",
      "        \n",
      "        Subtracts :attr:`other`, scaled by :attr:`alpha`, from :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{{out}}_i = \\text{{input}}_i - \\text{{alpha}} \\times \\text{{other}}_i\n",
      "        \n",
      "        \n",
      "        Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`,\n",
      "        :ref:`type promotion <type-promotion-doc>`, and integer, float, and complex inputs.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            other (Tensor or Scalar): the tensor or scalar to subtract from :attr:`input`\n",
      "        \n",
      "        Keyword args:\n",
      "            alpha (Scalar): the scalar multiplier for :attr:`other`\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor((1, 2))\n",
      "            >>> b = torch.tensor((0, 1))\n",
      "            >>> torch.sub(a, b, alpha=2)\n",
      "            tensor([1, 0])\n",
      "    \n",
      "    subtract(...)\n",
      "        subtract(input, other, *, alpha=1, out=None) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.sub`.\n",
      "    \n",
      "    sum(...)\n",
      "        sum(input, *, dtype=None) -> Tensor\n",
      "        \n",
      "        Returns the sum of all elements in the :attr:`input` tensor.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "                is performed. This is useful for preventing data type overflows. Default: None.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 3)\n",
      "            >>> a\n",
      "            tensor([[ 0.1133, -0.9567,  0.2958]])\n",
      "            >>> torch.sum(a)\n",
      "            tensor(-0.5475)\n",
      "        \n",
      "        .. function:: sum(input, dim, keepdim=False, *, dtype=None) -> Tensor\n",
      "        \n",
      "        Returns the sum of each row of the :attr:`input` tensor in the given\n",
      "        dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
      "        reduce over all of them.\n",
      "        \n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "        as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "        output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "                is performed. This is useful for preventing data type overflows. Default: None.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[ 0.0569, -0.2475,  0.0737, -0.3429],\n",
      "                    [-0.2993,  0.9138,  0.9337, -1.6864],\n",
      "                    [ 0.1132,  0.7892, -0.1003,  0.5688],\n",
      "                    [ 0.3637, -0.9906, -0.4752, -1.5197]])\n",
      "            >>> torch.sum(a, 1)\n",
      "            tensor([-0.4598, -0.1381,  1.3708, -2.6217])\n",
      "            >>> b = torch.arange(4 * 5 * 6).view(4, 5, 6)\n",
      "            >>> torch.sum(b, (2, 1))\n",
      "            tensor([  435.,  1335.,  2235.,  3135.])\n",
      "    \n",
      "    svd(...)\n",
      "        svd(input, some=True, compute_uv=True, *, out=None) -> (Tensor, Tensor, Tensor)\n",
      "        \n",
      "        Computes the singular value decomposition of either a matrix or batch of\n",
      "        matrices :attr:`input`. The singular value decomposition is represented as a\n",
      "        namedtuple (`U,S,V`), such that\n",
      "        :attr:`input` = `U` diag(`S`) `Vᴴ`,\n",
      "        where `Vᴴ` is the transpose of `V` for the real-valued inputs,\n",
      "        or the conjugate transpose of `V` for the complex-valued inputs.\n",
      "        If :attr:`input` is a batch of tensors, then `U`, `S`, and `V` are also\n",
      "        batched with the same batch dimensions as :attr:`input`.\n",
      "        \n",
      "        If :attr:`some` is ``True`` (default), the method returns the reduced singular\n",
      "        value decomposition i.e., if the last two dimensions of :attr:`input` are\n",
      "        `m` and `n`, then the returned `U` and `V` matrices will contain only\n",
      "        min(`n, m`) orthonormal columns.\n",
      "        \n",
      "        If :attr:`compute_uv` is ``False``, the returned `U` and `V` will be\n",
      "        zero-filled matrices of shape `(m × m)` and `(n × n)`\n",
      "        respectively, and the same device as :attr:`input`. The :attr:`some`\n",
      "        argument has no effect when :attr:`compute_uv` is ``False``.\n",
      "        \n",
      "        Supports input of float, double, cfloat and cdouble data types.\n",
      "        The dtypes of `U` and `V` are the same as :attr:`input`'s. `S` will\n",
      "        always be real-valued, even if :attr:`input` is complex.\n",
      "        \n",
      "        .. warning:: :func:`torch.svd` is deprecated. Please use\n",
      "                     :func:`torch.linalg.svd` instead, which is similar to NumPy's\n",
      "                     ``numpy.linalg.svd``.\n",
      "        \n",
      "        .. note:: Differences with :func:`torch.linalg.svd`:\n",
      "        \n",
      "                     * :attr:`some` is the opposite of\n",
      "                       :func:`torch.linalg.svd`'s :attr:`full_matricies`. Note that\n",
      "                       default value for both is ``True``, so the default behavior is\n",
      "                       effectively the opposite.\n",
      "        \n",
      "                     * :func:`torch.svd` returns `V`, whereas :func:`torch.linalg.svd` returns `Vᴴ`.\n",
      "        \n",
      "                     * If :attr:`compute_uv=False`, :func:`torch.svd` returns zero-filled tensors for\n",
      "                       ``U`` and ``Vh``, whereas :func:`torch.linalg.svd` returns\n",
      "                       empty tensors.\n",
      "        \n",
      "        .. note:: The singular values are returned in descending order. If :attr:`input` is a batch of matrices,\n",
      "                  then the singular values of each matrix in the batch is returned in descending order.\n",
      "        \n",
      "        .. note:: The implementation of SVD on CPU uses the LAPACK routine `?gesdd` (a divide-and-conquer\n",
      "                  algorithm) instead of `?gesvd` for speed. Analogously, the SVD on GPU uses the cuSOLVER routines\n",
      "                  `gesvdj` and `gesvdjBatched` on CUDA 10.1.243 and later, and uses the MAGMA routine `gesdd`\n",
      "                  on earlier versions of CUDA.\n",
      "        \n",
      "        .. note:: The returned matrix `U` will be transposed, i.e. with strides\n",
      "                  :code:`U.contiguous().transpose(-2, -1).stride()`.\n",
      "        \n",
      "        .. note:: Gradients computed using `U` and `V` may be unstable if\n",
      "                  :attr:`input` is not full rank or has non-unique singular values.\n",
      "        \n",
      "        .. note:: When :attr:`some` = ``False``, the gradients on :code:`U[..., :, min(m, n):]`\n",
      "                  and :code:`V[..., :, min(m, n):]` will be ignored in backward as those vectors\n",
      "                  can be arbitrary bases of the subspaces.\n",
      "        \n",
      "        .. note:: The `S` tensor can only be used to compute gradients if :attr:`compute_uv` is True.\n",
      "        \n",
      "        .. note:: With the complex-valued input the backward operation works correctly only\n",
      "                  for gauge invariant loss functions. Please look at `Gauge problem in AD`_ for more details.\n",
      "        \n",
      "        .. note:: Since `U` and `V` of an SVD is not unique, each vector can be multiplied by\n",
      "                  an arbitrary phase factor :math:`e^{i \\phi}` while the SVD result is still correct.\n",
      "                  Different platforms, like Numpy, or inputs on different device types, may produce different\n",
      "                  `U` and `V` tensors.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor of size `(*, m, n)` where `*` is zero or more\n",
      "                            batch dimensions consisting of `(m × n)` matrices.\n",
      "            some (bool, optional): controls whether to compute the reduced or full decomposition, and\n",
      "                                   consequently the shape of returned `U` and `V`. Defaults to True.\n",
      "            compute_uv (bool, optional): option whether to compute `U` and `V` or not. Defaults to True.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the output tuple of tensors\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(5, 3)\n",
      "            >>> a\n",
      "            tensor([[ 0.2364, -0.7752,  0.6372],\n",
      "                    [ 1.7201,  0.7394, -0.0504],\n",
      "                    [-0.3371, -1.0584,  0.5296],\n",
      "                    [ 0.3550, -0.4022,  1.5569],\n",
      "                    [ 0.2445, -0.0158,  1.1414]])\n",
      "            >>> u, s, v = torch.svd(a)\n",
      "            >>> u\n",
      "            tensor([[ 0.4027,  0.0287,  0.5434],\n",
      "                    [-0.1946,  0.8833,  0.3679],\n",
      "                    [ 0.4296, -0.2890,  0.5261],\n",
      "                    [ 0.6604,  0.2717, -0.2618],\n",
      "                    [ 0.4234,  0.2481, -0.4733]])\n",
      "            >>> s\n",
      "            tensor([2.3289, 2.0315, 0.7806])\n",
      "            >>> v\n",
      "            tensor([[-0.0199,  0.8766,  0.4809],\n",
      "                    [-0.5080,  0.4054, -0.7600],\n",
      "                    [ 0.8611,  0.2594, -0.4373]])\n",
      "            >>> torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t()))\n",
      "            tensor(8.6531e-07)\n",
      "            >>> a_big = torch.randn(7, 5, 3)\n",
      "            >>> u, s, v = torch.svd(a_big)\n",
      "            >>> torch.dist(a_big, torch.matmul(torch.matmul(u, torch.diag_embed(s)), v.transpose(-2, -1)))\n",
      "            tensor(2.6503e-06)\n",
      "        \n",
      "        .. _Gauge problem in AD: https://re-ra.xyz/Gauge-Problem-in-Automatic-Differentiation/\n",
      "    \n",
      "    swapaxes(...)\n",
      "        swapaxes(input, axis0, axis1) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.transpose`.\n",
      "        \n",
      "        This function is equivalent to NumPy's swapaxes function.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> x = torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])\n",
      "            >>> x\n",
      "            tensor([[[0, 1],\n",
      "                    [2, 3]],\n",
      "        \n",
      "                    [[4, 5],\n",
      "                    [6, 7]]])\n",
      "            >>> torch.swapaxes(x, 0, 1)\n",
      "            tensor([[[0, 1],\n",
      "                    [4, 5]],\n",
      "        \n",
      "                    [[2, 3],\n",
      "                    [6, 7]]])\n",
      "            >>> torch.swapaxes(x, 0, 2)\n",
      "            tensor([[[0, 4],\n",
      "                    [2, 6]],\n",
      "        \n",
      "                    [[1, 5],\n",
      "                    [3, 7]]])\n",
      "    \n",
      "    swapdims(...)\n",
      "        swapdims(input, dim0, dim1) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.transpose`.\n",
      "        \n",
      "        This function is equivalent to NumPy's swapaxes function.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> x = torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])\n",
      "            >>> x\n",
      "            tensor([[[0, 1],\n",
      "                    [2, 3]],\n",
      "        \n",
      "                    [[4, 5],\n",
      "                    [6, 7]]])\n",
      "            >>> torch.swapdims(x, 0, 1)\n",
      "            tensor([[[0, 1],\n",
      "                    [4, 5]],\n",
      "        \n",
      "                    [[2, 3],\n",
      "                    [6, 7]]])\n",
      "            >>> torch.swapdims(x, 0, 2)\n",
      "            tensor([[[0, 4],\n",
      "                    [2, 6]],\n",
      "        \n",
      "                    [[1, 5],\n",
      "                    [3, 7]]])\n",
      "    \n",
      "    symeig(...)\n",
      "        symeig(input, eigenvectors=False, upper=True, *, out=None) -> (Tensor, Tensor)\n",
      "        \n",
      "        This function returns eigenvalues and eigenvectors\n",
      "        of a real symmetric matrix :attr:`input` or a batch of real symmetric matrices,\n",
      "        represented by a namedtuple (eigenvalues, eigenvectors).\n",
      "        \n",
      "        This function calculates all eigenvalues (and vectors) of :attr:`input`\n",
      "        such that :math:`\\text{input} = V \\text{diag}(e) V^T`.\n",
      "        \n",
      "        The boolean argument :attr:`eigenvectors` defines computation of\n",
      "        both eigenvectors and eigenvalues or eigenvalues only.\n",
      "        \n",
      "        If it is ``False``, only eigenvalues are computed. If it is ``True``,\n",
      "        both eigenvalues and eigenvectors are computed.\n",
      "        \n",
      "        Since the input matrix :attr:`input` is supposed to be symmetric,\n",
      "        only the upper triangular portion is used by default.\n",
      "        \n",
      "        If :attr:`upper` is ``False``, then lower triangular portion is used.\n",
      "        \n",
      "        .. note:: The eigenvalues are returned in ascending order. If :attr:`input` is a batch of matrices,\n",
      "                  then the eigenvalues of each matrix in the batch is returned in ascending order.\n",
      "        \n",
      "        .. note:: Irrespective of the original strides, the returned matrix `V` will\n",
      "                  be transposed, i.e. with strides `V.contiguous().transpose(-1, -2).stride()`.\n",
      "        \n",
      "        .. warning:: Extra care needs to be taken when backward through outputs. Such\n",
      "                     operation is only stable when all eigenvalues are distinct and becomes\n",
      "                     less stable the smaller :math:`\\min_{i \\neq j} |\\lambda_i - \\lambda_j|` is.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor of size :math:`(*, n, n)` where `*` is zero or more\n",
      "                            batch dimensions consisting of symmetric matrices.\n",
      "            eigenvectors(bool, optional): controls whether eigenvectors have to be computed\n",
      "            upper(boolean, optional): controls whether to consider upper-triangular or lower-triangular region\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the output tuple of (Tensor, Tensor)\n",
      "        \n",
      "        Returns:\n",
      "            (Tensor, Tensor): A namedtuple (eigenvalues, eigenvectors) containing\n",
      "        \n",
      "                - **eigenvalues** (*Tensor*): Shape :math:`(*, m)`. The eigenvalues in ascending order.\n",
      "                - **eigenvectors** (*Tensor*): Shape :math:`(*, m, m)`.\n",
      "                  If ``eigenvectors=False``, it's an empty tensor.\n",
      "                  Otherwise, this tensor contains the orthonormal eigenvectors of the ``input``.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "        \n",
      "            >>> a = torch.randn(5, 5)\n",
      "            >>> a = a + a.t()  # To make a symmetric\n",
      "            >>> a\n",
      "            tensor([[-5.7827,  4.4559, -0.2344, -1.7123, -1.8330],\n",
      "                    [ 4.4559,  1.4250, -2.8636, -3.2100, -0.1798],\n",
      "                    [-0.2344, -2.8636,  1.7112, -5.5785,  7.1988],\n",
      "                    [-1.7123, -3.2100, -5.5785, -2.6227,  3.1036],\n",
      "                    [-1.8330, -0.1798,  7.1988,  3.1036, -5.1453]])\n",
      "            >>> e, v = torch.symeig(a, eigenvectors=True)\n",
      "            >>> e\n",
      "            tensor([-13.7012,  -7.7497,  -2.3163,   5.2477,   8.1050])\n",
      "            >>> v\n",
      "            tensor([[ 0.1643,  0.9034, -0.0291,  0.3508,  0.1817],\n",
      "                    [-0.2417, -0.3071, -0.5081,  0.6534,  0.4026],\n",
      "                    [-0.5176,  0.1223, -0.0220,  0.3295, -0.7798],\n",
      "                    [-0.4850,  0.2695, -0.5773, -0.5840,  0.1337],\n",
      "                    [ 0.6415, -0.0447, -0.6381, -0.0193, -0.4230]])\n",
      "            >>> a_big = torch.randn(5, 2, 2)\n",
      "            >>> a_big = a_big + a_big.transpose(-2, -1)  # To make a_big symmetric\n",
      "            >>> e, v = a_big.symeig(eigenvectors=True)\n",
      "            >>> torch.allclose(torch.matmul(v, torch.matmul(e.diag_embed(), v.transpose(-2, -1))), a_big)\n",
      "            True\n",
      "    \n",
      "    t(...)\n",
      "        t(input) -> Tensor\n",
      "        \n",
      "        Expects :attr:`input` to be <= 2-D tensor and transposes dimensions 0\n",
      "        and 1.\n",
      "        \n",
      "        0-D and 1-D tensors are returned as is. When input is a 2-D tensor this\n",
      "        is equivalent to ``transpose(input, 0, 1)``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.randn(())\n",
      "            >>> x\n",
      "            tensor(0.1995)\n",
      "            >>> torch.t(x)\n",
      "            tensor(0.1995)\n",
      "            >>> x = torch.randn(3)\n",
      "            >>> x\n",
      "            tensor([ 2.4320, -0.4608,  0.7702])\n",
      "            >>> torch.t(x)\n",
      "            tensor([ 2.4320, -0.4608,  0.7702])\n",
      "            >>> x = torch.randn(2, 3)\n",
      "            >>> x\n",
      "            tensor([[ 0.4875,  0.9158, -0.5872],\n",
      "                    [ 0.3938, -0.6929,  0.6932]])\n",
      "            >>> torch.t(x)\n",
      "            tensor([[ 0.4875,  0.3938],\n",
      "                    [ 0.9158, -0.6929],\n",
      "                    [-0.5872,  0.6932]])\n",
      "    \n",
      "    take(...)\n",
      "        take(input, index) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the elements of :attr:`input` at the given indices.\n",
      "        The input tensor is treated as if it were viewed as a 1-D tensor. The result\n",
      "        takes the same shape as the indices.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            indices (LongTensor): the indices into tensor\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> src = torch.tensor([[4, 3, 5],\n",
      "            ...                     [6, 7, 8]])\n",
      "            >>> torch.take(src, torch.tensor([0, 2, 5]))\n",
      "            tensor([ 4,  5,  8])\n",
      "    \n",
      "    tan(...)\n",
      "        tan(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the tangent of the elements of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\tan(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([-1.2027, -1.7687,  0.4412, -1.3856])\n",
      "            >>> torch.tan(a)\n",
      "            tensor([-2.5930,  4.9859,  0.4722, -5.3366])\n",
      "    \n",
      "    tan_(...)\n",
      "    \n",
      "    tanh(...)\n",
      "        tanh(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the hyperbolic tangent of the elements\n",
      "        of :attr:`input`.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\tanh(\\text{input}_{i})\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 0.8986, -0.7279,  1.1745,  0.2611])\n",
      "            >>> torch.tanh(a)\n",
      "            tensor([ 0.7156, -0.6218,  0.8257,  0.2553])\n",
      "    \n",
      "    tanh_(...)\n",
      "    \n",
      "    tensor(...)\n",
      "        tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
      "        \n",
      "        Constructs a tensor with :attr:`data`.\n",
      "        \n",
      "        .. warning::\n",
      "        \n",
      "            :func:`torch.tensor` always copies :attr:`data`. If you have a Tensor\n",
      "            ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "            or :func:`torch.Tensor.detach`.\n",
      "            If you have a NumPy ``ndarray`` and want to avoid a copy, use\n",
      "            :func:`torch.as_tensor`.\n",
      "        \n",
      "        .. warning::\n",
      "        \n",
      "            When data is a tensor `x`, :func:`torch.tensor` reads out 'the data' from whatever it is passed,\n",
      "            and constructs a leaf variable. Therefore ``torch.tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "            and ``torch.tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "            The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "        \n",
      "        Args:\n",
      "            data (array_like): Initial data for the tensor. Can be a list, tuple,\n",
      "                NumPy ``ndarray``, scalar, and other types.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, infers data type from :attr:`data`.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "            pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
      "                the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
      "        \n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n",
      "            tensor([[ 0.1000,  1.2000],\n",
      "                    [ 2.2000,  3.1000],\n",
      "                    [ 4.9000,  5.2000]])\n",
      "        \n",
      "            >>> torch.tensor([0, 1])  # Type inference on data\n",
      "            tensor([ 0,  1])\n",
      "        \n",
      "            >>> torch.tensor([[0.11111, 0.222222, 0.3333333]],\n",
      "            ...              dtype=torch.float64,\n",
      "            ...              device=torch.device('cuda:0'))  # creates a torch.cuda.DoubleTensor\n",
      "            tensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device='cuda:0')\n",
      "        \n",
      "            >>> torch.tensor(3.14159)  # Create a scalar (zero-dimensional tensor)\n",
      "            tensor(3.1416)\n",
      "        \n",
      "            >>> torch.tensor([])  # Create an empty tensor (of size (0,))\n",
      "            tensor([])\n",
      "    \n",
      "    tensor_split(...)\n",
      "        tensor_split(input, indices_or_sections, dim=0) -> List of Tensors\n",
      "        \n",
      "        Splits a tensor into multiple sub-tensors, all of which are views of :attr:`input`,\n",
      "        along dimension :attr:`dim` according to the indices or number of sections specified\n",
      "        by :attr:`indices_or_sections`. This function is based on NumPy's\n",
      "        :func:`numpy.array_split`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor to split\n",
      "            indices_or_sections (Tensor, int or list or tuple of ints):\n",
      "                If :attr:`indices_or_sections` is an integer ``n`` or a zero dimensional long tensor\n",
      "                with value ``n``, :attr:`input` is split into ``n`` sections along dimension :attr:`dim`.\n",
      "                If :attr:`input` is divisible by ``n`` along dimension :attr:`dim`, each\n",
      "                section will be of equal size, :code:`input.size(dim) / n`. If :attr:`input`\n",
      "                is not divisible by ``n``, the sizes of the first :code:`int(input.size(dim) % n)`\n",
      "                sections will have size :code:`int(input.size(dim) / n) + 1`, and the rest will\n",
      "                have size :code:`int(input.size(dim) / n)`.\n",
      "        \n",
      "                If :attr:`indices_or_sections` is a list or tuple of ints, or a one-dimensional long\n",
      "                tensor, then :attr:`input` is split along dimension :attr:`dim` at each of the indices\n",
      "                in the list, tuple or tensor. For instance, :code:`indices_or_sections=[2, 3]` and :code:`dim=0`\n",
      "                would result in the tensors :code:`input[:2]`, :code:`input[2:3]`, and :code:`input[3:]`.\n",
      "        \n",
      "                If indices_or_sections is a tensor, it must be a zero-dimensional or one-dimensional\n",
      "                long tensor on the CPU.\n",
      "        \n",
      "            dim (int, optional): dimension along which to split the tensor. Default: ``0``\n",
      "        \n",
      "        Example::\n",
      "            >>> x = torch.arange(8)\n",
      "            >>> torch.tensor_split(x, 3)\n",
      "            (tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7]))\n",
      "        \n",
      "            >>> x = torch.arange(7)\n",
      "            >>> torch.tensor_split(x, 3)\n",
      "            (tensor([0, 1, 2]), tensor([3, 4]), tensor([5, 6]))\n",
      "            >>> torch.tensor_split(x, (1, 6))\n",
      "            (tensor([0]), tensor([1, 2, 3, 4, 5]), tensor([6]))\n",
      "        \n",
      "            >>> x = torch.arange(14).reshape(2, 7)\n",
      "            >>> x\n",
      "            tensor([[ 0,  1,  2,  3,  4,  5,  6],\n",
      "                    [ 7,  8,  9, 10, 11, 12, 13]])\n",
      "            >>> torch.tensor_split(x, 3, dim=1)\n",
      "            (tensor([[0, 1, 2],\n",
      "                    [7, 8, 9]]),\n",
      "             tensor([[ 3,  4],\n",
      "                    [10, 11]]),\n",
      "             tensor([[ 5,  6],\n",
      "                    [12, 13]]))\n",
      "            >>> torch.tensor_split(x, (1, 6), dim=1)\n",
      "            (tensor([[0],\n",
      "                    [7]]),\n",
      "             tensor([[ 1,  2,  3,  4,  5],\n",
      "                    [ 8,  9, 10, 11, 12]]),\n",
      "             tensor([[ 6],\n",
      "                    [13]]))\n",
      "    \n",
      "    tensordot(a, b, dims=2, out=None)\n",
      "        Returns a contraction of a and b over multiple dimensions.\n",
      "        \n",
      "        :attr:`tensordot` implements a generalized matrix product.\n",
      "        \n",
      "        Args:\n",
      "          a (Tensor): Left tensor to contract\n",
      "          b (Tensor): Right tensor to contract\n",
      "          dims (int or Tuple[List[int]] containing two lists): number of dimensions to\n",
      "             contract or explicit lists of dimensions for :attr:`a` and\n",
      "             :attr:`b` respectively\n",
      "        \n",
      "        When called with a non-negative integer argument :attr:`dims` = :math:`d`, and\n",
      "        the number of dimensions of :attr:`a` and :attr:`b` is :math:`m` and :math:`n`,\n",
      "        respectively, :func:`~torch.tensordot` computes\n",
      "        \n",
      "        .. math::\n",
      "            r_{i_0,...,i_{m-d}, i_d,...,i_n}\n",
      "              = \\sum_{k_0,...,k_{d-1}} a_{i_0,...,i_{m-d},k_0,...,k_{d-1}} \\times b_{k_0,...,k_{d-1}, i_d,...,i_n}.\n",
      "        \n",
      "        When called with :attr:`dims` of the list form, the given dimensions will be contracted\n",
      "        in place of the last :math:`d` of :attr:`a` and the first :math:`d` of :math:`b`. The sizes\n",
      "        in these dimensions must match, but :func:`~torch.tensordot` will deal with broadcasted\n",
      "        dimensions.\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> a = torch.arange(60.).reshape(3, 4, 5)\n",
      "            >>> b = torch.arange(24.).reshape(4, 3, 2)\n",
      "            >>> torch.tensordot(a, b, dims=([1, 0], [0, 1]))\n",
      "            tensor([[4400., 4730.],\n",
      "                    [4532., 4874.],\n",
      "                    [4664., 5018.],\n",
      "                    [4796., 5162.],\n",
      "                    [4928., 5306.]])\n",
      "        \n",
      "            >>> a = torch.randn(3, 4, 5, device='cuda')\n",
      "            >>> b = torch.randn(4, 5, 6, device='cuda')\n",
      "            >>> c = torch.tensordot(a, b, dims=2).cpu()\n",
      "            tensor([[ 8.3504, -2.5436,  6.2922,  2.7556, -1.0732,  3.2741],\n",
      "                    [ 3.3161,  0.0704,  5.0187, -0.4079, -4.3126,  4.8744],\n",
      "                    [ 0.8223,  3.9445,  3.2168, -0.2400,  3.4117,  1.7780]])\n",
      "        \n",
      "            >>> a = torch.randn(3, 5, 4, 6)\n",
      "            >>> b = torch.randn(6, 4, 5, 3)\n",
      "            >>> torch.tensordot(a, b, dims=([2, 1, 3], [1, 2, 0]))\n",
      "            tensor([[  7.7193,  -2.4867, -10.3204],\n",
      "                    [  1.5513, -14.4737,  -6.5113],\n",
      "                    [ -0.2850,   4.2573,  -3.5997]])\n",
      "    \n",
      "    threshold(...)\n",
      "    \n",
      "    threshold_(...)\n",
      "        threshold_(input, threshold, value) -> Tensor\n",
      "        \n",
      "        In-place version of :func:`~threshold`.\n",
      "    \n",
      "    tile(...)\n",
      "        tile(input, reps) -> Tensor\n",
      "        \n",
      "        Constructs a tensor by repeating the elements of :attr:`input`.\n",
      "        The :attr:`reps` argument specifies the number of repetitions\n",
      "        in each dimension.\n",
      "        \n",
      "        If :attr:`reps` specifies fewer dimensions than :attr:`input` has, then\n",
      "        ones are prepended to :attr:`reps` until all dimensions are specified.\n",
      "        For example, if :attr:`input` has shape (8, 6, 4, 2) and :attr:`reps`\n",
      "        is (2, 2), then :attr:`reps` is treated as (1, 1, 2, 2).\n",
      "        \n",
      "        Analogously, if :attr:`input` has fewer dimensions than :attr:`reps`\n",
      "        specifies, then :attr:`input` is treated as if it were unsqueezed at\n",
      "        dimension zero until it has as many dimensions as :attr:`reps` specifies.\n",
      "        For example, if :attr:`input` has shape (4, 2) and :attr:`reps`\n",
      "        is (3, 3, 2, 2), then :attr:`input` is treated as if it had the\n",
      "        shape (1, 1, 4, 2).\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            This function is similar to NumPy's tile function.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the tensor whose elements to repeat.\n",
      "            reps (tuple): the number of repetitions per dimension.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.tensor([1, 2, 3])\n",
      "            >>> x.tile((2,))\n",
      "            tensor([1, 2, 3, 1, 2, 3])\n",
      "            >>> y = torch.tensor([[1, 2], [3, 4]])\n",
      "            >>> torch.tile(y, (2, 2))\n",
      "            tensor([[1, 2, 1, 2],\n",
      "                    [3, 4, 3, 4],\n",
      "                    [1, 2, 1, 2],\n",
      "                    [3, 4, 3, 4]])\n",
      "    \n",
      "    topk(...)\n",
      "        topk(input, k, dim=None, largest=True, sorted=True, *, out=None) -> (Tensor, LongTensor)\n",
      "        \n",
      "        Returns the :attr:`k` largest elements of the given :attr:`input` tensor along\n",
      "        a given dimension.\n",
      "        \n",
      "        If :attr:`dim` is not given, the last dimension of the `input` is chosen.\n",
      "        \n",
      "        If :attr:`largest` is ``False`` then the `k` smallest elements are returned.\n",
      "        \n",
      "        A namedtuple of `(values, indices)` is returned, where the `indices` are the indices\n",
      "        of the elements in the original `input` tensor.\n",
      "        \n",
      "        The boolean option :attr:`sorted` if ``True``, will make sure that the returned\n",
      "        `k` elements are themselves sorted\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            k (int): the k in \"top-k\"\n",
      "            dim (int, optional): the dimension to sort along\n",
      "            largest (bool, optional): controls whether to return largest or\n",
      "                   smallest elements\n",
      "            sorted (bool, optional): controls whether to return the elements\n",
      "                   in sorted order\n",
      "        \n",
      "        Keyword args:\n",
      "            out (tuple, optional): the output tuple of (Tensor, LongTensor) that can be\n",
      "                optionally given to be used as output buffers\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.arange(1., 6.)\n",
      "            >>> x\n",
      "            tensor([ 1.,  2.,  3.,  4.,  5.])\n",
      "            >>> torch.topk(x, 3)\n",
      "            torch.return_types.topk(values=tensor([5., 4., 3.]), indices=tensor([4, 3, 2]))\n",
      "    \n",
      "    trace(...)\n",
      "        trace(input) -> Tensor\n",
      "        \n",
      "        Returns the sum of the elements of the diagonal of the input 2-D matrix.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.arange(1., 10.).view(3, 3)\n",
      "            >>> x\n",
      "            tensor([[ 1.,  2.,  3.],\n",
      "                    [ 4.,  5.,  6.],\n",
      "                    [ 7.,  8.,  9.]])\n",
      "            >>> torch.trace(x)\n",
      "            tensor(15.)\n",
      "    \n",
      "    transpose(...)\n",
      "        transpose(input, dim0, dim1) -> Tensor\n",
      "        \n",
      "        Returns a tensor that is a transposed version of :attr:`input`.\n",
      "        The given dimensions :attr:`dim0` and :attr:`dim1` are swapped.\n",
      "        \n",
      "        The resulting :attr:`out` tensor shares its underlying storage with the\n",
      "        :attr:`input` tensor, so changing the content of one would change the content\n",
      "        of the other.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim0 (int): the first dimension to be transposed\n",
      "            dim1 (int): the second dimension to be transposed\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.randn(2, 3)\n",
      "            >>> x\n",
      "            tensor([[ 1.0028, -0.9893,  0.5809],\n",
      "                    [-0.1669,  0.7299,  0.4942]])\n",
      "            >>> torch.transpose(x, 0, 1)\n",
      "            tensor([[ 1.0028, -0.1669],\n",
      "                    [-0.9893,  0.7299],\n",
      "                    [ 0.5809,  0.4942]])\n",
      "    \n",
      "    trapz(...)\n",
      "        trapz(y, x, *, dim=-1) -> Tensor\n",
      "        \n",
      "        Estimate :math:`\\int y\\,dx` along `dim`, using the trapezoid rule.\n",
      "        \n",
      "        Arguments:\n",
      "            y (Tensor): The values of the function to integrate\n",
      "            x (Tensor): The points at which the function `y` is sampled.\n",
      "                If `x` is not in ascending order, intervals on which it is decreasing\n",
      "                contribute negatively to the estimated integral (i.e., the convention\n",
      "                :math:`\\int_a^b f = -\\int_b^a f` is followed).\n",
      "            dim (int): The dimension along which to integrate.\n",
      "                By default, use the last dimension.\n",
      "        \n",
      "        Returns:\n",
      "            A Tensor with the same shape as the input, except with `dim` removed.\n",
      "            Each element of the returned tensor represents the estimated integral\n",
      "            :math:`\\int y\\,dx` along `dim`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> y = torch.randn((2, 3))\n",
      "            >>> y\n",
      "            tensor([[-2.1156,  0.6857, -0.2700],\n",
      "                    [-1.2145,  0.5540,  2.0431]])\n",
      "            >>> x = torch.tensor([[1, 3, 4], [1, 2, 3]])\n",
      "            >>> torch.trapz(y, x)\n",
      "            tensor([-1.2220,  0.9683])\n",
      "        \n",
      "        .. function:: trapz(y, *, dx=1, dim=-1) -> Tensor\n",
      "        \n",
      "        As above, but the sample points are spaced uniformly at a distance of `dx`.\n",
      "        \n",
      "        Arguments:\n",
      "            y (Tensor): The values of the function to integrate\n",
      "        \n",
      "        Keyword args:\n",
      "            dx (float): The distance between points at which `y` is sampled.\n",
      "            dim (int): The dimension along which to integrate.\n",
      "                By default, use the last dimension.\n",
      "        \n",
      "        Returns:\n",
      "            A Tensor with the same shape as the input, except with `dim` removed.\n",
      "            Each element of the returned tensor represents the estimated integral\n",
      "            :math:`\\int y\\,dx` along `dim`.\n",
      "    \n",
      "    triangular_solve(...)\n",
      "        triangular_solve(input, A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "        \n",
      "        Solves a system of equations with a triangular coefficient matrix :math:`A`\n",
      "        and multiple right-hand sides :math:`b`.\n",
      "        \n",
      "        In particular, solves :math:`AX = b` and assumes :math:`A` is upper-triangular\n",
      "        with the default keyword arguments.\n",
      "        \n",
      "        `torch.triangular_solve(b, A)` can take in 2D inputs `b, A` or inputs that are\n",
      "        batches of 2D matrices. If the inputs are batches, then returns\n",
      "        batched outputs `X`\n",
      "        \n",
      "        Supports real-valued and complex-valued inputs.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): multiple right-hand sides of size :math:`(*, m, k)` where\n",
      "                        :math:`*` is zero of more batch dimensions (:math:`b`)\n",
      "            A (Tensor): the input triangular coefficient matrix of size :math:`(*, m, m)`\n",
      "                        where :math:`*` is zero or more batch dimensions\n",
      "            upper (bool, optional): whether to solve the upper-triangular system\n",
      "                of equations (default) or the lower-triangular system of equations. Default: ``True``.\n",
      "            transpose (bool, optional): whether :math:`A` should be transposed before\n",
      "                being sent into the solver. Default: ``False``.\n",
      "            unitriangular (bool, optional): whether :math:`A` is unit triangular.\n",
      "                If True, the diagonal elements of :math:`A` are assumed to be\n",
      "                1 and not referenced from :math:`A`. Default: ``False``.\n",
      "        \n",
      "        Returns:\n",
      "            A namedtuple `(solution, cloned_coefficient)` where `cloned_coefficient`\n",
      "            is a clone of :math:`A` and `solution` is the solution :math:`X` to :math:`AX = b`\n",
      "            (or whatever variant of the system of equations, depending on the keyword arguments.)\n",
      "        \n",
      "        Examples::\n",
      "        \n",
      "            >>> A = torch.randn(2, 2).triu()\n",
      "            >>> A\n",
      "            tensor([[ 1.1527, -1.0753],\n",
      "                    [ 0.0000,  0.7986]])\n",
      "            >>> b = torch.randn(2, 3)\n",
      "            >>> b\n",
      "            tensor([[-0.0210,  2.3513, -1.5492],\n",
      "                    [ 1.5429,  0.7403, -1.0243]])\n",
      "            >>> torch.triangular_solve(b, A)\n",
      "            torch.return_types.triangular_solve(\n",
      "            solution=tensor([[ 1.7841,  2.9046, -2.5405],\n",
      "                    [ 1.9320,  0.9270, -1.2826]]),\n",
      "            cloned_coefficient=tensor([[ 1.1527, -1.0753],\n",
      "                    [ 0.0000,  0.7986]]))\n",
      "    \n",
      "    tril(...)\n",
      "        tril(input, diagonal=0, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices\n",
      "        :attr:`input`, the other elements of the result tensor :attr:`out` are set to 0.\n",
      "        \n",
      "        The lower triangular part of the matrix is defined as the elements on and\n",
      "        below the diagonal.\n",
      "        \n",
      "        The argument :attr:`diagonal` controls which diagonal to consider. If\n",
      "        :attr:`diagonal` = 0, all elements on and below the main diagonal are\n",
      "        retained. A positive value includes just as many diagonals above the main\n",
      "        diagonal, and similarly a negative value excludes just as many diagonals below\n",
      "        the main diagonal. The main diagonal are the set of indices\n",
      "        :math:`\\lbrace (i, i) \\rbrace` for :math:`i \\in [0, \\min\\{d_{1}, d_{2}\\} - 1]` where\n",
      "        :math:`d_{1}, d_{2}` are the dimensions of the matrix.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            diagonal (int, optional): the diagonal to consider\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(3, 3)\n",
      "            >>> a\n",
      "            tensor([[-1.0813, -0.8619,  0.7105],\n",
      "                    [ 0.0935,  0.1380,  2.2112],\n",
      "                    [-0.3409, -0.9828,  0.0289]])\n",
      "            >>> torch.tril(a)\n",
      "            tensor([[-1.0813,  0.0000,  0.0000],\n",
      "                    [ 0.0935,  0.1380,  0.0000],\n",
      "                    [-0.3409, -0.9828,  0.0289]])\n",
      "        \n",
      "            >>> b = torch.randn(4, 6)\n",
      "            >>> b\n",
      "            tensor([[ 1.2219,  0.5653, -0.2521, -0.2345,  1.2544,  0.3461],\n",
      "                    [ 0.4785, -0.4477,  0.6049,  0.6368,  0.8775,  0.7145],\n",
      "                    [ 1.1502,  3.2716, -1.1243, -0.5413,  0.3615,  0.6864],\n",
      "                    [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024,  0.0978]])\n",
      "            >>> torch.tril(b, diagonal=1)\n",
      "            tensor([[ 1.2219,  0.5653,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "                    [ 0.4785, -0.4477,  0.6049,  0.0000,  0.0000,  0.0000],\n",
      "                    [ 1.1502,  3.2716, -1.1243, -0.5413,  0.0000,  0.0000],\n",
      "                    [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024,  0.0000]])\n",
      "            >>> torch.tril(b, diagonal=-1)\n",
      "            tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "                    [ 0.4785,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "                    [ 1.1502,  3.2716,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "                    [-0.0614, -0.7344, -1.3164,  0.0000,  0.0000,  0.0000]])\n",
      "    \n",
      "    tril_indices(...)\n",
      "        tril_indices(row, col, offset=0, *, dtype=torch.long, device='cpu', layout=torch.strided) -> Tensor\n",
      "        \n",
      "        Returns the indices of the lower triangular part of a :attr:`row`-by-\n",
      "        :attr:`col` matrix in a 2-by-N Tensor, where the first row contains row\n",
      "        coordinates of all indices and the second row contains column coordinates.\n",
      "        Indices are ordered based on rows and then columns.\n",
      "        \n",
      "        The lower triangular part of the matrix is defined as the elements on and\n",
      "        below the diagonal.\n",
      "        \n",
      "        The argument :attr:`offset` controls which diagonal to consider. If\n",
      "        :attr:`offset` = 0, all elements on and below the main diagonal are\n",
      "        retained. A positive value includes just as many diagonals above the main\n",
      "        diagonal, and similarly a negative value excludes just as many diagonals below\n",
      "        the main diagonal. The main diagonal are the set of indices\n",
      "        :math:`\\lbrace (i, i) \\rbrace` for :math:`i \\in [0, \\min\\{d_{1}, d_{2}\\} - 1]`\n",
      "        where :math:`d_{1}, d_{2}` are the dimensions of the matrix.\n",
      "        \n",
      "        .. note::\n",
      "            When running on CUDA, ``row * col`` must be less than :math:`2^{59}` to\n",
      "            prevent overflow during calculation.\n",
      "        \n",
      "        Args:\n",
      "            row (``int``): number of rows in the 2-D matrix.\n",
      "            col (``int``): number of columns in the 2-D matrix.\n",
      "            offset (``int``): diagonal offset from the main diagonal.\n",
      "                Default: if not provided, 0.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, ``torch.long``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            layout (:class:`torch.layout`, optional): currently only support ``torch.strided``.\n",
      "        \n",
      "        Example::\n",
      "            >>> a = torch.tril_indices(3, 3)\n",
      "            >>> a\n",
      "            tensor([[0, 1, 1, 2, 2, 2],\n",
      "                    [0, 0, 1, 0, 1, 2]])\n",
      "        \n",
      "            >>> a = torch.tril_indices(4, 3, -1)\n",
      "            >>> a\n",
      "            tensor([[1, 2, 2, 3, 3, 3],\n",
      "                    [0, 0, 1, 0, 1, 2]])\n",
      "        \n",
      "            >>> a = torch.tril_indices(4, 3, 1)\n",
      "            >>> a\n",
      "            tensor([[0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "                    [0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      "    \n",
      "    triplet_margin_loss(...)\n",
      "    \n",
      "    triu(...)\n",
      "        triu(input, diagonal=0, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices\n",
      "        :attr:`input`, the other elements of the result tensor :attr:`out` are set to 0.\n",
      "        \n",
      "        The upper triangular part of the matrix is defined as the elements on and\n",
      "        above the diagonal.\n",
      "        \n",
      "        The argument :attr:`diagonal` controls which diagonal to consider. If\n",
      "        :attr:`diagonal` = 0, all elements on and above the main diagonal are\n",
      "        retained. A positive value excludes just as many diagonals above the main\n",
      "        diagonal, and similarly a negative value includes just as many diagonals below\n",
      "        the main diagonal. The main diagonal are the set of indices\n",
      "        :math:`\\lbrace (i, i) \\rbrace` for :math:`i \\in [0, \\min\\{d_{1}, d_{2}\\} - 1]` where\n",
      "        :math:`d_{1}, d_{2}` are the dimensions of the matrix.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            diagonal (int, optional): the diagonal to consider\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(3, 3)\n",
      "            >>> a\n",
      "            tensor([[ 0.2309,  0.5207,  2.0049],\n",
      "                    [ 0.2072, -1.0680,  0.6602],\n",
      "                    [ 0.3480, -0.5211, -0.4573]])\n",
      "            >>> torch.triu(a)\n",
      "            tensor([[ 0.2309,  0.5207,  2.0049],\n",
      "                    [ 0.0000, -1.0680,  0.6602],\n",
      "                    [ 0.0000,  0.0000, -0.4573]])\n",
      "            >>> torch.triu(a, diagonal=1)\n",
      "            tensor([[ 0.0000,  0.5207,  2.0049],\n",
      "                    [ 0.0000,  0.0000,  0.6602],\n",
      "                    [ 0.0000,  0.0000,  0.0000]])\n",
      "            >>> torch.triu(a, diagonal=-1)\n",
      "            tensor([[ 0.2309,  0.5207,  2.0049],\n",
      "                    [ 0.2072, -1.0680,  0.6602],\n",
      "                    [ 0.0000, -0.5211, -0.4573]])\n",
      "        \n",
      "            >>> b = torch.randn(4, 6)\n",
      "            >>> b\n",
      "            tensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],\n",
      "                    [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],\n",
      "                    [ 0.4333,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],\n",
      "                    [-0.9888,  1.0679, -1.3337, -1.6556,  0.4798,  0.2830]])\n",
      "            >>> torch.triu(b, diagonal=1)\n",
      "            tensor([[ 0.0000, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],\n",
      "                    [ 0.0000,  0.0000, -1.2919,  1.3378, -0.1768, -1.0857],\n",
      "                    [ 0.0000,  0.0000,  0.0000, -1.0432,  0.9348, -0.4410],\n",
      "                    [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4798,  0.2830]])\n",
      "            >>> torch.triu(b, diagonal=-1)\n",
      "            tensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],\n",
      "                    [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],\n",
      "                    [ 0.0000,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],\n",
      "                    [ 0.0000,  0.0000, -1.3337, -1.6556,  0.4798,  0.2830]])\n",
      "    \n",
      "    triu_indices(...)\n",
      "        triu_indices(row, col, offset=0, *, dtype=torch.long, device='cpu', layout=torch.strided) -> Tensor\n",
      "        \n",
      "        Returns the indices of the upper triangular part of a :attr:`row` by\n",
      "        :attr:`col` matrix in a 2-by-N Tensor, where the first row contains row\n",
      "        coordinates of all indices and the second row contains column coordinates.\n",
      "        Indices are ordered based on rows and then columns.\n",
      "        \n",
      "        The upper triangular part of the matrix is defined as the elements on and\n",
      "        above the diagonal.\n",
      "        \n",
      "        The argument :attr:`offset` controls which diagonal to consider. If\n",
      "        :attr:`offset` = 0, all elements on and above the main diagonal are\n",
      "        retained. A positive value excludes just as many diagonals above the main\n",
      "        diagonal, and similarly a negative value includes just as many diagonals below\n",
      "        the main diagonal. The main diagonal are the set of indices\n",
      "        :math:`\\lbrace (i, i) \\rbrace` for :math:`i \\in [0, \\min\\{d_{1}, d_{2}\\} - 1]`\n",
      "        where :math:`d_{1}, d_{2}` are the dimensions of the matrix.\n",
      "        \n",
      "        .. note::\n",
      "            When running on CUDA, ``row * col`` must be less than :math:`2^{59}` to\n",
      "            prevent overflow during calculation.\n",
      "        \n",
      "        Args:\n",
      "            row (``int``): number of rows in the 2-D matrix.\n",
      "            col (``int``): number of columns in the 2-D matrix.\n",
      "            offset (``int``): diagonal offset from the main diagonal.\n",
      "                Default: if not provided, 0.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, ``torch.long``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            layout (:class:`torch.layout`, optional): currently only support ``torch.strided``.\n",
      "        \n",
      "        Example::\n",
      "            >>> a = torch.triu_indices(3, 3)\n",
      "            >>> a\n",
      "            tensor([[0, 0, 0, 1, 1, 2],\n",
      "                    [0, 1, 2, 1, 2, 2]])\n",
      "        \n",
      "            >>> a = torch.triu_indices(4, 3, -1)\n",
      "            >>> a\n",
      "            tensor([[0, 0, 0, 1, 1, 1, 2, 2, 3],\n",
      "                    [0, 1, 2, 0, 1, 2, 1, 2, 2]])\n",
      "        \n",
      "            >>> a = torch.triu_indices(4, 3, 1)\n",
      "            >>> a\n",
      "            tensor([[0, 0, 1],\n",
      "                    [1, 2, 2]])\n",
      "    \n",
      "    true_divide(...)\n",
      "        true_divide(dividend, divisor, *, out) -> Tensor\n",
      "        \n",
      "        Alias for :func:`torch.div` with ``rounding_mode=None``.\n",
      "    \n",
      "    trunc(...)\n",
      "        trunc(input, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with the truncated integer values of\n",
      "        the elements of :attr:`input`.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4)\n",
      "            >>> a\n",
      "            tensor([ 3.4742,  0.5466, -0.8008, -0.9079])\n",
      "            >>> torch.trunc(a)\n",
      "            tensor([ 3.,  0., -0., -0.])\n",
      "    \n",
      "    trunc_(...)\n",
      "    \n",
      "    typename(o)\n",
      "    \n",
      "    unbind(...)\n",
      "        unbind(input, dim=0) -> seq\n",
      "        \n",
      "        Removes a tensor dimension.\n",
      "        \n",
      "        Returns a tuple of all slices along a given dimension, already without it.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): the tensor to unbind\n",
      "            dim (int): dimension to remove\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.unbind(torch.tensor([[1, 2, 3],\n",
      "            >>>                            [4, 5, 6],\n",
      "            >>>                            [7, 8, 9]]))\n",
      "            (tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9]))\n",
      "    \n",
      "    unify_type_list(...) method of builtins.PyCapsule instance\n",
      "        unify_type_list(arg0: List[c10::Type]) -> c10::Type\n",
      "    \n",
      "    unique_consecutive(*args, **kwargs)\n",
      "        Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "        \n",
      "        .. note:: This function is different from :func:`torch.unique` in the sense that this function\n",
      "            only eliminates consecutive duplicate values. This semantics is similar to `std::unique`\n",
      "            in C++.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor\n",
      "            return_inverse (bool): Whether to also return the indices for where\n",
      "                elements in the original input ended up in the returned unique list.\n",
      "            return_counts (bool): Whether to also return the counts for each unique\n",
      "                element.\n",
      "            dim (int): the dimension to apply unique. If ``None``, the unique of the\n",
      "                flattened input is returned. default: ``None``\n",
      "        \n",
      "        Returns:\n",
      "            (Tensor, Tensor (optional), Tensor (optional)): A tensor or a tuple of tensors containing\n",
      "        \n",
      "                - **output** (*Tensor*): the output list of unique scalar elements.\n",
      "                - **inverse_indices** (*Tensor*): (optional) if\n",
      "                  :attr:`return_inverse` is True, there will be an additional\n",
      "                  returned tensor (same shape as input) representing the indices\n",
      "                  for where elements in the original input map to in the output;\n",
      "                  otherwise, this function will only return a single tensor.\n",
      "                - **counts** (*Tensor*): (optional) if\n",
      "                  :attr:`return_counts` is True, there will be an additional\n",
      "                  returned tensor (same shape as output or output.size(dim),\n",
      "                  if dim was specified) representing the number of occurrences\n",
      "                  for each unique value or tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.tensor([1, 1, 2, 2, 3, 1, 1, 2])\n",
      "            >>> output = torch.unique_consecutive(x)\n",
      "            >>> output\n",
      "            tensor([1, 2, 3, 1, 2])\n",
      "        \n",
      "            >>> output, inverse_indices = torch.unique_consecutive(x, return_inverse=True)\n",
      "            >>> output\n",
      "            tensor([1, 2, 3, 1, 2])\n",
      "            >>> inverse_indices\n",
      "            tensor([0, 0, 1, 1, 2, 3, 3, 4])\n",
      "        \n",
      "            >>> output, counts = torch.unique_consecutive(x, return_counts=True)\n",
      "            >>> output\n",
      "            tensor([1, 2, 3, 1, 2])\n",
      "            >>> counts\n",
      "            tensor([2, 2, 1, 2, 1])\n",
      "    \n",
      "    unsafe_chunk(...)\n",
      "        unsafe_chunk(input, chunks, dim=0) -> List of Tensors\n",
      "        \n",
      "        Works like :func:`torch.chunk` but without enforcing the autograd restrictions\n",
      "        on inplace modification of the outputs.\n",
      "        \n",
      "        .. warning::\n",
      "            This function is safe to use as long as only the input, or only the outputs\n",
      "            are modified inplace after calling this function. It is user's\n",
      "            responsibility to ensure that is the case. If both the input and one or more\n",
      "            of the outputs are modified inplace, gradients computed by autograd will be\n",
      "            silently incorrect.\n",
      "    \n",
      "    unsafe_split(...)\n",
      "        unsafe_split(tensor, split_size_or_sections, dim=0) -> List of Tensors\n",
      "        \n",
      "        Works like :func:`torch.split` but without enforcing the autograd restrictions\n",
      "        on inplace modification of the outputs.\n",
      "        \n",
      "        .. warning::\n",
      "            This function is safe to use as long as only the input, or only the outputs\n",
      "            are modified inplace after calling this function. It is user's\n",
      "            responsibility to ensure that is the case. If both the input and one or more\n",
      "            of the outputs are modified inplace, gradients computed by autograd will be\n",
      "            silently incorrect.\n",
      "    \n",
      "    unsafe_split_with_sizes(...)\n",
      "    \n",
      "    unsqueeze(...)\n",
      "        unsqueeze(input, dim) -> Tensor\n",
      "        \n",
      "        Returns a new tensor with a dimension of size one inserted at the\n",
      "        specified position.\n",
      "        \n",
      "        The returned tensor shares the same underlying data with this tensor.\n",
      "        \n",
      "        A :attr:`dim` value within the range ``[-input.dim() - 1, input.dim() + 1)``\n",
      "        can be used. Negative :attr:`dim` will correspond to :meth:`unsqueeze`\n",
      "        applied at :attr:`dim` = ``dim + input.dim() + 1``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int): the index at which to insert the singleton dimension\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.tensor([1, 2, 3, 4])\n",
      "            >>> torch.unsqueeze(x, 0)\n",
      "            tensor([[ 1,  2,  3,  4]])\n",
      "            >>> torch.unsqueeze(x, 1)\n",
      "            tensor([[ 1],\n",
      "                    [ 2],\n",
      "                    [ 3],\n",
      "                    [ 4]])\n",
      "    \n",
      "    use_deterministic_algorithms(d)\n",
      "        Sets whether PyTorch operations must use \"deterministic\"\n",
      "        algorithms. That is, algorithms which, given the same input, and when\n",
      "        run on the same software and hardware, always produce the same output.\n",
      "        When True, operations will use deterministic algorithms when available,\n",
      "        and if only nondeterministic algorithms are available they will throw a\n",
      "        :class:RuntimeError when called.\n",
      "        \n",
      "        .. warning::\n",
      "            This feature is in beta, and its design and implementation may change\n",
      "            in the future.\n",
      "        \n",
      "        The following normally-nondeterministic operations will act\n",
      "        deterministically when `d=True`:\n",
      "        \n",
      "            * :class:`torch.nn.Conv1d` when called on CUDA tensor\n",
      "            * :class:`torch.nn.Conv2d` when called on CUDA tensor\n",
      "            * :class:`torch.nn.Conv3d` when called on CUDA tensor\n",
      "            * :class:`torch.nn.ConvTranspose1d` when called on CUDA tensor\n",
      "            * :class:`torch.nn.ConvTranspose2d` when called on CUDA tensor\n",
      "            * :class:`torch.nn.ConvTranspose3d` when called on CUDA tensor\n",
      "            * :func:`torch.bmm` when called on sparse-dense CUDA tensors\n",
      "            * :func:`torch.__getitem__` backward when `self` is a CPU tensor and\n",
      "              ``indices`` is a list of tensors\n",
      "            * :func:`torch.index_put` with ``accumulate=True`` when called on a CPU\n",
      "              tensor\n",
      "        \n",
      "        The following normally-nondeterministic operations will throw a\n",
      "        :class:`RuntimeError` when `d=True`:\n",
      "        \n",
      "            * :class:`torch.nn.AvgPool3d` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.AdaptiveAvgPool2d` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.AdaptiveAvgPool3d` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.MaxPool3d` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.AdaptiveMaxPool2d` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.FractionalMaxPool2d` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.FractionalMaxPool3d` when called on a CUDA tensor that requires grad\n",
      "            * :func:`torch.nn.functional.interpolate` when called on a CUDA tensor that requires grad\n",
      "              and one of the following modes is used:\n",
      "        \n",
      "              - `linear`\n",
      "              - `bilinear`\n",
      "              - `bicubic`\n",
      "              - `trilinear`\n",
      "        \n",
      "            * :class:`torch.nn.ReflectionPad1d` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.ReflectionPad2d` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.ReplicationPad1d` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.ReplicationPad2d` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.ReplicationPad3d` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.NLLLoss` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.CTCLoss` when called on a CUDA tensor that requires grad\n",
      "            * :class:`torch.nn.EmbeddingBag` when called on a CUDA tensor that requires grad\n",
      "            * :func:`torch.scatter_add_` when called on a CUDA tensor\n",
      "            * :func:`torch.index_add_` when called on a CUDA tensor\n",
      "            * :func:`torch.index_copy`\n",
      "            * :func:`torch.index_select` when called on a CUDA tensor that requires grad\n",
      "            * :func:`torch.repeat_interleave` when called on a CUDA tensor that requires grad\n",
      "            * :func:`torch.histc` when called on a CUDA tensor\n",
      "            * :func:`torch.bincount` when called on a CUDA tensor\n",
      "            * :func:`torch.kthvalue` with called on a CUDA tensor\n",
      "            * :func:`torch.median` with indices output when called on a CUDA tensor\n",
      "        \n",
      "        A handful of CUDA operations are nondeterministic if the CUDA version is\n",
      "        10.2 or greater, unless the environment variable `CUBLAS_WORKSPACE_CONFIG=:4096:8`\n",
      "        or `CUBLAS_WORKSPACE_CONFIG=:16:8` is set. See the CUDA documentation for more\n",
      "        details: `<https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility>`_\n",
      "        If one of these environment variable configurations is not set, a :class:`RuntimeError`\n",
      "        will be raised from these operations when called with CUDA tensors:\n",
      "        \n",
      "            * :func:`torch.mm`\n",
      "            * :func:`torch.mv`\n",
      "            * :func:`torch.bmm`\n",
      "        \n",
      "        Note that deterministic operations tend to have worse performance than\n",
      "        non-deterministic operations.\n",
      "        \n",
      "        Args:\n",
      "            d (:class:`bool`): If True, force operations to be deterministic.\n",
      "                               If False, allow non-deterministic operations.\n",
      "    \n",
      "    vander(...)\n",
      "        vander(x, N=None, increasing=False) -> Tensor\n",
      "        \n",
      "        Generates a Vandermonde matrix.\n",
      "        \n",
      "        The columns of the output matrix are elementwise powers of the input vector :math:`x^{(N-1)}, x^{(N-2)}, ..., x^0`.\n",
      "        If increasing is True, the order of the columns is reversed :math:`x^0, x^1, ..., x^{(N-1)}`. Such a\n",
      "        matrix with a geometric progression in each row is named for Alexandre-Theophile Vandermonde.\n",
      "        \n",
      "        Arguments:\n",
      "            x (Tensor): 1-D input tensor.\n",
      "            N (int, optional): Number of columns in the output. If N is not specified,\n",
      "                a square array is returned :math:`(N = len(x))`.\n",
      "            increasing (bool, optional): Order of the powers of the columns. If True,\n",
      "                the powers increase from left to right, if False (the default) they are reversed.\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: Vandermonde matrix. If increasing is False, the first column is :math:`x^{(N-1)}`,\n",
      "            the second :math:`x^{(N-2)}` and so forth. If increasing is True, the columns\n",
      "            are :math:`x^0, x^1, ..., x^{(N-1)}`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.tensor([1, 2, 3, 5])\n",
      "            >>> torch.vander(x)\n",
      "            tensor([[  1,   1,   1,   1],\n",
      "                    [  8,   4,   2,   1],\n",
      "                    [ 27,   9,   3,   1],\n",
      "                    [125,  25,   5,   1]])\n",
      "            >>> torch.vander(x, N=3)\n",
      "            tensor([[ 1,  1,  1],\n",
      "                    [ 4,  2,  1],\n",
      "                    [ 9,  3,  1],\n",
      "                    [25,  5,  1]])\n",
      "            >>> torch.vander(x, N=3, increasing=True)\n",
      "            tensor([[ 1,  1,  1],\n",
      "                    [ 1,  2,  4],\n",
      "                    [ 1,  3,  9],\n",
      "                    [ 1,  5, 25]])\n",
      "    \n",
      "    var(...)\n",
      "        var(input, unbiased=True) -> Tensor\n",
      "        \n",
      "        Returns the variance of all elements in the :attr:`input` tensor.\n",
      "        \n",
      "        If :attr:`unbiased` is ``False``, then the variance will be calculated via the\n",
      "        biased estimator. Otherwise, Bessel's correction will be used.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            unbiased (bool): whether to use the unbiased estimation or not\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 3)\n",
      "            >>> a\n",
      "            tensor([[-0.3425, -1.2636, -0.4864]])\n",
      "            >>> torch.var(a)\n",
      "            tensor(0.2455)\n",
      "        \n",
      "        \n",
      "        .. function:: var(input, dim, unbiased=True, keepdim=False, *, out=None) -> Tensor\n",
      "        \n",
      "        Returns the variance of each row of the :attr:`input` tensor in the given\n",
      "        dimension :attr:`dim`.\n",
      "        \n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "        as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "        output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
      "        \n",
      "        \n",
      "        If :attr:`unbiased` is ``False``, then the variance will be calculated via the\n",
      "        biased estimator. Otherwise, Bessel's correction will be used.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "            unbiased (bool): whether to use the unbiased estimation or not\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[-0.3567,  1.7385, -1.3042,  0.7423],\n",
      "                    [ 1.3436, -0.1015, -0.9834, -0.8438],\n",
      "                    [ 0.6056,  0.1089, -0.3112, -1.4085],\n",
      "                    [-0.7700,  0.6074, -0.1469,  0.7777]])\n",
      "            >>> torch.var(a, 1)\n",
      "            tensor([ 1.7444,  1.1363,  0.7356,  0.5112])\n",
      "    \n",
      "    var_mean(...)\n",
      "        var_mean(input, unbiased=True) -> (Tensor, Tensor)\n",
      "        \n",
      "        Returns the variance and mean of all elements in the :attr:`input` tensor.\n",
      "        \n",
      "        If :attr:`unbiased` is ``False``, then the variance will be calculated via the\n",
      "        biased estimator. Otherwise, Bessel's correction will be used.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            unbiased (bool): whether to use the unbiased estimation or not\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(1, 3)\n",
      "            >>> a\n",
      "            tensor([[0.0146, 0.4258, 0.2211]])\n",
      "            >>> torch.var_mean(a)\n",
      "            (tensor(0.0423), tensor(0.2205))\n",
      "        \n",
      "        .. function:: var_mean(input, dim, keepdim=False, unbiased=True) -> (Tensor, Tensor)\n",
      "        \n",
      "        Returns the variance and mean of each row of the :attr:`input` tensor in the given\n",
      "        dimension :attr:`dim`.\n",
      "        \n",
      "        \n",
      "        If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "        as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
      "        Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "        output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
      "        \n",
      "        \n",
      "        If :attr:`unbiased` is ``False``, then the variance will be calculated via the\n",
      "        biased estimator. Otherwise, Bessel's correction will be used.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "            dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "            keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "            unbiased (bool): whether to use the unbiased estimation or not\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.randn(4, 4)\n",
      "            >>> a\n",
      "            tensor([[-1.5650,  2.0415, -0.1024, -0.5790],\n",
      "                    [ 0.2325, -2.6145, -1.6428, -0.3537],\n",
      "                    [-0.2159, -1.1069,  1.2882, -1.3265],\n",
      "                    [-0.6706, -1.5893,  0.6827,  1.6727]])\n",
      "            >>> torch.var_mean(a, 1)\n",
      "            (tensor([2.3174, 1.6403, 1.4092, 2.0791]), tensor([-0.0512, -1.0946, -0.3403,  0.0239]))\n",
      "    \n",
      "    vdot(...)\n",
      "        vdot(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes the dot product of two 1D tensors. The vdot(a, b) function handles complex numbers\n",
      "        differently than dot(a, b). If the first argument is complex, the complex conjugate of the\n",
      "        first argument is used for the calculation of the dot product.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            Unlike NumPy's vdot, torch.vdot intentionally only supports computing the dot product\n",
      "            of two 1D tensors with the same number of elements.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): first tensor in the dot product, must be 1D. Its conjugate is used if it's complex.\n",
      "            other (Tensor): second tensor in the dot product, must be 1D.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.vdot(torch.tensor([2, 3]), torch.tensor([2, 1]))\n",
      "            tensor(7)\n",
      "            >>> a = torch.tensor((1 +2j, 3 - 1j))\n",
      "            >>> b = torch.tensor((2 +1j, 4 - 0j))\n",
      "            >>> torch.vdot(a, b)\n",
      "            tensor([16.+1.j])\n",
      "            >>> torch.vdot(b, a)\n",
      "            tensor([16.-1.j])\n",
      "    \n",
      "    view_as_complex(...)\n",
      "        view_as_complex(input) -> Tensor\n",
      "        \n",
      "        Returns a view of :attr:`input` as a complex tensor. For an input complex\n",
      "        tensor of :attr:`size` :math:`m1, m2, \\dots, mi, 2`, this function returns a\n",
      "        new complex tensor of :attr:`size` :math:`m1, m2, \\dots, mi` where the last\n",
      "        dimension of the input tensor is expected to represent the real and imaginary\n",
      "        components of complex numbers.\n",
      "        \n",
      "        .. warning::\n",
      "            :func:`view_as_complex` is only supported for tensors with\n",
      "            :class:`torch.dtype` ``torch.float64`` and ``torch.float32``.  The input is\n",
      "            expected to have the last dimension of :attr:`size` 2. In addition, the\n",
      "            tensor must have a `stride` of 1 for its last dimension. The strides of all\n",
      "            other dimensions must be even numbers.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> x=torch.randn(4, 2)\n",
      "            >>> x\n",
      "            tensor([[ 1.6116, -0.5772],\n",
      "                    [-1.4606, -0.9120],\n",
      "                    [ 0.0786, -1.7497],\n",
      "                    [-0.6561, -1.6623]])\n",
      "            >>> torch.view_as_complex(x)\n",
      "            tensor([(1.6116-0.5772j), (-1.4606-0.9120j), (0.0786-1.7497j), (-0.6561-1.6623j)])\n",
      "    \n",
      "    view_as_real(...)\n",
      "        view_as_real(input) -> Tensor\n",
      "        \n",
      "        Returns a view of :attr:`input` as a real tensor. For an input complex tensor of\n",
      "        :attr:`size` :math:`m1, m2, \\dots, mi`, this function returns a new\n",
      "        real tensor of size :math:`m1, m2, \\dots, mi, 2`, where the last dimension of size 2\n",
      "        represents the real and imaginary components of complex numbers.\n",
      "        \n",
      "        .. warning::\n",
      "            :func:`view_as_real` is only supported for tensors with ``complex dtypes``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the input tensor.\n",
      "        \n",
      "        Example::\n",
      "            >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "            >>> x\n",
      "            tensor([(0.4737-0.3839j), (-0.2098-0.6699j), (0.3470-0.9451j), (-0.5174-1.3136j)])\n",
      "            >>> torch.view_as_real(x)\n",
      "            tensor([[ 0.4737, -0.3839],\n",
      "                    [-0.2098, -0.6699],\n",
      "                    [ 0.3470, -0.9451],\n",
      "                    [-0.5174, -1.3136]])\n",
      "    \n",
      "    vstack(...)\n",
      "        vstack(tensors, *, out=None) -> Tensor\n",
      "        \n",
      "        Stack tensors in sequence vertically (row wise).\n",
      "        \n",
      "        This is equivalent to concatenation along the first axis after all 1-D tensors have been reshaped by :func:`torch.atleast_2d`.\n",
      "        \n",
      "        Args:\n",
      "            tensors (sequence of Tensors): sequence of tensors to concatenate\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> a = torch.tensor([1, 2, 3])\n",
      "            >>> b = torch.tensor([4, 5, 6])\n",
      "            >>> torch.vstack((a,b))\n",
      "            tensor([[1, 2, 3],\n",
      "                    [4, 5, 6]])\n",
      "            >>> a = torch.tensor([[1],[2],[3]])\n",
      "            >>> b = torch.tensor([[4],[5],[6]])\n",
      "            >>> torch.vstack((a,b))\n",
      "            tensor([[1],\n",
      "                    [2],\n",
      "                    [3],\n",
      "                    [4],\n",
      "                    [5],\n",
      "                    [6]])\n",
      "    \n",
      "    wait(...) method of builtins.PyCapsule instance\n",
      "        wait(arg0: torch._C.Future) -> object\n",
      "    \n",
      "    where(...)\n",
      "        where(condition, x, y) -> Tensor\n",
      "        \n",
      "        Return a tensor of elements selected from either :attr:`x` or :attr:`y`, depending on :attr:`condition`.\n",
      "        \n",
      "        The operation is defined as:\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_i = \\begin{cases}\n",
      "                \\text{x}_i & \\text{if } \\text{condition}_i \\\\\n",
      "                \\text{y}_i & \\text{otherwise} \\\\\n",
      "            \\end{cases}\n",
      "        \n",
      "        .. note::\n",
      "            The tensors :attr:`condition`, :attr:`x`, :attr:`y` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "        \n",
      "        .. note::\n",
      "            Currently valid scalar and tensor combination are\n",
      "            1. Scalar of floating dtype and torch.double\n",
      "            2. Scalar of integral dtype and torch.long\n",
      "            3. Scalar of complex dtype and torch.complex128\n",
      "        \n",
      "        Arguments:\n",
      "            condition (BoolTensor): When True (nonzero), yield x, otherwise yield y\n",
      "            x (Tensor or Scalar): value (if :attr:x is a scalar) or values selected at indices\n",
      "                                  where :attr:`condition` is ``True``\n",
      "            y (Tensor or Scalar): value (if :attr:x is a scalar) or values selected at indices\n",
      "                                  where :attr:`condition` is ``False``\n",
      "        \n",
      "        Returns:\n",
      "            Tensor: A tensor of shape equal to the broadcasted shape of :attr:`condition`, :attr:`x`, :attr:`y`\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.randn(3, 2)\n",
      "            >>> y = torch.ones(3, 2)\n",
      "            >>> x\n",
      "            tensor([[-0.4620,  0.3139],\n",
      "                    [ 0.3898, -0.7197],\n",
      "                    [ 0.0478, -0.1657]])\n",
      "            >>> torch.where(x > 0, x, y)\n",
      "            tensor([[ 1.0000,  0.3139],\n",
      "                    [ 0.3898,  1.0000],\n",
      "                    [ 0.0478,  1.0000]])\n",
      "            >>> x = torch.randn(2, 2, dtype=torch.double)\n",
      "            >>> x\n",
      "            tensor([[ 1.0779,  0.0383],\n",
      "                    [-0.8785, -1.1089]], dtype=torch.float64)\n",
      "            >>> torch.where(x > 0, x, 0.)\n",
      "            tensor([[1.0779, 0.0383],\n",
      "                    [0.0000, 0.0000]], dtype=torch.float64)\n",
      "        \n",
      "        .. function:: where(condition) -> tuple of LongTensor\n",
      "        \n",
      "        ``torch.where(condition)`` is identical to\n",
      "        ``torch.nonzero(condition, as_tuple=True)``.\n",
      "        \n",
      "        .. note::\n",
      "            See also :func:`torch.nonzero`.\n",
      "    \n",
      "    xlogy(...)\n",
      "        xlogy(input, other, *, out=None) -> Tensor\n",
      "        \n",
      "        Computes ``input * log(other)`` with the following cases.\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} = \\begin{cases}\n",
      "                \\text{NaN} & \\text{if } \\text{other}_{i} = \\text{NaN} \\\\\n",
      "                0 & \\text{if } \\text{input}_{i} = 0.0 \\\\\n",
      "                \\text{input}_{i} * \\log{(\\text{other}_{i})} & \\text{otherwise}\n",
      "            \\end{cases}\n",
      "        \n",
      "        Similar to SciPy's `scipy.special.xlogy`.\n",
      "        \n",
      "        \n",
      "        \n",
      "        Args:\n",
      "            input (Number or Tensor)\n",
      "            other (Number or Tensor)\n",
      "        \n",
      "        .. note:: At least one of :attr:`input` or :attr:`other` must be a tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> x = torch.zeros(5,)\n",
      "            >>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])\n",
      "            >>> torch.xlogy(x, y)\n",
      "            tensor([0., 0., 0., 0., nan])\n",
      "            >>> x = torch.tensor([1, 2, 3])\n",
      "            >>> y = torch.tensor([3, 2, 1])\n",
      "            >>> torch.xlogy(x, y)\n",
      "            tensor([1.0986, 1.3863, 0.0000])\n",
      "            >>> torch.xlogy(x, 4)\n",
      "            tensor([1.3863, 2.7726, 4.1589])\n",
      "            >>> torch.xlogy(2, y)\n",
      "            tensor([2.1972, 1.3863, 0.0000])\n",
      "    \n",
      "    xlogy_(...)\n",
      "    \n",
      "    zero_(...)\n",
      "    \n",
      "    zeros(...)\n",
      "        zeros(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with the scalar value `0`, with the shape defined\n",
      "        by the variable argument :attr:`size`.\n",
      "        \n",
      "        Args:\n",
      "            size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "                Can be a variable number of arguments or a collection like a list or tuple.\n",
      "        \n",
      "        Keyword args:\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.zeros(2, 3)\n",
      "            tensor([[ 0.,  0.,  0.],\n",
      "                    [ 0.,  0.,  0.]])\n",
      "        \n",
      "            >>> torch.zeros(5)\n",
      "            tensor([ 0.,  0.,  0.,  0.,  0.])\n",
      "    \n",
      "    zeros_like(...)\n",
      "        zeros_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with the scalar value `0`, with the same size as\n",
      "        :attr:`input`. ``torch.zeros_like(input)`` is equivalent to\n",
      "        ``torch.zeros(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)``.\n",
      "        \n",
      "        .. warning::\n",
      "            As of 0.4, this function does not support an :attr:`out` keyword. As an alternative,\n",
      "            the old ``torch.zeros_like(input, out=output)`` is equivalent to\n",
      "            ``torch.zeros(input.size(), out=output)``.\n",
      "        \n",
      "        Args:\n",
      "            input (Tensor): the size of :attr:`input` will determine size of the output tensor.\n",
      "        \n",
      "        Keyword args:\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned Tensor.\n",
      "                Default: if ``None``, defaults to the dtype of :attr:`input`.\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned tensor.\n",
      "                Default: if ``None``, defaults to the layout of :attr:`input`.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, defaults to the device of :attr:`input`.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "            memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "                returned Tensor. Default: ``torch.preserve_format``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> input = torch.empty(2, 3)\n",
      "            >>> torch.zeros_like(input)\n",
      "            tensor([[ 0.,  0.,  0.],\n",
      "                    [ 0.,  0.,  0.]])\n",
      "\n",
      "DATA\n",
      "    AVG = <AggregationType.AVG: 1>\n",
      "    CONV_BN_FUSION = <MobileOptimizerType.CONV_BN_FUSION: 0>\n",
      "    FUSE_ADD_RELU = <MobileOptimizerType.FUSE_ADD_RELU: 3>\n",
      "    HOIST_CONV_PACKED_PARAMS = <MobileOptimizerType.HOIST_CONV_PACKED_PARA...\n",
      "    INSERT_FOLD_PREPACK_OPS = <MobileOptimizerType.INSERT_FOLD_PREPACK_OPS...\n",
      "    REMOVE_DROPOUT = <MobileOptimizerType.REMOVE_DROPOUT: 2>\n",
      "    SUM = <AggregationType.SUM: 0>\n",
      "    __all__ = ['typename', 'is_tensor', 'is_storage', 'set_default_tensor_...\n",
      "    __annotations__ = {'_tensor_classes': typing.Set[torch._C.Type]}\n",
      "    default_generator = <torch._C.Generator object>\n",
      "    has_cuda = True\n",
      "    has_cudnn = True\n",
      "    has_lapack = True\n",
      "    has_mkl = True\n",
      "    has_mkldnn = True\n",
      "    has_openmp = True\n",
      "\n",
      "VERSION\n",
      "    1.8.1\n",
      "\n",
      "FILE\n",
      "    d:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "等价于：↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.arange(4.0, requires_grad=True)\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "在我们计算$y$关于$\\mathbf{x}$的梯度之前，我们需要一个地方来存储梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# 等价于 x = torch.arange(4.0, requires_grad=True)\n",
    "x.requires_grad_(True)\n",
    "# x.grad 存储了x的梯度\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "现在让我们计算 $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此处，y是标量\n",
    "y = 2 * torch.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "通过调用反向传播函数来自动计算`y`关于`x` 每个分量的梯度\n",
    "- Notice: 标量对向量求导，结果为向量！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "现在让我们计算 `x` 的另一个函数\n",
    "- 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值。\n",
    "\n",
    "- Notice: PyTorch中，带下划线的函数（例如 `zero_()`）表示重写内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "\n",
    "y = x.sum()\n",
    "\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "深度学习中，我们的目的不是计算微分矩阵，而是批量中每个样本单独计算的偏导数之和，所以先做一个sum操作，将y转换为标量，之后再求导，得到标量关于向量的导数，结果为向量，而不是矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "\n",
    "# 此处，y是向量\n",
    "y = x * x\n",
    "\n",
    "# 等价于 y.backward(torch.ones(len(x)))\n",
    "y.sum().backward()\n",
    "\n",
    "# 向量对向量求导的结果是矩阵\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "将某些计算移动到记录的计算图之外"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".detach()返回一个新的tensor，从当前计算图中分离下来的，但是仍指向原变量的存放位置，不同之处只是requires_grad为false，得到的这个tensor永远不需要计算其梯度，不具有grad。即使之后重新将它的requires_grad置为true，它也不会具有梯度grad\n",
    "\n",
    "这样就会继续使用这个新的tensor进行计算，后面进行反向传播时，调用detach()的tensor就会停止，不能再继续向前进行传播。\n",
    "\n",
    "注意：使用detach返回的tensor和原始的tensor共同一个内存，即一个修改另一个也会跟着改变\n",
    "\n",
    "---\n",
    "参考：https://blog.csdn.net/qq_27825451/article/details/95498211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x\n",
    "\n",
    "u = y.detach()\n",
    "z = u * x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "\n",
    "y.sum().backward()\n",
    "\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "即使构建函数的计算图需要通过 Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c\n",
    "\n",
    "# 不指定size，则表示标量\n",
    "a = torch.randn(size=(), requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()\n",
    "\n",
    "a.grad == d / a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8222, requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-168394.5312, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(204800.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(204800., grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d / a"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
